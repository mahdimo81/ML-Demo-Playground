{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install milvus pymilvus"
      ],
      "metadata": {
        "id": "RU03tpY8Dbtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from pymilvus import connections, utility, Collection, FieldSchema, CollectionSchema, DataType\n",
        "from milvus import default_server\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MRkAF44XGYtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6FleN4kDOSl"
      },
      "outputs": [],
      "source": [
        "# Specify where the data will be stored.\n",
        "default_server.set_base_dir('milvus_data')\n",
        "default_server.set_wal_dir('milvus_wal')\n",
        "\n",
        "default_server.start()\n",
        "connections.connect(\"default\", host=\"127.0.0.1\", port=default_server.listen_port)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collection parameters\n",
        "collection_name = \"document_collection\"\n",
        "dimension = 384  # Dimensions of embedding vectors (depends on embedder model)\n",
        "\n",
        "# Define fields (columns)\n",
        "fields = [\n",
        "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
        "    FieldSchema(name=\"user_id\", dtype=DataType.INT64),\n",
        "    FieldSchema(name=\"content\", dtype=DataType.VARCHAR, max_length=500),\n",
        "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=dimension)\n",
        "]\n",
        "\n",
        "# Create schema\n",
        "schema = CollectionSchema(fields, description=\"Collection for document search\")\n",
        "\n",
        "# Create collection\n",
        "collection = Collection(name=collection_name, schema=schema)\n",
        "\n",
        "print(f\"Collection '{collection_name}' created successfully.\")"
      ],
      "metadata": {
        "id": "szBLmLHTDsov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create index for efficient search\n",
        "# Index parameters\n",
        "index_params = {\n",
        "    \"index_type\": \"IVF_FLAT\",\n",
        "    \"metric_type\": \"L2\",\n",
        "    \"params\": {\"nlist\": 128}\n",
        "}\n",
        "\n",
        "# Create index for embedding field\n",
        "collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "\n",
        "print(\"Index created successfully.\")"
      ],
      "metadata": {
        "id": "fMmb7LRGGtcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------\n",
        "|index_type/metric_type | L2 | IP  | COSINE | HAMMING | JACCARD | TANIMOTO |\n",
        "------------|----------|--------|---------|---------|----------|-\n",
        "|IVF_FLAT\t  | ✅ | ✅ | ✅    | ✅      | ✅      | ✅      |\n",
        "|IVF_SQ8\t  | ✅ | ✅ | ✅    | ❌      | ❌      | ❌      |\n",
        "|IVF_PQ\t    | ✅ | ✅ | ⚠️*   | ❌      | ❌      | ❌      |\n",
        "|HNSW\t      | ✅ | ✅ | ⚠️*   | ❌      | ❌      | ❌      |\n",
        "|DISKANN\t  | ✅ | ✅ | ⚠️**  | ❌      | ❌      | ❌      |\n",
        "|FLAT\t      | ✅ | ✅ | ✅    | ✅      | ✅      | ✅      |\n",
        "|SCANN\t    | ✅ | ✅ | ⚠️*   | ❌      | ❌      | ❌      |\n",
        "\n",
        "Here’s the English translation of your text about Milvus index types and metric types:\n",
        "\n",
        "---\n",
        "\n",
        "### **Types of `index_type` in Milvus:**\n",
        "\n",
        "1. **IVF_FLAT** (Inverted File with Flat)  \n",
        "   - Suitable for approximate nearest neighbor search Approximate Nearest Neighbors (ANN).  \n",
        "   - Parameters: `nlist` (number of clusters).  \n",
        "   - Requires setting `nprobe` during search.  \n",
        "\n",
        "2. **IVF_SQ8** (Inverted File with Scalar Quantization)  \n",
        "   - Similar to IVF_FLAT but with 8-bit compression for memory efficiency.  \n",
        "   - Parameters: `nlist`.  \n",
        "\n",
        "3. **IVF_PQ** (Inverted File with Product Quantization)  \n",
        "   - Uses product quantization (PQ) for compression.  \n",
        "   - Parameters: `nlist`, `m` (number of subspaces), `nbits` (bits assigned to each centroid).  \n",
        "\n",
        "4. **HNSW** (Hierarchical Navigable Small World)  \n",
        "   - A graph-based method for efficient search using small-world hierarchies.  \n",
        "   - Parameters:  \n",
        "     - `M` (number of connections per node in layers).  \n",
        "     - `efConstruction` (number of candidates considered during construction).  \n",
        "\n",
        "5. **DISKANN** (Graph-based, optimized for disk storage)  \n",
        "   - Designed for very large datasets (e.g., billions of vectors).  \n",
        "   - Parameters:  \n",
        "     - `max_degree` (maximum degree of each node in the graph).  \n",
        "     - `search_list_size` (search list size).  \n",
        "\n",
        "6. **FLAT** (Exhaustive search without compression)  \n",
        "   - Suitable for small datasets.  \n",
        "   - No parameters (most accurate but slowest method).  \n",
        "\n",
        "7. **SCANN** (Quantization-based)  \n",
        "   - Parameters:  \n",
        "     - `quantization_bit` (e.g., 4, 6, 8 bits).  \n",
        "     - `nlist`.  \n",
        "\n",
        "8. **AUTOINDEX** (Automatically optimized by Milvus).  \n",
        "\n",
        "---\n",
        "\n",
        "### **Types of `metric_type` (Distance Metrics):**\n",
        "1. **`L2`** (Euclidean Distance)  \n",
        "   - Measures straight-line distance between vectors.  \n",
        "\n",
        "2. **`IP`** (Inner Product)  \n",
        "   - Higher values indicate greater similarity.  \n",
        "\n",
        "3. **`COSINE`** (Cosine Similarity)  \n",
        "   - Compares the angle between vectors (normalized).  \n",
        "\n",
        "4. **`HAMMING`** (Hamming Distance)  \n",
        "   - For binary vectors (counts differing bits).  \n",
        "\n",
        "5. **`JACCARD`** (Jaccard Index)  \n",
        "   - Compares sets (useful for binary data).  \n",
        "\n",
        "6. **`TANIMOTO`** (Tanimoto Coefficient)  \n",
        "   - Similar to Jaccard but for specific use cases.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Key Notes:**\n",
        "- **IVF_FLAT** and **IVF_SQ8** are ideal for medium-dimensional data (e.g., 100–1000 dimensions).  \n",
        "- **HNSW** offers high accuracy but higher memory usage.  \n",
        "- **DISKANN** is optimized for massive-scale data (e.g., billions of vectors).  \n",
        "- **COSINE** and **IP** often outperform **L2** for semantic search (e.g., NLP).  "
      ],
      "metadata": {
        "id": "K1kxd1L3IQYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model for create embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # A model with 384 dimension\n",
        "\n",
        "# Instance data\n",
        "documents = [\n",
        "    {\"user_id\": 10, \"content\": \"My name is mahdi\"},\n",
        "    {\"user_id\": 10, \"content\": \"I like neural networks\"},\n",
        "    {\"user_id\": 10, \"content\": \"I don't like math\"},\n",
        "    {\"user_id\": 15, \"content\": \"My name is steve\"},\n",
        "    {\"user_id\": 15, \"content\": \"I love machine learning\"}\n",
        "]\n",
        "\n",
        "# Produce embeddings\n",
        "embeddings = model.encode([doc[\"content\"] for doc in documents])\n",
        "\n",
        "# Preparing for insertion\n",
        "data = [\n",
        "    [doc[\"user_id\"] for doc in documents],  # (user_ids) reffers to user id in Relational DB\n",
        "    [doc[\"content\"] for doc in documents],  # (contents)\n",
        "    embeddings.tolist()  # Convert numpy array to list\n",
        "]\n",
        "\n",
        "# Insert data\n",
        "insert_result = collection.insert(data)\n",
        "\n",
        "print(f\"Inserted {len(documents)} documents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDZ4y0-8KrD_",
        "outputId": "c509e12d-6916-4c7c-a3f2-92d2e19ec7bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 5 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to existing collection if it does not connected\n",
        "# collection_name = \"document_collection\"\n",
        "# collection = Collection(collection_name)\n",
        "\n",
        "# Load collection into memory\n",
        "collection.load()\n",
        "\n",
        "# Query all data (limit to 1000 rows just in case)\n",
        "results = collection.query(\n",
        "    expr=\"\",  # No filtering condition; returns everything\n",
        "    output_fields=[\"id\", \"user_id\", \"content\", \"embedding\"],  # You can add \"embedding\" too if you want\n",
        "    limit=10\n",
        ")\n",
        "\n",
        "# Show results\n",
        "for i, res in enumerate(results):\n",
        "  print(f\"{i+1}. ID: {res['id']} || User ID: {res['user_id']} || Content: {res['content']} || Embedding: {np.array(res['embedding']).shape}...\")  # Show first 5 dims\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCSyhPySNi2w",
        "outputId": "7786a643-facf-4b66-9e8c-355236290f78"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. ID: 459948152356873207 || User ID: 10 || Content: My name is mahdi || Embedding: (384,)...\n",
            "2. ID: 459948152356873208 || User ID: 10 || Content: I like neural networks || Embedding: (384,)...\n",
            "3. ID: 459948152356873209 || User ID: 10 || Content: I don't like math || Embedding: (384,)...\n",
            "4. ID: 459948152356873210 || User ID: 15 || Content: My name is steve || Embedding: (384,)...\n",
            "5. ID: 459948152356873211 || User ID: 15 || Content: I love machine learning || Embedding: (384,)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tect for search\n",
        "search_text = \"what do you like?\"\n",
        "\n",
        "# Create embedding text\n",
        "search_embedding = model.encode([search_text])[0].tolist()\n",
        "\n",
        "# Search paramas\n",
        "search_params = {\n",
        "    \"metric_type\": \"L2\",\n",
        "    \"params\": {\"nprobe\": 10}\n",
        "}\n",
        "\n",
        "# Execute search\n",
        "results = collection.search(\n",
        "    data=[search_embedding],\n",
        "    anns_field=\"embedding\",\n",
        "    param=search_params,\n",
        "    limit=3,  # number of results\n",
        "    output_fields=[\"user_id\", \"content\"] # Fields we wants to return\n",
        ")\n",
        "\n",
        "# Show results\n",
        "for hits in results:\n",
        "    for hit in hits:\n",
        "        print(f\"ID: {hit.id}, Score: {hit.score}\")\n",
        "        print(f\"user_id: {hit.entity.get('user_id')}\")\n",
        "        print(f\"Content: {hit.entity.get('content')}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qda2-pEGORAI",
        "outputId": "4ac6cb52-be3a-42eb-ad13-e7c922df48af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: 459948152356873208, Score: 1.2803442478179932\n",
            "user_id: 10\n",
            "Content: I like neural networks\n",
            "\n",
            "ID: 459948152356873209, Score: 1.612396001815796\n",
            "user_id: 10\n",
            "Content: I don't like math\n",
            "\n",
            "ID: 459948152356873211, Score: 1.6257460117340088\n",
            "user_id: 15\n",
            "Content: I love machine learning\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text for search\n",
        "search_text = \"what do you like?\"\n",
        "\n",
        "# Create embedding text\n",
        "search_embedding = model.encode([search_text])[0].tolist()\n",
        "\n",
        "# Search params\n",
        "search_params = {\n",
        "    \"metric_type\": \"L2\",\n",
        "    \"params\": {\"nprobe\": 10}\n",
        "}\n",
        "\n",
        "# Execute search with filter for user_id = 10\n",
        "results = collection.search(\n",
        "    data=[search_embedding],\n",
        "    anns_field=\"embedding\",\n",
        "    param=search_params,\n",
        "    limit=1,  # number of results\n",
        "    output_fields=[\"user_id\", \"content\"], # Fields we want to return\n",
        "    expr=\"user_id == 15\"  # Filter expression\n",
        ")\n",
        "\n",
        "# Show results\n",
        "for hits in results:\n",
        "    for hit in hits:\n",
        "        print(f\"ID: {hit.id}, Score: {hit.score}\")\n",
        "        print(f\"user_id: {hit.entity.get('user_id')}\")\n",
        "        print(f\"Content: {hit.entity.get('content')}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6s_0wDuPlTf",
        "outputId": "f59e30cc-76c5-4bfa-b89b-f488667b2a96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: 459948152356873211, Score: 1.6257460117340088\n",
            "user_id: 15\n",
            "Content: I love machine learning\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hits[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5Q11StfRoSG",
        "outputId": "be1bcb72-d82f-45dc-e2e1-f27e3af7408b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 459948152356873211, 'distance': 1.6257460117340088, 'entity': {'user_id': 15, 'content': 'I love machine learning'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Disconnect and stop DB server\n",
        "connections.disconnect(\"default\")\n",
        "default_server.stop()"
      ],
      "metadata": {
        "id": "euuGxFzMSX2d"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the previous locations\n",
        "default_server.set_base_dir('milvus_data')\n",
        "default_server.set_wal_dir('milvus_wal')\n",
        "\n",
        "# Run the server\n",
        "default_server.start()\n",
        "\n",
        "# Connect to the server\n",
        "connections.connect(\"default\", host=\"127.0.0.1\", port=default_server.listen_port)"
      ],
      "metadata": {
        "id": "-6C24C06SXxF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import utility\n",
        "\n",
        "# Checking for the existence of a previous collection\n",
        "collection_name = \"document_collection\"\n",
        "\n",
        "if utility.has_collection(collection_name):\n",
        "    print(f\"Collection '{collection_name}' exists and will be loaded.\")\n",
        "else:\n",
        "    print(f\"Collection '{collection_name}' does not exist!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Cy-uXwSXuG",
        "outputId": "7c9592fb-e080-48dd-88da-ac11484934e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'document_collection' exists and will be loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import Collection\n",
        "\n",
        "# Receive the collection\n",
        "collection = Collection(collection_name)\n",
        "\n",
        "# Load collection into memory\n",
        "collection.load()\n",
        "\n",
        "print(f\"Collection '{collection_name}' loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKBVHA4MTfqW",
        "outputId": "602948cf-71d5-4a07-82ee-71dd33a2e197"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'document_collection' loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query all data (limit to 1000 rows just in case)\n",
        "results = collection.query(\n",
        "    expr=\"\",  # No filtering condition; returns everything\n",
        "    output_fields=[\"id\", \"user_id\", \"content\", \"embedding\"],  # You can add \"embedding\" too if you want\n",
        "    limit=10\n",
        ")\n",
        "\n",
        "# Show results\n",
        "for i, res in enumerate(results):\n",
        "  print(f\"{i+1}. ID: {res['id']} || User ID: {res['user_id']} || Content: {res['content']} || Embedding: {np.array(res['embedding']).shape}...\")  # Show first 5 dims\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVW1yf8aTtMF",
        "outputId": "8bba5f3e-be77-45eb-fdcc-a92a2da9c2ce"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. ID: 459948152356873207 || User ID: 10 || Content: My name is mahdi || Embedding: (384,)...\n",
            "2. ID: 459948152356873208 || User ID: 10 || Content: I like neural networks || Embedding: (384,)...\n",
            "3. ID: 459948152356873209 || User ID: 10 || Content: I don't like math || Embedding: (384,)...\n",
            "4. ID: 459948152356873210 || User ID: 15 || Content: My name is steve || Embedding: (384,)...\n",
            "5. ID: 459948152356873211 || User ID: 15 || Content: I love machine learning || Embedding: (384,)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all data in the collection (keeps the collection structure)\n",
        "delete_expr = \"id >= 0\"  # Or any condition that matches all entities\n",
        "collection.delete(expr=delete_expr)\n",
        "\n",
        "print(\"All data has been deleted from the collection.\")"
      ],
      "metadata": {
        "id": "XvBKR0PXQkYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQL6iEw4Qmcn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}