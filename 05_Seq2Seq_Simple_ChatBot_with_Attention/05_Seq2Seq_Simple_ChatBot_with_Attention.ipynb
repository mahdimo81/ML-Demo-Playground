{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSYvvV6NqD4E"
   },
   "source": [
    "# Seq2Seq Chatbot Implementation with PyTorch By **Mahdi Momeni**\n",
    "\n",
    "## Overview\n",
    "This notebook implements a sequence-to-sequence (Seq2Seq with Attention) neural network for a simple chatbot using PyTorch. The model follows an encoder-decoder with attention architecture with GRU (Gated Recurrent Unit) layers, designed to handle conversational data and generate responses.\n",
    "\n",
    "## Model Architecture\n",
    "The system consists of three main components:\n",
    "1. **Encoder**:\n",
    "   - Embedding layer (vocab_size=2570, embedding_dim=128)\n",
    "   - 2-layer GRU (hidden_size=128) with dropout (p=0.2)\n",
    "2. **Attention**:\n",
    "   - Decoder Energy:   (FC) layer (hidden_size=128, hidden_size=128)\n",
    "   - ENcoder Energy:   (FC) layer (hidden_size=128, hidden_size=128)\n",
    "   - Energy: Tanh activation function on the sum of decoder energy and encoder energy\n",
    "   - Attention Scores: (FC) layer (hidden_size, 1, bias=False) on Energy\n",
    "   - Attention Weights: Softmax activation function on Attention Scores\n",
    "   - Context vector: BMM on attention weights and encoder outputs\n",
    "   \n",
    "3. **Decoder**:\n",
    "   - Embedding layer (matching encoder dimensions)\n",
    "   - 2-layer GRU (hidden_size + embed_size, hidden_size) with dropout (p=0.2)\n",
    "   - Additional dropout layer (p=0.3)\n",
    "   - Fully connected output layer (hidden_size * 2 ->> vocab_size)\n",
    "\n",
    "## Data Representation\n",
    "- Input/output sequences are padded to length 24\n",
    "- Special tokens:\n",
    "  - `<SOS>`: Start of sequence\n",
    "  - `<EOS>`: End of sequence\n",
    "  - `<PAD>`: Padding token\n",
    "- Batch size: 32\n",
    "- Vocabulary size: 2570 unique tokens\n",
    "\n",
    "## Training Process\n",
    "The model processes data in the following format:\n",
    "- Encoder input: `[batch_size, seq_len]` (32, 24)\n",
    "- Decoder input: `[batch_size, seq_len-1]`\n",
    "- Target output: `[batch_size, seq_len-1]` (reshaped for loss calculation)\n",
    "\n",
    "## Performance Considerations\n",
    "- Attention mechanism is included to generate more relevant words\n",
    "- Dropout layers are included to prevent overfitting\n",
    "- The model uses batch-first tensor organization\n",
    "- Hidden states are maintained between encoder and decoder\n",
    "- Output is processed through a linear layer to vocabulary size\n",
    "\n",
    "This implementation is included more advanced features than previous version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qa28oRlLDjIu"
   },
   "source": [
    "## **Data Loading and Initial Exploration**  \n",
    "\n",
    "The following code loads the raw dialog data from the `dialogs.txt` file and performs a basic exploratory analysis:  \n",
    "- **Preview**: Displays the first 100 characters to inspect formatting.  \n",
    "- **Character Count**: Measures the total number of characters in the dataset.  \n",
    "- **Word Count**: Estimates the dataset size by counting whitespace-separated tokens.  \n",
    "\n",
    "This initial step helps assess the dataset's scale and structure before further preprocessing (tokenization, cleaning, and splitting into training pairs).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OmKiA8fpk4c",
    "outputId": "52d0ab6c-5e71-4aa6-9788-239a9a67da14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi, how are you doing?\ti'm fine. how about yourself?\n",
      "i'm fine. how about yourself?\ti'm pretty good. \n",
      "Character's length: 243885\n",
      "Word's length: 47952\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "with open(\"dialogs.txt\", \"r\") as f:\n",
    "  text = f.read()\n",
    "  print(text[:100])\n",
    "  print(f\"Character's length: {len(text)}\")\n",
    "  print(f\"Word's length: {len(text.split())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF4ZAG3sEyeV"
   },
   "source": [
    "## **Text Normalization and Preprocessing**\n",
    "\n",
    "This step prepares raw dialog data for tokenization by applying critical formatting rules:\n",
    "\n",
    "### **Key Operations**\n",
    "1. **Case Normalization**:  \n",
    "   Converts all text to lowercase to reduce vocabulary complexity.\n",
    "\n",
    "2. **Punctuation Standardization**:  \n",
    "   Isolates key punctuation marks (`, . ? !`) with whitespace to ensure proper tokenization by:\n",
    "   - Adding spaces around each symbol  \n",
    "\n",
    "3. **Output**:  \n",
    "   Processed text is saved to `manipulated_text.txt` for downstream tasks.\n",
    "\n",
    "### **Why This Matters**\n",
    "- **Consistency**: Prevents model confusion from irregular spacing (e.g., \"hello!\" vs \"hello !\").  \n",
    "- **Reproducibility**: Saved intermediate file allows inspection and reuse without reprocessing.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Implementation Notes**\n",
    "- Uses Python's `str.translate()` for efficient bulk character replacement  \n",
    "- Preserves original line structure (conversational turns remain intact)  \n",
    "- Modifiable `change_chars` dictionary can extend to other symbols as needed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "JYZXbc9Yq4BT"
   },
   "outputs": [],
   "source": [
    "def manipulate_text(path):\n",
    "    # Define a function 'manipulate_text' that takes a file path ('path') as input\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        # Open the file at 'path' in read mode ('r') and assign it to file object 'f'\n",
    "\n",
    "        whole_text = f.read().lower()\n",
    "        # Read the entire file content, convert it to lowercase, and store in 'whole_text'\n",
    "\n",
    "        change_chars = {ord(\",\"): \" , \", ord(\".\"): \" . \", ord(\"?\"): \" ? \", ord(\"!\"): \" ! \"}\n",
    "        # Create a translation dictionary:\n",
    "        # - Keys: Unicode code points of punctuation (',', '.', '?', '!')\n",
    "        # - Values: Padded versions (e.g., comma becomes ' , ')\n",
    "\n",
    "        whole_text = whole_text.translate(change_chars)\n",
    "        # Apply the translation to 'whole_text', replacing punctuation with padded versions\n",
    "\n",
    "    with open(\"manipulated_text.txt\", 'w') as f2:\n",
    "        # Open (or create) 'manipulated_text.txt' in write mode ('w') as file object 'f2'\n",
    "\n",
    "      f2.write(whole_text)\n",
    "      # Write the modified 'whole_text' to the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "SrwQR43qVIuq"
   },
   "outputs": [],
   "source": [
    "manipulate_text(\"dialogs.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkPU1rVjHKcj"
   },
   "source": [
    "## **Loading Conversation Pairs**\n",
    "\n",
    "The processed text is loaded into a structured DataFrame with:\n",
    "- **Input**: Speaker's initial utterance  \n",
    "- **Target**: Corresponding response  \n",
    "\n",
    "This tabular format enables direct pairing of training samples for the seq2seq model. The first 5 rows are displayed to verify correct formatting.\n",
    "\n",
    "---\n",
    "\n",
    "Key features:\n",
    "- Clear separation of input/target pairs  \n",
    "- Proper handling of punctuation (from previous normalization)  \n",
    "- Ready for tokenization and sequence processing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "kiWakjDroqPr",
    "outputId": "389c5d34-5641-4591-acfe-a483b959975a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"# Display the first 5 rows of the DataFrame for inspection\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i'm fine .  how about yourself ? \",\n          \"i've been great .  what about you ? \",\n          \"i'm pretty good .  thanks for asking . \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i'm pretty good .  thanks for asking . \",\n          \"i've been good .  i'm in school right now . \",\n          \"no problem .  so how have you been ? \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-cc2cb61a-6ded-4b1d-beb6-2ca29d3ed692\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi ,  how are you doing ?</td>\n",
       "      <td>i'm fine .  how about yourself ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine .  how about yourself ?</td>\n",
       "      <td>i'm pretty good .  thanks for asking .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good .  thanks for asking .</td>\n",
       "      <td>no problem .  so how have you been ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem .  so how have you been ?</td>\n",
       "      <td>i've been great .  what about you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great .  what about you ?</td>\n",
       "      <td>i've been good .  i'm in school right now .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc2cb61a-6ded-4b1d-beb6-2ca29d3ed692')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cc2cb61a-6ded-4b1d-beb6-2ca29d3ed692 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cc2cb61a-6ded-4b1d-beb6-2ca29d3ed692');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-b28fa239-150f-4c71-a4f5-bff5f8ba4da1\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b28fa239-150f-4c71-a4f5-bff5f8ba4da1')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-b28fa239-150f-4c71-a4f5-bff5f8ba4da1 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                     Input  \\\n",
       "0               hi ,  how are you doing ?    \n",
       "1        i'm fine .  how about yourself ?    \n",
       "2  i'm pretty good .  thanks for asking .    \n",
       "3    no problem .  so how have you been ?    \n",
       "4     i've been great .  what about you ?    \n",
       "\n",
       "                                         Target  \n",
       "0             i'm fine .  how about yourself ?   \n",
       "1       i'm pretty good .  thanks for asking .   \n",
       "2         no problem .  so how have you been ?   \n",
       "3          i've been great .  what about you ?   \n",
       "4  i've been good .  i'm in school right now .   "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Import the Pandas library and alias it as 'pd' for convenience\n",
    "\n",
    "df = pd.read_csv('manipulated_text.txt', sep='\\t', names=['Input', 'Target'])\n",
    "# Read a CSV (or text) file into a Pandas DataFrame:\n",
    "# - File: 'manipulated_text.txt'\n",
    "# - Separator: Tab ('\\t')\n",
    "# - Column names: 'Input' and 'Target' (since the file has no headers)\n",
    "\n",
    "df.head(5)\n",
    "# Display the first 5 rows of the DataFrame for inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bsae2cBaIFPV"
   },
   "source": [
    "## **Vocabulary Dictionary Implementation**\n",
    "\n",
    "Following class creates a bidirectional word-integer mapping essential for text processing in neural networks:\n",
    "\n",
    "### **Core Functionality**\n",
    "- **word2int**: Dictionary mapping words to unique indices  \n",
    "- **int2word**: Reverse dictionary mapping indices back to words  \n",
    "- **Dynamic Vocabulary**: Automatically expands with new words via `add_word()`  \n",
    "\n",
    "### **Key Methods**\n",
    "1. `add_word(word)`  \n",
    "   - Assigns a new index to unseen words  \n",
    "   - Maintains consistent two-way mapping  \n",
    "\n",
    "2. `__len__()`  \n",
    "   - Returns current vocabulary size  \n",
    "\n",
    "### **Purpose**\n",
    "- Enables conversion between tokens and numerical representations  \n",
    "- Serves as the foundation for embedding layer initialization  \n",
    "- Preserves index consistency throughout training/inference  \n",
    "\n",
    "*Note: Special tokens (`<SOS>`, `<EOS>`, `<PAD>`) should be added first in most implementations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "d8wIGEzfpxXc"
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    # Define a class 'Dictionary' to map words to unique integers and vice versa\n",
    "\n",
    "    def __init__(self):\n",
    "        # Constructor method: Initializes the dictionary with empty mappings and index 0\n",
    "        self.word2int = {}  # Dictionary to map words to integers (word -> index)\n",
    "        self.int2word = {}  # Dictionary to map integers back to words (index -> word)\n",
    "        self.idx = 0        # Counter to assign the next available index\n",
    "\n",
    "    def add_word(self, word):\n",
    "        # Method to add a word to the dictionary if it doesn't already exist\n",
    "        if word not in self.word2int:  # Check if the word is not already in word2int\n",
    "            self.word2int[word] = self.idx  # Map the word to the current index\n",
    "            self.int2word[self.idx] = word  # Map the index back to the word\n",
    "            self.idx += 1  # Increment index for the next new word\n",
    "\n",
    "    def __len__(self):\n",
    "        # Special method to return the number of words in the dictionary\n",
    "        return len(self.word2int)  # The length of word2int gives the total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "4e3XRMFS5qIc"
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khKmj1kSJDV1"
   },
   "source": [
    "## **Vocabulary Creation & Sentence Encoding**\n",
    "\n",
    "This section:\n",
    "1. **Builds vocabulary** by scanning all words in Input/Target columns  \n",
    "2. **Converts sentences** to integer sequences using the dictionary  \n",
    "\n",
    "Key points:\n",
    "- Each unique word gets assigned an integer ID  \n",
    "- Same word in Input/Target receives the same ID  \n",
    "- Output dataframe (`int_df`) contains numericalized sequences  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "C69Zk5Ud5uh9"
   },
   "outputs": [],
   "source": [
    "tags = ['<SOS>', '<PAD>', '<EOS>']\n",
    "# Define special tokens: Start-of-Sequence, Padding, and End-of-Sequence\n",
    "\n",
    "for tag in tags:\n",
    "    dictionary.add_word(tag)\n",
    "    # Add each special token to the dictionary (ensures they have consistent integer IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "qYAqCIGk1ba8"
   },
   "outputs": [],
   "source": [
    "def sentence_to_ints(sentence):\n",
    "    # Convert a sentence (string) to a list of integer IDs using the dictionary\n",
    "    return [dictionary.word2int[word] for word in sentence.split()]\n",
    "    # Splits the sentence into words and looks up each word's integer ID\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Iterate over each row in the DataFrame (ignoring the index with '_')\n",
    "    for word in row['Input'].split():\n",
    "        dictionary.add_word(word)\n",
    "        # Add each word in the 'Input' column to the dictionary\n",
    "    for word in row['Target'].split():\n",
    "        dictionary.add_word(word)\n",
    "        # Add each word in the 'Target' column to the dictionary\n",
    "\n",
    "int_df = pd.DataFrame(columns=['Input', 'Target'])\n",
    "# Create a new DataFrame to store integer-encoded sentences\n",
    "\n",
    "int_df['Input'] = df['Input'].apply(sentence_to_ints)\n",
    "# Convert 'Input' text to integer sequences and store in the new DataFrame\n",
    "\n",
    "int_df['Target'] = df['Target'].apply(sentence_to_ints)\n",
    "# Convert 'Target' text to integer sequences and store in the new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "grbAMsVv10EV",
    "outputId": "859729d6-a99a-4b62-9b03-582e4b1ed4bf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"int_df\",\n  \"rows\": 3725,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "int_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-4c360326-e75d-4ac6-a4af-88981ce08d56\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>[10, 11, 12, 5, 13, 14, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10, 11, 12, 5, 13, 14, 9]</td>\n",
       "      <td>[10, 15, 16, 12, 17, 18, 19, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10, 15, 16, 12, 17, 18, 19, 12]</td>\n",
       "      <td>[20, 21, 12, 22, 5, 23, 7, 24, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20, 21, 12, 22, 5, 23, 7, 24, 9]</td>\n",
       "      <td>[25, 24, 26, 12, 27, 13, 7, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25, 24, 26, 12, 27, 13, 7, 9]</td>\n",
       "      <td>[25, 24, 16, 12, 10, 28, 29, 30, 31, 12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c360326-e75d-4ac6-a4af-88981ce08d56')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-4c360326-e75d-4ac6-a4af-88981ce08d56 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-4c360326-e75d-4ac6-a4af-88981ce08d56');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-9f8eb004-da96-4154-bf0b-1c98e1ab2149\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f8eb004-da96-4154-bf0b-1c98e1ab2149')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-9f8eb004-da96-4154-bf0b-1c98e1ab2149 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                               Input                                    Target\n",
       "0              [3, 4, 5, 6, 7, 8, 9]                [10, 11, 12, 5, 13, 14, 9]\n",
       "1         [10, 11, 12, 5, 13, 14, 9]          [10, 15, 16, 12, 17, 18, 19, 12]\n",
       "2   [10, 15, 16, 12, 17, 18, 19, 12]         [20, 21, 12, 22, 5, 23, 7, 24, 9]\n",
       "3  [20, 21, 12, 22, 5, 23, 7, 24, 9]            [25, 24, 26, 12, 27, 13, 7, 9]\n",
       "4     [25, 24, 26, 12, 27, 13, 7, 9]  [25, 24, 16, 12, 10, 28, 29, 30, 31, 12]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7aGHOSMmLAf1",
    "outputId": "de86267d-a014-47be-8106-e74356f215d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2570\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsZZPnILKDd9"
   },
   "source": [
    "## **Sequence Padding & Special Tokens**\n",
    "\n",
    "This step prepares numericalized sequences for the seq2seq model by:\n",
    "\n",
    "1. **Analyzing Sequence Lengths**:\n",
    "   - Calculates max input and target lengths\n",
    "   - Determines overall padding requirement\n",
    "\n",
    "2. **Applying Padding**:\n",
    "   - Adds `<SOS>` (start) and `<EOS>` (end) tokens to each sequence\n",
    "   - Pads with `<PAD>` tokens to ensure uniform length\n",
    "\n",
    "\n",
    "*Key Benefit*: Creates properly formatted tensors for batch processing while preserving sequence boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4C5_mbJ3pHc",
    "outputId": "e362bf41-56c8-4a30-b61f-209954179777"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 22, 22)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths = int_df['Input'].apply(len)\n",
    "# Calculate the length of each 'Input' sequence in int_df and store in input_lengths\n",
    "\n",
    "target_lengths = int_df['Target'].apply(len)\n",
    "# Calculate the length of each 'Target' sequence in int_df and store in target_lengths\n",
    "\n",
    "max_input_length = max(input_lengths)\n",
    "# Find the maximum sequence length in input_lengths\n",
    "\n",
    "max_target_length = max(target_lengths)\n",
    "# Find the maximum sequence length in target_lengths\n",
    "\n",
    "max_length = max(max_input_length, max_target_length)\n",
    "# Determine the overall maximum sequence length between inputs and targets\n",
    "\n",
    "max_input_length, max_target_length, max_length\n",
    "# Return a tuple of (max_input_length, max_target_length, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "lfvIhRNg4dVc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import NumPy library for array operations\n",
    "\n",
    "def add_padd(list_of_ints, max_length):\n",
    "    # Function to pad a sequence of integers to a fixed length with special tokens\n",
    "    pad = dictionary.word2int['<PAD>']\n",
    "    # Get the integer ID for the padding token '<PAD>' from the dictionary\n",
    "\n",
    "    return np.array(\n",
    "        [dictionary.word2int['<SOS>']] +  # Start with Start-of-Sequence token\n",
    "        list_of_ints +                     # Original sequence\n",
    "        [pad] * (max_length - len(list_of_ints)) +  # Padding tokens to reach max_length\n",
    "        [dictionary.word2int['<EOS>']]     # End with End-of-Sequence token\n",
    "    )\n",
    "    # Returns a NumPy array with the padded sequence\n",
    "\n",
    "int_df['Input'] = int_df['Input'].apply(lambda x: add_padd(x, max_length))\n",
    "# Apply padding to every sequence in the 'Input' column using the max_length\n",
    "\n",
    "int_df['Target'] = int_df['Target'].apply(lambda x: add_padd(x, max_length))\n",
    "# Apply padding to every sequence in the 'Target' column using the max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "naVtA5so5SEV",
    "outputId": "6ce133ea-34bf-49c3-a7b0-4530c705cf96"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"int_df\",\n  \"rows\": 3725,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "int_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ef4b4819-6682-4cb3-82ea-072c4b51e713\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 3, 4, 5, 6, 7, 8, 9, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 10, 11, 12, 5, 13, 14, 9, 1, 1, 1, 1, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 10, 11, 12, 5, 13, 14, 9, 1, 1, 1, 1, 1, 1...</td>\n",
       "      <td>[0, 10, 15, 16, 12, 17, 18, 19, 12, 1, 1, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 10, 15, 16, 12, 17, 18, 19, 12, 1, 1, 1, 1...</td>\n",
       "      <td>[0, 20, 21, 12, 22, 5, 23, 7, 24, 9, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 20, 21, 12, 22, 5, 23, 7, 24, 9, 1, 1, 1, ...</td>\n",
       "      <td>[0, 25, 24, 26, 12, 27, 13, 7, 9, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 25, 24, 26, 12, 27, 13, 7, 9, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 25, 24, 16, 12, 10, 28, 29, 30, 31, 12, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>[0, 136, 42, 16, 586, 12, 267, 40, 62, 680, 12...</td>\n",
       "      <td>[0, 6, 7, 2569, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>[0, 6, 7, 2569, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 106, 12, 255, 77, 236, 12, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>[0, 106, 12, 255, 77, 236, 12, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 125, 398, 186, 280, 30, 1503, 12, 759, 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>[0, 125, 398, 186, 280, 30, 1503, 12, 759, 129...</td>\n",
       "      <td>[0, 115, 35, 32, 255, 77, 1424, 47, 77, 30, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>[0, 115, 35, 32, 255, 77, 1424, 47, 77, 30, 15...</td>\n",
       "      <td>[0, 609, 2478, 589, 12, 67, 182, 280, 730, 150...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3725 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef4b4819-6682-4cb3-82ea-072c4b51e713')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ef4b4819-6682-4cb3-82ea-072c4b51e713 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ef4b4819-6682-4cb3-82ea-072c4b51e713');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-13071f6c-4f0b-47ee-9016-6e2cffc9e987\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13071f6c-4f0b-47ee-9016-6e2cffc9e987')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-13071f6c-4f0b-47ee-9016-6e2cffc9e987 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "0     [0, 3, 4, 5, 6, 7, 8, 9, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1     [0, 10, 11, 12, 5, 13, 14, 9, 1, 1, 1, 1, 1, 1...   \n",
       "2     [0, 10, 15, 16, 12, 17, 18, 19, 12, 1, 1, 1, 1...   \n",
       "3     [0, 20, 21, 12, 22, 5, 23, 7, 24, 9, 1, 1, 1, ...   \n",
       "4     [0, 25, 24, 26, 12, 27, 13, 7, 9, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "3720  [0, 136, 42, 16, 586, 12, 267, 40, 62, 680, 12...   \n",
       "3721  [0, 6, 7, 2569, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3722  [0, 106, 12, 255, 77, 236, 12, 1, 1, 1, 1, 1, ...   \n",
       "3723  [0, 125, 398, 186, 280, 30, 1503, 12, 759, 129...   \n",
       "3724  [0, 115, 35, 32, 255, 77, 1424, 47, 77, 30, 15...   \n",
       "\n",
       "                                                 Target  \n",
       "0     [0, 10, 11, 12, 5, 13, 14, 9, 1, 1, 1, 1, 1, 1...  \n",
       "1     [0, 10, 15, 16, 12, 17, 18, 19, 12, 1, 1, 1, 1...  \n",
       "2     [0, 20, 21, 12, 22, 5, 23, 7, 24, 9, 1, 1, 1, ...  \n",
       "3     [0, 25, 24, 26, 12, 27, 13, 7, 9, 1, 1, 1, 1, ...  \n",
       "4     [0, 25, 24, 16, 12, 10, 28, 29, 30, 31, 12, 1,...  \n",
       "...                                                 ...  \n",
       "3720  [0, 6, 7, 2569, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3721  [0, 106, 12, 255, 77, 236, 12, 1, 1, 1, 1, 1, ...  \n",
       "3722  [0, 125, 398, 186, 280, 30, 1503, 12, 759, 129...  \n",
       "3723  [0, 115, 35, 32, 255, 77, 1424, 47, 77, 30, 15...  \n",
       "3724  [0, 609, 2478, 589, 12, 67, 182, 280, 730, 150...  \n",
       "\n",
       "[3725 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpSmYtijLW7F"
   },
   "source": [
    "### **Sequence Format Verification**  \n",
    "\n",
    "This code checks the padded sequences by:  \n",
    "- Displaying the integer representation  \n",
    "- Converting back to text (with `<SOS>`, `<EOS>`, and `<PAD>` tokens visible)  \n",
    "- Confirming proper padding and special token handling  \n",
    "\n",
    "*Ensures data is correctly structured before training.*  \n",
    "\n",
    "---\n",
    "\n",
    "**Key Points:**  \n",
    "✔ Validates padding length  \n",
    "✔ Verifies special token placement  \n",
    "✔ Confirms reversible encoding/decoding  \n",
    "\n",
    "*(Example shows first input-target pair from the dataset.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "T_DGCwIx5S4s",
    "outputId": "67c69288-fb78-496f-ad66-3a4227495399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4 5 6 7 8 9 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<SOS> hi , how are you doing ? <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(int_df[\"Input\"][0])\n",
    "# Print the first padded input sequence from the DataFrame (as integer IDs)\n",
    "\n",
    "t = \"\"\n",
    "# Initialize an empty string to reconstruct the text from integer IDs\n",
    "\n",
    "for intw in int_df[\"Input\"][0]:\n",
    "    # Iterate through each integer in the first input sequence\n",
    "    if intw != dictionary.word2int['<EOS>']:\n",
    "        # If the integer is NOT the End-of-Sequence token:\n",
    "        t += dictionary.int2word[intw] + \" \"\n",
    "        # Look up its corresponding word and add to string with a space\n",
    "    else:\n",
    "        # If the integer IS the End-of-Sequence token:\n",
    "        t += dictionary.int2word[intw]\n",
    "        # Add the token without a trailing space (end of reconstruction)\n",
    "\n",
    "t\n",
    "# Return/print the reconstructed text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "uEOY_WUp8BoE",
    "outputId": "28e5e3cc-cf01-4efc-995b-ffd684aad554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 10 11 12  5 13 14  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"<SOS> i'm fine . how about yourself ? <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(int_df[\"Target\"][0])\n",
    "# Print the first padded target sequence from the DataFrame (as integer IDs)\n",
    "\n",
    "t = \"\"\n",
    "# Initialize an empty string to reconstruct the text from integer IDs\n",
    "\n",
    "for intw in int_df[\"Target\"][0]:\n",
    "    # Iterate through each integer in the first target sequence\n",
    "\n",
    "    if intw != dictionary.word2int['<EOS>']:\n",
    "        # If current integer is NOT the End-of-Sequence token:\n",
    "        t += dictionary.int2word[intw] + \" \"\n",
    "        # Convert integer to word and add it with a trailing space\n",
    "\n",
    "    else:\n",
    "        # If current integer IS the End-of-Sequence token:\n",
    "        t += dictionary.int2word[intw]\n",
    "        # Add the <EOS> token without trailing space\n",
    "\n",
    "t\n",
    "# Output the reconstructed text string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5It2EC4MDgG"
   },
   "source": [
    "### **Data Conversion for Model Input**  \n",
    "\n",
    "This step transforms the DataFrame into a NumPy array with the required 3D structure for training:  \n",
    "\n",
    "- **Input Shape**: `(3725, 2, 24)`  \n",
    "  - `3725` conversation pairs  \n",
    "  - `2` columns (input and target sequences)  \n",
    "  - `24` tokens per sequence (padded length)  \n",
    "\n",
    "*Ready for train test split, tensor conversion and batch loading.*  \n",
    "\n",
    "---\n",
    "\n",
    "**Why This Matters:**  \n",
    "✔ Ensures compatibility with PyTorch's `DataLoader`  \n",
    "✔ Maintains sequence alignment between inputs and targets  \n",
    "✔ Verifies consistent dimensionality for the encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZIFMU4q6b9t",
    "outputId": "7629d276-1764-442b-8671-361c92ea9cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3725, 2)\n",
      "[array([0, 3, 4, 5, 6, 7, 8, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 2])\n",
      " array([ 0, 10, 11, 12,  5, 13, 14,  9,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  2])                                       ]\n",
      "(3725, 2, 24)\n",
      "[[ 0  3  4  5  6  7  8  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2]\n",
      " [ 0 10 11 12  5 13 14  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2]]\n"
     ]
    }
   ],
   "source": [
    "array = int_df.to_numpy()\n",
    "# Convert the DataFrame (with Input and Target columns) to a NumPy array\n",
    "# Resulting shape will be (num_samples, 2) where each sample has [Input, Target]\n",
    "\n",
    "print(array.shape)\n",
    "# Print the shape of the array (number of samples × 2 columns)\n",
    "\n",
    "print(array[0])\n",
    "# Print the first sample (both Input and Target sequences as arrays)\n",
    "\n",
    "new_array = np.stack([np.stack(row) for row in array])\n",
    "# Double stacking:\n",
    "# 1. Inner np.stack(row) converts each [Input, Target] pair into a stacked array\n",
    "# 2. Outer np.stack combines all samples into one 3D array\n",
    "# Final shape will be (num_samples, 2, sequence_length)\n",
    "\n",
    "print(new_array.shape)\n",
    "# Print the new 3D array shape (samples × input/target × sequence_length)\n",
    "\n",
    "print(new_array[0])\n",
    "# Print the first sample's stacked Input and Target sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WkvhGPTNrS9"
   },
   "source": [
    "### **Dataset Splitting for Training and Evaluation**  \n",
    "\n",
    "This code prepares the data for model development by:  \n",
    "\n",
    "1. **Splitting into Train/Test Sets**  \n",
    "   - **80% Training** (2980 samples) – For model learning  \n",
    "   - **20% Testing** (745 samples) – For final evaluation  \n",
    "   - Randomized shuffling (`shuffle=True`) with fixed `random_state=42` for reproducibility  \n",
    "\n",
    "2. **Output Verification**  \n",
    "   - Confirms the split maintains the 3D structure `(samples, input/target, sequence_length)`  \n",
    "   - Sample inspection shows preserved tokenization and padding  \n",
    "\n",
    "*Next Step: These arrays will be converted to PyTorch tensors for training.*  \n",
    "\n",
    "---\n",
    "\n",
    "**Key Details:**  \n",
    "✔ **Stratified Shuffling**: Ensures balanced distribution of conversation patterns  \n",
    "✔ **Reproducibility**: Fixed random seed guarantees consistent splits across runs  \n",
    "✔ **Integrity Check**: First sample shows proper `<SOS>`, `<EOS>`, and `<PAD>` token placement  \n",
    "\n",
    "*(Example displays token IDs from the first training pair.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "UJIgQPTXBKr8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Import the train-test split function from scikit-learn\n",
    "\n",
    "# Split the data (e.g., 80% train, 20% test)\n",
    "train_data, test_data = train_test_split(\n",
    "    new_array,          # The 3D numpy array containing all samples (shape: N×2×L)\n",
    "    test_size=0.2,      # 20% of data will be allocated to test set\n",
    "    shuffle=True,       # Shuffle the data before splitting\n",
    "    random_state=42     # Seed for reproducibility (ensures same split every time)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kGA0hidBRt1",
    "outputId": "3ec989e0-f376-4e8e-9f1b-220d22ec7a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2980, 2, 24) (745, 2, 24)\n",
      "[[   0  170   38  305   26 1377   12    1    1    1    1    1    1    1\n",
      "     1    1    1    1    1    1    1    1    1    2]\n",
      " [   0   27  819    9    1    1    1    1    1    1    1    1    1    1\n",
      "     1    1    1    1    1    1    1    1    1    2]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)\n",
    "# Prints the shapes of the training and test sets:\n",
    "# - train_data.shape -> (num_train_samples, 2, sequence_length)\n",
    "# - test_data.shape  -> (num_test_samples, 2, sequence_length)\n",
    "# Example output: (800, 2, 20) (200, 2, 20) for an 80/20 split of 1000 samples\n",
    "\n",
    "print(train_data[0])\n",
    "# Prints the first training sample, which contains:\n",
    "# - train_data[0][0] -> Padded Input sequence (with SOS/PAD/EOS tokens)\n",
    "# - train_data[0][1] -> Corresponding padded Target sequence\n",
    "# Example structure:\n",
    "# [\n",
    "#   [SOS_ID, word1_ID, word2_ID, ..., PAD_ID, EOS_ID],  # Input\n",
    "#   [SOS_ID, word1_ID, word2_ID, ..., PAD_ID, EOS_ID]   # Target\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjGyIsmIPDRN"
   },
   "source": [
    "### **PyTorch Dataset and DataLoader Setup**\n",
    "\n",
    "This section implements the data pipeline for model training:\n",
    "\n",
    "#### **Custom Dataset Class**\n",
    "- **Structure**:\n",
    "  - `x`: Input sequences (encoder inputs)\n",
    "  - `y`: Target sequences (decoder inputs/outputs)\n",
    "  - Converts NumPy arrays to PyTorch tensors automatically\n",
    "\n",
    "#### **Data Loading**\n",
    "- **Train/Test Split**:\n",
    "  - Training samples: 2980 (80%)\n",
    "  - Test samples: 745 (20%)\n",
    "- **DataLoader Configuration**:\n",
    "  - Batch size: 32 sequences\n",
    "  - Shuffling enabled for training set\n",
    "  - Automatic batching and memory management\n",
    "\n",
    "#### **Output Verification**\n",
    "- Batch shape: `(32, 24)` for both input and target\n",
    "- Maintains sequence length consistency\n",
    "- Preserves token IDs and padding\n",
    "\n",
    "*Ready for model training with proper batch iteration.*\n",
    "\n",
    "---\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "✔ Memory-efficient data loading  \n",
    "✔ Proper tensor conversion  \n",
    "✔ Batch dimension first (PyTorch convention)  \n",
    "✔ Shuffling for better training dynamics  \n",
    "\n",
    "*Next: These batches will feed directly into the encoder-decoder model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "I3ccfo_v-W40"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    # Custom PyTorch Dataset class to handle our sequence pairs\n",
    "\n",
    "    def __init__(self, array):\n",
    "        # Initialize dataset with the 3D numpy array\n",
    "        self.x = array[:, 0, :]  # Extract all input sequences (first dimension)\n",
    "        self.y = array[:, 1, :]  # Extract all target sequences (second dimension)\n",
    "        self.x = torch.from_numpy(self.x)  # Convert to PyTorch tensor\n",
    "        self.y = torch.from_numpy(self.y)  # Convert to PyTorch tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample (input-target pair) by index\n",
    "        return self.x[index], self.y[index]\n",
    "        # Returns tuple: (input_sequence, target_sequence)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns total number of samples\n",
    "        return len(self.x)\n",
    "        # Both x and y have same length so either works\n",
    "\n",
    "dataset = CustomDataset(new_array)\n",
    "# Create dataset instance using our prepared 3D array\n",
    "# new_array shape: (num_samples, 2, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dODXvoNDBOnk",
    "outputId": "367505bb-79cb-4fef-acff-023129326218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2980\n",
      "Test size: 745\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_data)\n",
    "# Initialize training dataset with the pre-split training data\n",
    "# - train_data comes from train_test_split() earlier\n",
    "# - CustomDataset will extract input/target pairs and convert to tensors\n",
    "\n",
    "test_dataset = CustomDataset(test_data)\n",
    "# Initialize test dataset with the pre-split test data\n",
    "# - Same processing as training data but with held-out samples\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")  # Should be ~2980 (80% of 3725)\n",
    "# Print number of samples in training set (approximately 80% of total data)\n",
    "# The exact number depends on your original dataset size\n",
    "\n",
    "print(f\"Test size: {len(test_dataset)}\")   # Should be ~745 (20% of 3725)\n",
    "# Print number of samples in test set (approximately 20% of total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NnkXzUhLByJl",
    "outputId": "9d01d8fc-855d-4836-b49c-310dd5d264c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 24]) torch.Size([32, 24])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "# Set the number of samples per training batch (common sizes: 32, 64, 128)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,          # Training dataset we created\n",
    "    batch_size=batch_size,  # Number of samples per batch\n",
    "    shuffle=True            # Shuffle samples every epoch (important for training)\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,           # Test dataset we created\n",
    "    batch_size=batch_size,  # Same batch size for consistency\n",
    "    shuffle=True            # Shuffling test can be useful for evaluation\n",
    ")\n",
    "\n",
    "# Get the first batch from the training dataloader\n",
    "batch_x, batch_y = next(iter(train_dataloader))\n",
    "# - iter() creates an iterator from the dataloader\n",
    "# - next() gets the first batch\n",
    "# - batch_x contains input sequences, batch_y contains target sequences\n",
    "\n",
    "print(batch_x.shape, batch_y.shape)\n",
    "# Print the shapes of the batched tensors:\n",
    "# - For batch_size=32 and max_sequence_length=20:\n",
    "#   Output: torch.Size([32, 20]) torch.Size([32, 20])\n",
    "# - First dimension is batch size, second is sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qv9f_Ew3Qaxc"
   },
   "source": [
    "## **Model Architecture Overview**\n",
    "\n",
    "This implements a basic Seq2Seq model for QA System functionality:\n",
    "\n",
    "#### **Core Components**\n",
    "1. **Encoder**:\n",
    "   - Embedding layer (vocab_size=2570, embedding_dim=128)\n",
    "   - 2-layer GRU (hidden_size=128) with dropout (p=0.2)\n",
    "2. **Attention**:\n",
    "   - Decoder Energy:   (FC) layer (hidden_size=128, hidden_size=128)\n",
    "   - ENcoder Energy:   (FC) layer (hidden_size=128, hidden_size=128)\n",
    "   - Energy: Tanh activation function on the sum of decoder energy and encoder energy\n",
    "   - Attention Scores: (FC) layer (hidden_size, 1, bias=False) on Energy\n",
    "   - Attention Weights: Softmax activation function on Attention Scores\n",
    "   - Context vector: BMM on attention weights and encoder outputs\n",
    "3. **Decoder**:\n",
    "   - Embedding layer (matching encoder dimensions)\n",
    "   - 2-layer GRU (hidden_size + embed_size, hidden_size) with dropout (p=0.2)\n",
    "   - Additional dropout layer (p=0.3)\n",
    "   - Fully connected output layer (hidden_size * 2 ->> vocab_size)\n",
    "\n",
    "\n",
    "#### **Design Choices**\n",
    "- Shared vocabulary size (2570 tokens)\n",
    "- Consistent hidden dimensions (128)\n",
    "- Dropout for both encoder (20%) and decoder (30%)\n",
    "- Batch-first tensor organization\n",
    "\n",
    "*This foundation enables basic conversation flow while maintaining extensibility for future improvements.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "duoXUasLCZmV"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super().__init__()  # Initialize parent class (nn.Module)\n",
    "\n",
    "        # Store architecture parameters\n",
    "        self.vocab_size  = vocab_size   # Size of vocabulary (number of unique tokens)\n",
    "        self.embed_size  = embed_size   # Dimension of word embeddings\n",
    "        self.hidden_size = hidden_size  # Dimension of GRU hidden states\n",
    "        self.num_layers  = num_layers   # Number of stacked GRU layers\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Auto-detect device\n",
    "\n",
    "        # Layer definitions\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        # Converts token indices to dense vectors of size embed_size\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.embed_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,  # Expects input as (batch, seq_len, features)\n",
    "            dropout=0.2       # Dropout between GRU layers (if num_layers > 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input shape: (batch_size, sequence_length)\n",
    "        # hidden shape: (num_layers, batch_size, hidden_size)\n",
    "\n",
    "        x = input  # Store input tokens\n",
    "        x = self.embedding(x)  # Convert to embeddings -> (batch_size, seq_len, embed_size)\n",
    "        x, hidden = self.gru(x, hidden)  # Process through GRU\n",
    "\n",
    "        # Returns:\n",
    "        # x - All hidden states (batch_size, seq_len, hidden_size)\n",
    "        # hidden - Final hidden state (num_layers, batch_size, hidden_size)\n",
    "        return x, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with zeros\n",
    "        hidden = torch.zeros(\n",
    "            self.num_layers,\n",
    "            batch_size,\n",
    "            self.hidden_size\n",
    "        ).to(self.device)  # Places on GPU if available\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "Yyx52owiSTL9"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Linear layers to transform decoder hidden state and encoder outputs\n",
    "        self.decoder_attn = nn.Linear(hidden_size, hidden_size)\n",
    "        self.encoder_attn = nn.Linear(hidden_size, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)  # To compute attention scores\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            decoder_hidden: (num_layers, batch_size, hidden_size) - current decoder hidden state\n",
    "            encoder_outputs: (batch_size, seq_len, hidden_size) - all encoder outputs\n",
    "\n",
    "        Returns:\n",
    "            context_vector: (batch_size, hidden_size)\n",
    "            attention_weights: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        # Use the last layer's hidden state (most relevant for attention)\n",
    "        # print(decoder_hidden.shape)                  [2, 32, hidden_size=128]\n",
    "        # print(decoder_hidden[-1].shape)              [32, hidden_size=128]\n",
    "        # print(decoder_hidden[-1].unsqueeze(1).shape) [32, 1, hidden_size=128]\n",
    "\n",
    "        decoder_hidden = decoder_hidden[-1].unsqueeze(1)  # (batch_size, 1, hidden_size)\n",
    "\n",
    "        # Transform decoder hidden state\n",
    "        decoder_energy = self.decoder_attn(decoder_hidden)  # (batch_size, 1, hidden_size)\n",
    "\n",
    "        # Transform encoder outputs\n",
    "        # print(decoder_energy.shape)  torch.Size([32, 1, 128])\n",
    "        # print(encoder_outputs.shape) torch.Size([32, 24, 128])\n",
    "\n",
    "        encoder_energy = self.encoder_attn(encoder_outputs)  # (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # print(encoder_energy.shape)  torch.Size([32, 24, 128])\n",
    "\n",
    "        # Combine energies and get attention scores\n",
    "        energy = torch.tanh(decoder_energy + encoder_energy)  # (batch_size, seq_len, hidden_size)\n",
    "        # print(energy.shape) torch.Size([32, 24, 128])\n",
    "        attention_scores = self.v(energy).squeeze(2)  # (batch_size, seq_len)\n",
    "        # print(attention_scores.shape) torch.Size([32, 24])\n",
    "\n",
    "        # Compute attention weights\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)  # (batch_size, seq_len)\n",
    "        # print(attention_weights.shape) torch.Size([32, 24])\n",
    "\n",
    "        # print(attention_weights.unsqueeze(1).shape) torch.Size([32, 1, 24])\n",
    "        # Compute context vector\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1),\n",
    "                                 encoder_outputs)\n",
    "        # print(context_vector.shape) torch.Size([32, 1, 128])\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "3H0CoJHeHoHN"
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.embed_size + self.hidden_size,  # Changed to accommodate context vector\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.drop_out = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(self.hidden_size * 2, self.vocab_size)  # Now takes hidden + context\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input shape: (batch_size, 1)\n",
    "        # hidden shape: (num_layers, batch_size, hidden_size)\n",
    "        # encoder_outputs shape: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        embedded = self.embedding(input)  # (batch_size, 1, embed_size)\n",
    "\n",
    "        # Calculate attention and context vector\n",
    "        context_vector = self.attention(hidden, encoder_outputs)\n",
    "        # context_vector -> torch.Size([32, 1, 128])\n",
    "\n",
    "        # Combine embedded input and context vector\n",
    "        gru_input = torch.cat((embedded, context_vector), dim=2)  # (batch_size, 1, embed_size + hidden_size)\n",
    "\n",
    "        # GRU processing\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        # print(output.shape) #torch.Size([32, 1, 128])\n",
    "\n",
    "        # Combine output and context for final prediction\n",
    "        output = output.squeeze(1)  # (batch_size, hidden_size)\n",
    "        # print(output.shape) # torch.Size([32, 128])\n",
    "\n",
    "        output_context = torch.cat((output, context_vector.squeeze(1)), dim=1)  # (batch_size, hidden_size * 2)\n",
    "\n",
    "        output = self.drop_out(output_context)\n",
    "        output = self.fc(output)  # (batch_size, vocab_size)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1AI7wd0IaX9",
    "outputId": "62cd4004-3112-4113-9e0d-ad9953eefd9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Architecture:\n",
      "EncoderRNN(\n",
      "  (embedding): Embedding(2570, 128)\n",
      "  (gru): GRU(128, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      ")\n",
      "\n",
      "Decoder with Attention Architecture:\n",
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(2570, 128)\n",
      "  (attention): Attention(\n",
      "    (decoder_attn): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (encoder_attn): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (v): Linear(in_features=128, out_features=1, bias=False)\n",
      "  )\n",
      "  (gru): GRU(256, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (drop_out): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=2570, bias=True)\n",
      ")\n",
      "\n",
      "Models will run on: cuda\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(dictionary.word2int)\n",
    "# Get total vocabulary size from dictionary (includes all words + special tokens)\n",
    "\n",
    "embed_size = 128\n",
    "# Dimension of word embeddings (typical range: 100-300)\n",
    "\n",
    "hidden_size = 128\n",
    "# Size of GRU hidden states (often same as embed_size for simplicity)\n",
    "# Note: For attention, hidden_size should match between encoder and decoder\n",
    "\n",
    "num_layers = 2\n",
    "# Number of stacked GRU layers (more layers = more complex patterns)\n",
    "\n",
    "# Initialize Encoder\n",
    "encoder_net = EncoderRNN(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_size=embed_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers\n",
    ")\n",
    "# Creates:\n",
    "# 1. Embedding layer (vocab_size -> embed_size)\n",
    "# 2. GRU layer (embed_size -> hidden_size)\n",
    "\n",
    "# Initialize Decoder with Attention\n",
    "decoder_net = AttnDecoderRNN(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_size=embed_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers\n",
    ")\n",
    "# Creates:\n",
    "# 1. Embedding layer (same as encoder)\n",
    "# 2. Attention mechanism\n",
    "# 3. GRU layer (now takes embed_size + hidden_size as input)\n",
    "# 4. Additional dropout\n",
    "# 5. Final linear layer (hidden_size * 2 -> vocab_size)\n",
    "\n",
    "# Print model architectures\n",
    "print(\"Encoder Architecture:\")\n",
    "print(encoder_net)\n",
    "print(\"\\nDecoder with Attention Architecture:\")\n",
    "print(decoder_net)\n",
    "\n",
    "# Verify device placement\n",
    "print(f\"\\nModels will run on: {encoder_net.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaZnF2g2RjSV"
   },
   "source": [
    "### **Model Forward Pass Verification**\n",
    "\n",
    "This test run validates the model's data flow and tensor shapes:\n",
    "\n",
    "#### **Key Operations**\n",
    "- **Device Setup**: Automatically uses GPU if available\n",
    "- **Encoder**:\n",
    "  - Input: `[32, 24]` (batch, seq_len)\n",
    "  - Output: `[32, 24, 128]` (sequence representations)\n",
    "- **Decoder**:\n",
    "  - Input: `[32, 23]` (teacher-forced, right-shifted)\n",
    "  - Output: `[736, 2570]` (flattened logits for loss calculation)\n",
    "\n",
    "#### **Shape Verification**\n",
    "✔ Maintains consistent hidden dimensions (128)  \n",
    "✔ Proper sequence length handling (24->23 for teacher forcing)  \n",
    "✔ Correct output reshaping for cross-entropy loss  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpYInVVxgkKh",
    "outputId": "c0510530-fb08-44f8-b50c-c39dd85498f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input: torch.Size([32, 24])\n",
      "Encoder hidden in: torch.Size([2, 32, 128])\n",
      "Encoder outputs: torch.Size([32, 24, 128])\n",
      "Encoder hidden out: torch.Size([2, 32, 128])\n",
      "\n",
      "Decoder input: torch.Size([32, 23])\n",
      "Decoder hidden in: torch.Size([2, 32, 128])\n",
      "Decoder outputs: torch.Size([32, 23, 2570])\n",
      "Decoder hidden out: torch.Size([2, 32, 128])\n",
      "\n",
      "Target: torch.Size([32, 23])\n",
      "Target reshaped: torch.Size([736])\n",
      "Decoder outputs reshaped: torch.Size([736, 2570])\n"
     ]
    }
   ],
   "source": [
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move models to device\n",
    "encoder_net = encoder_net.to(device)\n",
    "decoder_net = decoder_net.to(device)\n",
    "\n",
    "# Get a batch from dataloader\n",
    "batch_x, batch_y = next(iter(train_dataloader))\n",
    "batch_size = batch_x.shape[0]\n",
    "\n",
    "# --- ENCODER PASS ---\n",
    "encoder_input = batch_x.to(device)  # Shape: [batch_size, seq_len]\n",
    "print(f\"Encoder input: {encoder_input.shape}\")\n",
    "# Example: [32, 24] (batch of 32 sequences, each length 24)\n",
    "\n",
    "encoder_hidden = encoder_net.init_hidden(batch_size)  # Shape: [num_layers, batch_size, hidden_size]\n",
    "print(f\"Encoder hidden in: {encoder_hidden.shape}\")\n",
    "# Example: [2, 32, 128] (2 layers, 32 sequences, 128-dim hidden state)\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_net(encoder_input, encoder_hidden)\n",
    "print(f\"Encoder outputs: {encoder_outputs.shape}\")  # Shape: [batch_size, seq_len, hidden_size]\n",
    "# Example: [32, 24, 128] (all hidden states for each sequence position)\n",
    "print(f\"Encoder hidden out: {encoder_hidden.shape}\\n\")  # Shape same as input hidden\n",
    "# Example: [2, 32, 128] (final hidden state at each layer)\n",
    "\n",
    "# --- DECODER PASS WITH ATTENTION ---\n",
    "# Teacher forcing: feed previous target as next input (shifted by one)\n",
    "decoder_input = batch_y[:, :-1].to(device)  # Remove last token, Shape: [batch_size, seq_len-1]\n",
    "print(f\"Decoder input: {decoder_input.shape}\")\n",
    "# Example: [32, 23] (original seq_len=24, now 23 for teacher forcing)\n",
    "\n",
    "decoder_hidden = encoder_hidden  # Initialize with encoder's final hidden state\n",
    "print(f\"Decoder hidden in: {decoder_hidden.shape}\")  # Shape: [num_layers, batch_size, hidden_size]\n",
    "# Example: [2, 32, 128]\n",
    "\n",
    "# Initialize tensor to store decoder outputs and attention weights\n",
    "decoder_outputs = torch.zeros(\n",
    "    batch_size,\n",
    "    decoder_input.size(1),\n",
    "    decoder_net.vocab_size\n",
    ").to(device)\n",
    "\n",
    "# Process each timestep sequentially\n",
    "for t in range(decoder_input.size(1)):\n",
    "    # Get current timestep input (all batch elements at position t)\n",
    "    decoder_step_input = decoder_input[:, t] # torch.Size([32])\n",
    "    decoder_step_input = decoder_step_input.unsqueeze(1)  # torch.Size([32, 1])\n",
    "\n",
    "    # Forward pass with attention\n",
    "    decoder_output, decoder_hidden = decoder_net(\n",
    "        decoder_step_input,\n",
    "        decoder_hidden,\n",
    "        encoder_outputs\n",
    "    )\n",
    "\n",
    "    # Store outputs and attention weights\n",
    "    decoder_outputs[:, t, :] = decoder_output\n",
    "\n",
    "print(f\"Decoder outputs: {decoder_outputs.shape}\")  # Shape: [batch_size, seq_len-1, vocab_size]\n",
    "# Example: [32, 23, 2570]\n",
    "print(f\"Decoder hidden out: {decoder_hidden.shape}\\n\")  # Shape same as input hidden\n",
    "# Example: [2, 32, 128]\n",
    "\n",
    "# --- TARGETS FOR LOSS CALCULATION ---\n",
    "target = batch_y[:, 1:].to(device)  # Remove first token (shifted right), Shape: [batch_size, seq_len-1]\n",
    "print(f\"Target: {target.shape}\")\n",
    "# Example: [32, 23] (compare with decoder output)\n",
    "print(f\"Target reshaped: {target.reshape(-1,).shape}\")  # Flattened for loss: [batch_size*(seq_len-1)]\n",
    "# Example: [736] (32*23=736)\n",
    "\n",
    "# Reshape decoder outputs for loss calculation\n",
    "decoder_outputs = decoder_outputs.reshape(-1, decoder_net.vocab_size)\n",
    "print(f\"Decoder outputs reshaped: {decoder_outputs.shape}\")\n",
    "# Example: [736, 2570] (matches target reshaped length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQMAaJRpSW-t"
   },
   "source": [
    "## **Seq2Seq Model Training Implementation**\n",
    "\n",
    "This section implements the complete training loop for the encoder-decoder chatbot (QA System) model with the following key components:\n",
    "\n",
    "### **Training Configuration**\n",
    "- **Optimizers**:\n",
    "  - Separate Adam optimizers for encoder/decoder (lr=0.001)\n",
    "  - Weight decay (L2 regularization) of 1e-5\n",
    "- **Loss Function**:\n",
    "  - CrossEntropyLoss with:\n",
    "    - Padding index ignored (`<PAD>`)\n",
    "    - Label smoothing (0.1) for regularization\n",
    "- **Training Protocol**:\n",
    "  - Batch processing (size=32)\n",
    "  - Gradient clipping (max_norm=5)\n",
    "  - Early stopping (patience=3)\n",
    "  - Best model checkpointing\n",
    "\n",
    "### **Key Training Steps**\n",
    "1. **Forward Pass**:\n",
    "   - Encoder processes input sequence -> hidden states\n",
    "   - Decoder uses teacher forcing (shifted targets)\n",
    "   - Target reshaped for loss calculation\n",
    "\n",
    "2. **Backward Pass**:\n",
    "   - Gradient computation via backpropagation\n",
    "   - Gradient clipping for stability\n",
    "   - Parameter updates\n",
    "\n",
    "3. **Validation**:\n",
    "   - Full inference mode (no gradients)\n",
    "   - Identical forward pass as training\n",
    "   - Tracks best validation loss\n",
    "\n",
    "### **Training Monitoring**\n",
    "- Per-epoch metrics:\n",
    "  - Training loss (average per batch)\n",
    "  - Validation loss\n",
    "  - Early stopping counter\n",
    "- Progress tracking via tqdm\n",
    "- Automatic device management (GPU/CPU)\n",
    "\n",
    "### **Implementation Notes**\n",
    "- Teacher forcing: Uses shifted targets (y[:, :-1]) as decoder input\n",
    "- Target reshaping: Flattens for cross-entropy calculation\n",
    "- Memory efficiency: Processes one batch at a time\n",
    "- Reproducibility: Deterministic operations where possible\n",
    "\n",
    "*Output: Returns training/validation loss histories for analysis.*\n",
    "\n",
    "---\n",
    "\n",
    "**Visualization Ready**:\n",
    "The returned `total_train_losses` and `total_val_losses` arrays can be directly plotted to analyze learning curves and model convergence.\n",
    "\n",
    "This implementation balances computational efficiency with training stability while maintaining clear separation between training and validation phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "fcX9zXAoWgya"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def train(encoder_net, decoder_net, train_data, test_data, dictionary,\n",
    "          device, epochs=20, lr=0.01, patience = 3):\n",
    "    # Set optimizers\n",
    "    encoder_optimizer = torch.optim.Adam(params=encoder_net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    decoder_optimizer = torch.optim.Adam(params=decoder_net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    # Set criterion\n",
    "    pad_idx = dictionary.word2int[\"<PAD>\"]\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx, label_smoothing=0.1)\n",
    "\n",
    "    # Training tracking variables\n",
    "    total_train_losses = []\n",
    "    total_val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    epochs_no_improve = 0\n",
    "    best_encoder_state = None\n",
    "    best_decoder_state = None\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Training phase\n",
    "        encoder_net.train()\n",
    "        decoder_net.train()\n",
    "        train_losses, val_losses = 0, 0\n",
    "        train_batches, val_batches = 0, 0\n",
    "\n",
    "        for X, y in train_data:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            batch_size = X.size(0)\n",
    "\n",
    "            # Reset gradients\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            # Encoder forward pass\n",
    "            encoder_hidden = encoder_net.init_hidden(batch_size)\n",
    "            encoder_outputs, encoder_hidden = encoder_net(X, encoder_hidden)\n",
    "\n",
    "            # Prepare decoder inputs\n",
    "            decoder_input = y[:, :-1]\n",
    "            decoder_target = y[:, 1:].reshape(-1)\n",
    "\n",
    "            # Initialize decoder outputs\n",
    "            decoder_outputs = torch.zeros(\n",
    "                batch_size,\n",
    "                decoder_input.size(1),\n",
    "                decoder_net.vocab_size\n",
    "            ).to(device)\n",
    "\n",
    "            # Initialize decoder hidden state\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            # Decoder forward pass with attention\n",
    "            for t in range(decoder_input.size(1)):\n",
    "                decoder_step_input = decoder_input[:, t].unsqueeze(1)\n",
    "                step_output, decoder_hidden = decoder_net(\n",
    "                    decoder_step_input,\n",
    "                    decoder_hidden,\n",
    "                    encoder_outputs\n",
    "                )\n",
    "                decoder_outputs[:, t, :] = step_output\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(\n",
    "                decoder_outputs.reshape(-1, decoder_net.vocab_size),\n",
    "                decoder_target\n",
    "            )\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(encoder_net.parameters(), 5)\n",
    "            torch.nn.utils.clip_grad_norm_(decoder_net.parameters(), 5)\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            train_losses += loss.item()\n",
    "            train_batches += 1\n",
    "\n",
    "        # Validation phase\n",
    "        encoder_net.eval()\n",
    "        decoder_net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_data:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                batch_size = X.size(0)\n",
    "\n",
    "                # Encoder forward pass\n",
    "                encoder_hidden = encoder_net.init_hidden(batch_size)\n",
    "                encoder_outputs, encoder_hidden = encoder_net(X, encoder_hidden)\n",
    "\n",
    "                # Prepare decoder inputs\n",
    "                decoder_input = y[:, :-1]\n",
    "                decoder_target = y[:, 1:].reshape(-1)\n",
    "\n",
    "                # Initialize decoder outputs\n",
    "                decoder_outputs = torch.zeros(\n",
    "                    batch_size,\n",
    "                    decoder_input.size(1),\n",
    "                    decoder_net.vocab_size\n",
    "                ).to(device)\n",
    "\n",
    "                # Initialize decoder hidden state\n",
    "                decoder_hidden = encoder_hidden\n",
    "\n",
    "                # Decoder forward pass with attention\n",
    "                for t in range(decoder_input.size(1)):\n",
    "                    decoder_step_input = decoder_input[:, t].unsqueeze(1)\n",
    "                    step_output, decoder_hidden = decoder_net(\n",
    "                        decoder_step_input,\n",
    "                        decoder_hidden,\n",
    "                        encoder_outputs\n",
    "                    )\n",
    "                    decoder_outputs[:, t, :] = step_output\n",
    "\n",
    "                # Calculate validation loss\n",
    "                val_loss = criterion(\n",
    "                    decoder_outputs.reshape(-1, decoder_net.vocab_size),\n",
    "                    decoder_target\n",
    "                )\n",
    "\n",
    "                val_losses += val_loss.item()\n",
    "                val_batches += 1\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        avg_train_loss = train_losses / train_batches\n",
    "        avg_val_loss = val_losses / val_batches\n",
    "        total_train_losses.append(avg_train_loss)\n",
    "        total_val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}\")\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_encoder_state = encoder_net.state_dict()\n",
    "            best_decoder_state = decoder_net.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping after {patience} epochs without improvement\")\n",
    "                encoder_net.load_state_dict(best_encoder_state)\n",
    "                decoder_net.load_state_dict(best_decoder_state)\n",
    "                break\n",
    "\n",
    "    return total_train_losses, total_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431,
     "referenced_widgets": [
      "01fc16b46a3345cf9c2c999cce35148a",
      "33aca096adce48788041aaf3dc629561",
      "d0e551577dfe445e8373a139d500e572",
      "ba2c8fd073bb4557848d319a1f580c8f",
      "2cc082a638974394a73cd14387216317",
      "6f194e50f52e40c3ace4fbea5eafa8ed",
      "21fbf60bc2394216b6cebb5553a95a89",
      "7820652370494e9ea83b478213a7cedc",
      "5516b4c4ec7b4269b465c9a0a4a2daa3",
      "cd32adf91b7348a28099c09c6a8866b8",
      "c2e4cabed1d74e82a2862b8b8b7ee78f"
     ]
    },
    "id": "vDkj9n4aaJmT",
    "outputId": "5c03b259-5db3-45ba-8411-eecccd7a30f6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fc16b46a3345cf9c2c999cce35148a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20 | Train Loss: 5.6606 | Val Loss: 5.2981\n",
      "Validation loss improved from inf to 5.2981\n",
      "Epoch: 2/20 | Train Loss: 5.1923 | Val Loss: 5.0449\n",
      "Validation loss improved from 5.2981 to 5.0449\n",
      "Epoch: 3/20 | Train Loss: 4.9142 | Val Loss: 4.8466\n",
      "Validation loss improved from 5.0449 to 4.8466\n",
      "Epoch: 4/20 | Train Loss: 4.7036 | Val Loss: 4.7085\n",
      "Validation loss improved from 4.8466 to 4.7085\n",
      "Epoch: 5/20 | Train Loss: 4.5166 | Val Loss: 4.6656\n",
      "Validation loss improved from 4.7085 to 4.6656\n",
      "Epoch: 6/20 | Train Loss: 4.3750 | Val Loss: 4.6052\n",
      "Validation loss improved from 4.6656 to 4.6052\n",
      "Epoch: 7/20 | Train Loss: 4.2142 | Val Loss: 4.5669\n",
      "Validation loss improved from 4.6052 to 4.5669\n",
      "Epoch: 8/20 | Train Loss: 4.0543 | Val Loss: 4.5380\n",
      "Validation loss improved from 4.5669 to 4.5380\n",
      "Epoch: 9/20 | Train Loss: 3.9193 | Val Loss: 4.5737\n",
      "Epoch: 10/20 | Train Loss: 3.7783 | Val Loss: 4.5766\n",
      "Epoch: 11/20 | Train Loss: 3.6283 | Val Loss: 4.5803\n",
      "Epoch: 12/20 | Train Loss: 3.4892 | Val Loss: 4.6141\n",
      "Epoch: 13/20 | Train Loss: 3.3620 | Val Loss: 4.6217\n",
      "Early stopping after 5 epochs without improvement\n"
     ]
    }
   ],
   "source": [
    "total_train_losses, total_val_losses = train(\n",
    "    encoder_net=encoder_net,\n",
    "    decoder_net=decoder_net,  # Now using attention-based decoder\n",
    "    train_data=train_dataloader,\n",
    "    test_data=test_dataloader,\n",
    "    dictionary=dictionary,\n",
    "    device=device,\n",
    "    epochs=20,\n",
    "    lr=0.001,\n",
    "    patience = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "aYLr-VfvaRwR",
    "outputId": "cdf878b3-2794-430e-f8f1-a682b5074fb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7d9024d3dc10>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # Import the matplotlib plotting library\n",
    "\n",
    "plt.figure(figsize=(15, 7))       # Create a new figure with size 15x7 inches\n",
    "\n",
    "plt.plot(total_train_losses, 'r--' ,label=\"Train Loss\")\n",
    "# Plot training losses with red dashed line and label\n",
    "plt.plot(total_val_losses, 'b--',label=\"Validation Loss\")\n",
    "# Plot validation losses with blue dashed line and label\n",
    "plt.legend()\n",
    "# Display the legend to identify plotted lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XxEuuoYUBQM"
   },
   "source": [
    "## **Text Generation Function**\n",
    "\n",
    "This function implements the chatbot's response generation pipeline:\n",
    "\n",
    "#### **Core Process Flow**\n",
    "1. **Input Preprocessing**:\n",
    "   - Converts input to lowercase\n",
    "   - Adds `<SOS>` and `<EOS>` tokens\n",
    "   - Translates words to integer IDs using vocabulary\n",
    "\n",
    "2. **Encoder Phase**:\n",
    "   - Processes input sequence into context vectors\n",
    "   - Generates initial hidden state for decoder\n",
    "\n",
    "3. **Decoder Phase**:\n",
    "   - Starts with `<SOS>` token\n",
    "   - Generates words sequentially using:\n",
    "     - Greedy search (`top_k=1`) or\n",
    "     - Top-K sampling (`top_k>1`) with temperature\n",
    "   - Stops at `<EOS>` or 50-word limit\n",
    "\n",
    "4. **Postprocessing**:\n",
    "   - Cleans punctuation spacing\n",
    "   - Returns natural-looking text\n",
    "\n",
    "#### **Key Parameters**\n",
    "- `top_k`: Controls diversity:\n",
    "  - `1` = deterministic/greedy\n",
    "  - `>1` = random sampling from top K options\n",
    "- `max_length`: Prevents infinite loops (50 words)\n",
    "\n",
    "#### **Example Output**\n",
    "Shows the probabilistic nature of generation - responses vary based on sampling.\n",
    "\n",
    "#### **Implementation Notes**\n",
    "- Maintains proper device placement (GPU/CPU)\n",
    "- Handles edge cases (OOV words via dictionary)\n",
    "- Includes basic punctuation formatting\n",
    "- Uses teacher-forcing during training only\n",
    "\n",
    "This function serves as the interface between the trained model and end-users, converting model outputs into human-readable responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "JZ3Yl5h3nPwB"
   },
   "outputs": [],
   "source": [
    "def generate_text(input_text, top_k, encoder_net, decoder_net, dictionary):\n",
    "    input_text = input_text.lower()\n",
    "    list_of_words = input_text.split()\n",
    "    list_of_words = [\"<SOS>\"] + list_of_words + [\"<EOS>\"]\n",
    "    int_list_of_words = []\n",
    "\n",
    "    for word in list_of_words:\n",
    "        int_list_of_words.append(dictionary.word2int[word])\n",
    "\n",
    "    encoder_input = torch.tensor(int_list_of_words).reshape(1, -1).to(device)\n",
    "    encoder_init_hidden = encoder_net.init_hidden(batch_size=1)\n",
    "\n",
    "    # Get encoder outputs (all hidden states)\n",
    "    encoder_outputs, encoder_hidden_out = encoder_net(encoder_input, encoder_init_hidden)\n",
    "\n",
    "    sos_tag = dictionary.word2int[\"<SOS>\"]\n",
    "    eos_tag = dictionary.word2int[\"<EOS>\"]\n",
    "\n",
    "    decoder_input = torch.full((1, 1), sos_tag).to(device)\n",
    "    decoder_hidden = encoder_hidden_out\n",
    "    generated_words = []\n",
    "    generate = True\n",
    "\n",
    "    while generate:\n",
    "        # Forward pass with attention\n",
    "        decoder_output, decoder_hidden = decoder_net(\n",
    "            decoder_input,\n",
    "            decoder_hidden,\n",
    "            encoder_outputs\n",
    "        )\n",
    "\n",
    "        p = torch.softmax(decoder_output, dim=1).data\n",
    "        p = p.to(device)\n",
    "\n",
    "        if top_k != 1:\n",
    "            if top_k is None:\n",
    "                top_ch = np.arange(len(dictionary))\n",
    "            else:\n",
    "                p, top_ch = p.topk(top_k)\n",
    "                top_ch = top_ch.cpu().numpy().squeeze()\n",
    "\n",
    "            p = p.cpu().numpy().squeeze()\n",
    "            next_word_idx = np.random.choice(top_ch, p=p/p.sum())\n",
    "        else:\n",
    "            next_word_idx = p.argmax(dim=1).cpu().numpy().squeeze().item()\n",
    "\n",
    "        next_word = dictionary.int2word[next_word_idx]\n",
    "\n",
    "        if next_word == \"<EOS>\" or len(generated_words) > 50:\n",
    "            generate = False\n",
    "        elif next_word != \"<SOS>\":\n",
    "            generated_words.append(next_word)\n",
    "\n",
    "        decoder_input = torch.full((1, 1), next_word_idx).to(device)\n",
    "\n",
    "    generated_text = \" \".join(generated_words)\n",
    "    generated_text = generated_text.replace(\" ,\", \",\")\n",
    "    generated_text = generated_text.replace(\" .\", \".\")\n",
    "    generated_text = generated_text.replace(\" ?\", \"?\")\n",
    "    generated_text = generated_text.replace(\" !\", \"!\")\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8QCiNlUq1Uq",
    "outputId": "9fd4cdc9-41f7-49f1-b61e-01dda5d92469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: i'm not sure. i'm sorry about it. i'm sorry. i think i have to go out. i'm not sure. i'm not going to go to the bathroom. i think i'll order. i don't know, i'm not going to see a movie movie.\n"
     ]
    }
   ],
   "source": [
    "text = \"hi , how are you doing ?\"\n",
    "generated_text = generate_text(\n",
    "    text,\n",
    "    top_k=3,\n",
    "    encoder_net=encoder_net,\n",
    "    decoder_net=decoder_net,  # Now using attention decoder\n",
    "    dictionary=dictionary\n",
    ")\n",
    "\n",
    "print(\"Generated:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "r1HZ4BmPygkT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
