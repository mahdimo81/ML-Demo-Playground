{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading and Extracting the Cornell Movie-Dialogs Corpus\n",
        "This code downloads a dataset from Kaggle and copies it to the current working directory for easier access.\n",
        "\n",
        "#### Key Steps:\n",
        "1. **KaggleHub Download**:\n",
        "   - Uses `kagglehub.dataset_download()` to fetch the `\"rajathmc/cornell-moviedialog-corpus\"` dataset.\n",
        "   - The downloaded dataset's path is stored in `path` and printed for verification.\n",
        "\n",
        "2. **Local Directory Setup**:\n",
        "   - Imports `shutil` and `os` to handle file operations.\n",
        "   - Sets `source_path` to the downloaded dataset location.\n",
        "   - Defines `destination_path` as the current working directory (via `os.getcwd()`).\n",
        "\n",
        "3. **Copying Files**:\n",
        "   - Uses `shutil.copytree()` to recursively copy the dataset to a new folder named `\"cornell-moviedialog-corpus\"` in the current directory.\n",
        "   - Prints the destination path for confirmation.\n",
        "\n",
        "#### Notes:\n",
        "- **Prerequisites**:\n",
        "  - Requires the `kagglehub` package installed (`pip install kagglehub`).\n",
        "  - Ensure Kaggle credentials are configured if the dataset is private.\n",
        "- **Output**:\n",
        "  - The dataset files will be available in `./cornell-moviedialog-corpus/`."
      ],
      "metadata": {
        "id": "7Wv7cHECizPz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcXD6hZ96Mq2",
        "outputId": "f0ca65c9-4048-4b08-837a-400d48e3182e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/cornell-moviedialog-corpus\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rajathmc/cornell-moviedialog-corpus\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THlk_RUt7UNf",
        "outputId": "674c06e6-b21a-4ee9-ffd2-185a4c11ff98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset copied to: /content/cornell-moviedialog-corpus\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Source path (where the dataset was downloaded)\n",
        "source_path = path\n",
        "\n",
        "# Destination path (current working directory)\n",
        "destination_path = os.getcwd()  # Gets the current working directory\n",
        "\n",
        "# Copy all contents from source to destination\n",
        "shutil.copytree(source_path, os.path.join(destination_path, \"cornell-moviedialog-corpus\"))\n",
        "\n",
        "print(f\"Dataset copied to: {os.path.join(destination_path, 'cornell-moviedialog-corpus')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the Cornell Movie-Dialogs Corpus\n",
        "Following code processes the movie conversations and lines from the Cornell Movie-Dialogs Corpus to extract question-answer (QA) pairs for dialogue modeling.\n",
        "\n",
        "#### Key Steps:\n",
        "\n",
        "1. **File Paths and Initialization**:\n",
        "   - `corpus_movie_conv`: Path to the conversations file (`movie_conversations.txt`).\n",
        "   - `corpus_movie_lines`: Path to the dialogue lines file (`movie_lines.txt`).\n",
        "   - `max_len`: Maximum allowed length of a sentence (25 words).\n",
        "\n",
        "2. **Reading Data**:\n",
        "   - Conversations (`conv`) and dialogue lines (`lines`) are loaded into memory.\n",
        "   - The lines file uses `latin-1` encoding to handle special characters.\n",
        "\n",
        "3. **Building a Lines Dictionary**:\n",
        "   - `lines_dict` maps each line ID (e.g., `L194`) to its corresponding text by splitting on `\" +++$+++ \"`.\n",
        "   - Example: `lines_dict[\"L194\"]` → \"First dialogue line text...\"\n",
        "\n",
        "4. **Text Preprocessing**:\n",
        "   - `remove_punc()` removes punctuation and converts text to lowercase for uniformity.\n",
        "   - Example: `\"Hello, World!\"` → `\"hello world\"`.\n",
        "\n",
        "5. **Extracting QA Pairs**:\n",
        "   - For each conversation in `conv`, the line IDs are extracted (e.g., `['L194', 'L195', ...]`).\n",
        "   - Adjacent lines are paired as questions and answers:\n",
        "     - `first`: The current line (preprocessed).\n",
        "     - `second`: The next line (preprocessed).\n",
        "   - Each pair is truncated to `max_len` words and added to `pairs`.\n",
        "\n",
        "6. **Output**:\n",
        "   - The total number of QA pairs (`221616`) is printed, showing the scale of the dataset.\n",
        "\n",
        "#### Example QA Pair:\n",
        "# Input:\n",
        "[\"hello how are you\", \"i am fine thanks\"]\n",
        "\n",
        "# Preprocessed (max_len=3):\n",
        "[[\"hello\", \"how\", \"are\"], [\"i\", \"am\", \"fine\"]]"
      ],
      "metadata": {
        "id": "LDQxrydqjzHK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBOXcSRf_9Bo"
      },
      "outputs": [],
      "source": [
        "# Paths to the movie conversation and lines files\n",
        "corpus_movie_conv = \"cornell-moviedialog-corpus/movie_conversations.txt\"\n",
        "corpus_movie_lines = \"cornell-moviedialog-corpus/movie_lines.txt\"\n",
        "\n",
        "# Maximum length for sequences\n",
        "max_len = 25\n",
        "\n",
        "# Read conversation data\n",
        "with open(corpus_movie_conv, \"r\") as c:\n",
        "    conv = c.readlines()\n",
        "\n",
        "# Read movie lines with Latin-1 encoding\n",
        "with open(corpus_movie_lines, \"r\", encoding='latin-1') as l:\n",
        "    lines = l.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ72pyuNBPUQ",
        "outputId": "f8c69223-ba7b-4535-bb4a-d855643dc14c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n',\n",
              " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n',\n",
              " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n',\n",
              " 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n',\n",
              " \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\",\n",
              " 'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n',\n",
              " \"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\",\n",
              " 'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n',\n",
              " 'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n',\n",
              " 'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "lines[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aPEJu68CTOq"
      },
      "outputs": [],
      "source": [
        "lines_dict = {}\n",
        "for line in lines:\n",
        "  objects = line.split(\" +++$+++ \")\n",
        "  lines_dict[objects[0]] = objects[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU_-YoGTDEFg"
      },
      "outputs": [],
      "source": [
        "def remove_punc(string):\n",
        "    # Define punctuation characters to remove\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    no_punc = \"\"\n",
        "\n",
        "    # Iterate through each character and remove punctuation\n",
        "    for char in string:\n",
        "        if char not in punctuations:\n",
        "            no_punc += char\n",
        "\n",
        "    # Return the cleaned string in lowercase\n",
        "    return no_punc.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw5Pg9ndEn74",
        "outputId": "64e44198-024c-47c0-9096-acb95e716f76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['L194', 'L195', 'L196', 'L197']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "eval(conv[0].split(\" +++$+++ \")[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4zBLgENFOK3"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store conversation pairs\n",
        "pairs = []\n",
        "\n",
        "# Iterate through each conversation in the conversation data\n",
        "for con in conv:\n",
        "    # Extract the list of line IDs involved in the conversation\n",
        "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
        "\n",
        "    # Iterate through each line ID to form question-answer pairs\n",
        "    for i in range(len(ids)):\n",
        "        qa_pairs = []\n",
        "\n",
        "        # Skip the last line as it doesn't have a subsequent line to pair with\n",
        "        if i == len(ids) - 1:\n",
        "            break\n",
        "\n",
        "        # Get and clean the current line and the next line\n",
        "        first = remove_punc(lines_dict[ids[i]].strip())\n",
        "        second = remove_punc(lines_dict[ids[i + 1]].strip())\n",
        "\n",
        "        # Split the lines into words and limit to max_len words\n",
        "        qa_pairs.append(first.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "\n",
        "        # Add the question-answer pair to the pairs list\n",
        "        pairs.append(qa_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVY1yd4UI5sw",
        "outputId": "ab9aa5c3-9bf1-47fb-c81c-b29a97175c31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221616"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Vocabulary from Dialogue Pairs\n",
        "Following code creates a vocabulary mapping for the dialogue pairs by analyzing word frequencies and assigning special tokens.\n",
        "\n",
        "#### Key Steps:\n",
        "\n",
        "1. **Word Frequency Counting**:\n",
        "   - Uses `Counter` from `collections` to count occurrences of each word across all question-answer pairs.\n",
        "   - Iterates through `pairs`, updating counts for words in both questions (`pair[0]`) and answers (`pair[1]`).\n",
        "\n",
        "2. **Vocabulary Filtering**:\n",
        "   - Keeps only words that appear more than `min_word_freq` (5) times to filter out rare words.\n",
        "   - This helps reduce vocabulary size and eliminates noise from infrequent words.\n",
        "\n",
        "3. **Word-to-Index Mapping**:\n",
        "   - Creates `word_map` dictionary where each word is assigned a unique integer:\n",
        "     - Frequent words are numbered sequentially starting from 1\n",
        "     - Adds four special tokens:\n",
        "       - `<pad>` → 0 (for padding shorter sequences)\n",
        "       - `<unk>` → for unknown/rare words\n",
        "       - `<start>` → to mark beginning of sequences\n",
        "       - `<end>` → to mark end of sequences\n",
        "\n",
        "4. **Vocabulary Persistence**:\n",
        "   - Saves the `word_map` dictionary as a JSON file (`WORDMAP_corpus.json`) for later use in model training.\n",
        "\n",
        "#### Example Output:\n",
        "{\n",
        "  \"`<pad>`\": 0,\n",
        "  \"hello\": 1,\n",
        "  \"how\": 2,\n",
        "  ...\n",
        "  \"`<unk>`\": 2532,\n",
        "  \"`<start>`\": 2533,\n",
        "  \"`<end>`\": 2534\n",
        "}"
      ],
      "metadata": {
        "id": "4IRp76v5k0_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auv1vfsQJTCv",
        "outputId": "dbd94011-6438-45ec-e3d4-d8d2f347c77c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'can': 14103,\n",
              "         'we': 25912,\n",
              "         'make': 5821,\n",
              "         'this': 30502,\n",
              "         'quick': 310,\n",
              "         'roxanne': 1,\n",
              "         'korrine': 1,\n",
              "         'and': 52131,\n",
              "         'andrew': 49,\n",
              "         'barrett': 20,\n",
              "         'are': 21713,\n",
              "         'having': 1081,\n",
              "         'an': 8827,\n",
              "         'incredibly': 49,\n",
              "         'horrendous': 4,\n",
              "         'public': 306,\n",
              "         'break': 799,\n",
              "         'up': 14316,\n",
              "         'on': 23908,\n",
              "         'the': 120903,\n",
              "         'quad': 2,\n",
              "         'again': 2807,\n",
              "         'well': 16263,\n",
              "         'i': 137639,\n",
              "         'thought': 4202,\n",
              "         'wed': 541,\n",
              "         'start': 1459,\n",
              "         'with': 21394,\n",
              "         'pronunciation': 2,\n",
              "         'if': 16727,\n",
              "         'thats': 14742,\n",
              "         'okay': 5946,\n",
              "         'you': 169695,\n",
              "         'not': 26496,\n",
              "         'hacking': 18,\n",
              "         'gagging': 9,\n",
              "         'spitting': 15,\n",
              "         'part': 1260,\n",
              "         'please': 3258,\n",
              "         'then': 7532,\n",
              "         'how': 14001,\n",
              "         'bout': 393,\n",
              "         'try': 1998,\n",
              "         'out': 16100,\n",
              "         'some': 8153,\n",
              "         'french': 306,\n",
              "         'cuisine': 11,\n",
              "         'saturday': 184,\n",
              "         'night': 3489,\n",
              "         'youre': 18180,\n",
              "         'asking': 691,\n",
              "         'me': 41056,\n",
              "         'so': 16697,\n",
              "         'cute': 259,\n",
              "         'whats': 6573,\n",
              "         'your': 26791,\n",
              "         'name': 2839,\n",
              "         'forget': 1316,\n",
              "         'it': 60011,\n",
              "         'no': 27124,\n",
              "         'its': 24458,\n",
              "         'my': 26250,\n",
              "         'fault': 456,\n",
              "         'didnt': 8043,\n",
              "         'have': 27982,\n",
              "         'a': 89110,\n",
              "         'proper': 126,\n",
              "         'introduction': 19,\n",
              "         'cameron': 34,\n",
              "         'thing': 4976,\n",
              "         'is': 37374,\n",
              "         'im': 30345,\n",
              "         'at': 13283,\n",
              "         'mercy': 62,\n",
              "         'of': 47393,\n",
              "         'particularly': 102,\n",
              "         'hideous': 19,\n",
              "         'breed': 31,\n",
              "         'loser': 113,\n",
              "         'sister': 585,\n",
              "         'cant': 8757,\n",
              "         'date': 507,\n",
              "         'until': 1236,\n",
              "         'she': 11346,\n",
              "         'does': 3336,\n",
              "         'seems': 751,\n",
              "         'like': 19130,\n",
              "         'could': 7311,\n",
              "         'get': 17562,\n",
              "         'easy': 1089,\n",
              "         'enough': 2295,\n",
              "         'why': 12219,\n",
              "         'unsolved': 13,\n",
              "         'mystery': 84,\n",
              "         'used': 1767,\n",
              "         'to': 100667,\n",
              "         'be': 24193,\n",
              "         'really': 6196,\n",
              "         'popular': 94,\n",
              "         'when': 9007,\n",
              "         'started': 709,\n",
              "         'high': 749,\n",
              "         'school': 1358,\n",
              "         'was': 25287,\n",
              "         'just': 20634,\n",
              "         'got': 14745,\n",
              "         'sick': 852,\n",
              "         'or': 7778,\n",
              "         'something': 6827,\n",
              "         'shame': 149,\n",
              "         'gosh': 103,\n",
              "         'only': 5044,\n",
              "         'find': 3549,\n",
              "         'kat': 39,\n",
              "         'boyfriend': 253,\n",
              "         'let': 4589,\n",
              "         'see': 10288,\n",
              "         'what': 44771,\n",
              "         'do': 30487,\n",
              "         'cesc': 1,\n",
              "         'ma': 309,\n",
              "         'tete': 1,\n",
              "         'head': 1438,\n",
              "         'right': 12793,\n",
              "         'ready': 1076,\n",
              "         'for': 29046,\n",
              "         'quiz': 9,\n",
              "         'dont': 33134,\n",
              "         'want': 14744,\n",
              "         'know': 29121,\n",
              "         'say': 8124,\n",
              "         'that': 44755,\n",
              "         'though': 842,\n",
              "         'useful': 66,\n",
              "         'things': 3447,\n",
              "         'where': 7504,\n",
              "         'good': 9381,\n",
              "         'stores': 35,\n",
              "         'much': 4715,\n",
              "         'because': 4218,\n",
              "         'such': 1326,\n",
              "         'nice': 2319,\n",
              "         'one': 12865,\n",
              "         'our': 4763,\n",
              "         'little': 5569,\n",
              "         'wench': 10,\n",
              "         'plan': 611,\n",
              "         'progressing': 3,\n",
              "         'theres': 5085,\n",
              "         'someone': 2121,\n",
              "         'think': 14340,\n",
              "         'might': 2406,\n",
              "         'there': 12922,\n",
              "         'mind': 2249,\n",
              "         'counted': 31,\n",
              "         'help': 3299,\n",
              "         'cause': 1230,\n",
              "         'thug': 7,\n",
              "         'obviously': 224,\n",
              "         'failing': 19,\n",
              "         'arent': 1347,\n",
              "         'ever': 3652,\n",
              "         'going': 11379,\n",
              "         'word': 1164,\n",
              "         'as': 9332,\n",
              "         'gentleman': 153,\n",
              "         'sweet': 442,\n",
              "         'hair': 532,\n",
              "         'look': 7492,\n",
              "         'ebers': 1,\n",
              "         'deep': 314,\n",
              "         'conditioner': 11,\n",
              "         'every': 2226,\n",
              "         'two': 4538,\n",
              "         'days': 1424,\n",
              "         'never': 7067,\n",
              "         'use': 1444,\n",
              "         'blowdryer': 2,\n",
              "         'without': 1488,\n",
              "         'diffuser': 1,\n",
              "         'attachment': 5,\n",
              "         'sure': 6049,\n",
              "         'wanna': 1241,\n",
              "         'go': 12495,\n",
              "         'but': 22026,\n",
              "         'unless': 479,\n",
              "         'goes': 873,\n",
              "         'workin': 92,\n",
              "         'doesnt': 3054,\n",
              "         'seem': 738,\n",
              "         'goin': 604,\n",
              "         'him': 14721,\n",
              "         'shes': 3954,\n",
              "         'lesbian': 28,\n",
              "         'found': 1550,\n",
              "         'picture': 549,\n",
              "         'jared': 3,\n",
              "         'leto': 6,\n",
              "         'in': 41692,\n",
              "         'her': 11430,\n",
              "         'drawers': 15,\n",
              "         'pretty': 1791,\n",
              "         'harboring': 6,\n",
              "         'samesex': 3,\n",
              "         'tendencies': 6,\n",
              "         'kind': 2730,\n",
              "         'guy': 3124,\n",
              "         'likes': 369,\n",
              "         'ones': 702,\n",
              "         'who': 9152,\n",
              "         'knows': 1204,\n",
              "         'all': 18850,\n",
              "         'ive': 7039,\n",
              "         'heard': 1976,\n",
              "         'shed': 281,\n",
              "         'dip': 24,\n",
              "         'before': 3587,\n",
              "         'dating': 86,\n",
              "         'smokes': 38,\n",
              "         'hi': 1204,\n",
              "         'looks': 1232,\n",
              "         'worked': 569,\n",
              "         'tonight': 1819,\n",
              "         'huh': 2286,\n",
              "         'chastity': 12,\n",
              "         'believe': 3360,\n",
              "         'share': 248,\n",
              "         'art': 290,\n",
              "         'instructor': 6,\n",
              "         'fun': 658,\n",
              "         'tons': 51,\n",
              "         'looked': 555,\n",
              "         'back': 7418,\n",
              "         'party': 809,\n",
              "         'always': 3299,\n",
              "         'seemed': 238,\n",
              "         'occupied': 25,\n",
              "         'wanted': 2354,\n",
              "         'did': 11887,\n",
              "         'had': 7015,\n",
              "         'been': 8487,\n",
              "         'selfish': 56,\n",
              "         'guillermo': 1,\n",
              "         'says': 1567,\n",
              "         'any': 5405,\n",
              "         'lighter': 28,\n",
              "         'gonna': 5323,\n",
              "         'extra': 200,\n",
              "         '90210': 1,\n",
              "         'listen': 2434,\n",
              "         'crap': 273,\n",
              "         'endless': 20,\n",
              "         'blonde': 105,\n",
              "         'babble': 7,\n",
              "         'boring': 144,\n",
              "         'myself': 1445,\n",
              "         'thank': 2557,\n",
              "         'god': 2881,\n",
              "         'hear': 2351,\n",
              "         'more': 5498,\n",
              "         'story': 1143,\n",
              "         'about': 18683,\n",
              "         'coiffure': 4,\n",
              "         'figured': 438,\n",
              "         'youd': 1980,\n",
              "         'stuff': 1427,\n",
              "         'eventually': 103,\n",
              "         'real': 2247,\n",
              "         'fear': 302,\n",
              "         'wearing': 334,\n",
              "         'pastels': 2,\n",
              "         'kidding': 587,\n",
              "         'sometimes': 934,\n",
              "         'become': 400,\n",
              "         'persona': 4,\n",
              "         'quit': 461,\n",
              "         'need': 5194,\n",
              "         'learn': 541,\n",
              "         'lie': 600,\n",
              "         'wow': 348,\n",
              "         'lets': 3125,\n",
              "         'hope': 1256,\n",
              "         'they': 15365,\n",
              "         'change': 966,\n",
              "         'he': 24379,\n",
              "         'here': 15848,\n",
              "         'joey': 164,\n",
              "         'great': 2823,\n",
              "         'would': 7917,\n",
              "         'getting': 2127,\n",
              "         'drink': 1073,\n",
              "         'practically': 131,\n",
              "         'proposed': 44,\n",
              "         'same': 1858,\n",
              "         'dermatologist': 3,\n",
              "         'mean': 7183,\n",
              "         'dr': 1071,\n",
              "         'bonchowski': 1,\n",
              "         'hes': 8639,\n",
              "         'exactly': 1380,\n",
              "         'relevant': 23,\n",
              "         'oily': 7,\n",
              "         'dry': 168,\n",
              "         'combination': 58,\n",
              "         'hed': 532,\n",
              "         'different': 1030,\n",
              "         'bianca': 31,\n",
              "         'highlights': 6,\n",
              "         'dorsey': 8,\n",
              "         'include': 53,\n",
              "         'dooropening': 1,\n",
              "         'coatholding': 1,\n",
              "         'wonder': 505,\n",
              "         'guys': 2071,\n",
              "         'were': 14085,\n",
              "         'supposed': 1253,\n",
              "         'actually': 1166,\n",
              "         'id': 3964,\n",
              "         'give': 4358,\n",
              "         'private': 399,\n",
              "         'line': 678,\n",
              "         'home': 2769,\n",
              "         'twenty': 742,\n",
              "         'minutes': 1168,\n",
              "         'til': 167,\n",
              "         're': 64,\n",
              "         'sophomore': 13,\n",
              "         'prom': 101,\n",
              "         'expensive': 110,\n",
              "         'bogey': 11,\n",
              "         'lowenbraus': 1,\n",
              "         'hopefully': 28,\n",
              "         'yeah': 10451,\n",
              "         'sears': 9,\n",
              "         'catalog': 5,\n",
              "         'tube': 37,\n",
              "         'sock': 19,\n",
              "         'gig': 59,\n",
              "         'huge': 126,\n",
              "         'ad': 66,\n",
              "         'queen': 179,\n",
              "         'harry': 598,\n",
              "         'gay': 118,\n",
              "         'cruise': 30,\n",
              "         'ill': 8849,\n",
              "         'uniform': 85,\n",
              "         'neat': 70,\n",
              "         'agent': 391,\n",
              "         'shot': 993,\n",
              "         'being': 1941,\n",
              "         'prada': 4,\n",
              "         'next': 1543,\n",
              "         'year': 1055,\n",
              "         'hey': 3185,\n",
              "         'cheeks': 23,\n",
              "         'concentrating': 16,\n",
              "         'awfully': 71,\n",
              "         'hard': 1385,\n",
              "         'considering': 87,\n",
              "         'gym': 27,\n",
              "         'class': 413,\n",
              "         'talk': 4268,\n",
              "         'deal': 1253,\n",
              "         't': 95,\n",
              "         'whereve': 29,\n",
              "         'nowhere': 175,\n",
              "         'daddy': 696,\n",
              "         'potential': 59,\n",
              "         'smack': 21,\n",
              "         'way': 6112,\n",
              "         'least': 1088,\n",
              "         'bra': 28,\n",
              "         'oh': 10884,\n",
              "         'becoming': 83,\n",
              "         'normal': 256,\n",
              "         'means': 850,\n",
              "         'gigglepuss': 6,\n",
              "         'playing': 546,\n",
              "         'club': 307,\n",
              "         'skunk': 15,\n",
              "         'bothering': 92,\n",
              "         'ask': 2462,\n",
              "         'lowensteins': 3,\n",
              "         'freak': 142,\n",
              "         'torture': 71,\n",
              "         'suck': 108,\n",
              "         'ruining': 35,\n",
              "         'life': 3326,\n",
              "         'wont': 3337,\n",
              "         'too': 6295,\n",
              "         'busy': 449,\n",
              "         'listening': 311,\n",
              "         'bitches': 46,\n",
              "         'prozac': 6,\n",
              "         'completely': 372,\n",
              "         'wretched': 24,\n",
              "         'clouted': 1,\n",
              "         'fen': 1,\n",
              "         'sucked': 44,\n",
              "         'hedgepig': 1,\n",
              "         'even': 3907,\n",
              "         'shakespeare': 53,\n",
              "         'maybe': 5188,\n",
              "         'youve': 3787,\n",
              "         'friend': 1826,\n",
              "         'mandellas': 1,\n",
              "         'guess': 2647,\n",
              "         'since': 1437,\n",
              "         'allowed': 153,\n",
              "         'should': 4563,\n",
              "         'obsess': 1,\n",
              "         'over': 4909,\n",
              "         'dead': 2470,\n",
              "         'unbalanced': 2,\n",
              "         'now': 12037,\n",
              "         'tell': 8991,\n",
              "         'social': 127,\n",
              "         'advice': 235,\n",
              "         'from': 8496,\n",
              "         'act': 503,\n",
              "         'totally': 322,\n",
              "         'apeshit': 3,\n",
              "         'welcome': 341,\n",
              "         'hate': 1041,\n",
              "         'sit': 1044,\n",
              "         'susie': 79,\n",
              "         'care': 2058,\n",
              "         'firm': 109,\n",
              "         'believer': 21,\n",
              "         'doing': 4013,\n",
              "         'own': 1961,\n",
              "         'reasons': 172,\n",
              "         'else': 2336,\n",
              "         's': 97,\n",
              "         'wish': 1030,\n",
              "         'luxury': 19,\n",
              "         'asked': 1091,\n",
              "         'won': 261,\n",
              "         'told': 3710,\n",
              "         'went': 1891,\n",
              "         '9th': 14,\n",
              "         'month': 403,\n",
              "         'total': 165,\n",
              "         'babe': 146,\n",
              "         'said': 5404,\n",
              "         'everyone': 811,\n",
              "         'once': 1541,\n",
              "         'afterwards': 50,\n",
              "         'anymore': 906,\n",
              "         'wasnt': 2242,\n",
              "         'pissed': 151,\n",
              "         'broke': 405,\n",
              "         'after': 3015,\n",
              "         'swore': 62,\n",
              "         'anything': 4396,\n",
              "         'havent': 1917,\n",
              "         'except': 531,\n",
              "         'bogeys': 3,\n",
              "         'decisions': 48,\n",
              "         'wouldve': 190,\n",
              "         'instead': 320,\n",
              "         'helping': 169,\n",
              "         'stupid': 768,\n",
              "         'repeat': 123,\n",
              "         'mistakes': 80,\n",
              "         'protecting': 81,\n",
              "         'keep': 2831,\n",
              "         'locked': 224,\n",
              "         'away': 2955,\n",
              "         'dark': 471,\n",
              "         'experience': 273,\n",
              "         'experiences': 33,\n",
              "         'trust': 967,\n",
              "         'people': 5029,\n",
              "         'will': 7901,\n",
              "         'beautiful': 1043,\n",
              "         'last': 3386,\n",
              "         'set': 921,\n",
              "         'damage': 148,\n",
              "         'send': 800,\n",
              "         'therapy': 86,\n",
              "         'forever': 263,\n",
              "         'woman': 1418,\n",
              "         'complete': 190,\n",
              "         'fruitloop': 1,\n",
              "         'patrick': 119,\n",
              "         'perm': 8,\n",
              "         'upset': 367,\n",
              "         'boy': 1874,\n",
              "         'starts': 160,\n",
              "         'end': 969,\n",
              "         'discussion': 64,\n",
              "         'neither': 346,\n",
              "         'sleep': 1090,\n",
              "         'fair': 404,\n",
              "         'mutant': 27,\n",
              "         'point': 1305,\n",
              "         'wherere': 43,\n",
              "         'must': 3306,\n",
              "         'attempting': 21,\n",
              "         'small': 559,\n",
              "         'study': 215,\n",
              "         'group': 238,\n",
              "         'friends': 1322,\n",
              "         'otherwise': 187,\n",
              "         'known': 545,\n",
              "         'orgy': 11,\n",
              "         'knew': 1951,\n",
              "         'forbid': 21,\n",
              "         'gloria': 30,\n",
              "         'steinem': 3,\n",
              "         'isnt': 3129,\n",
              "         'expect': 571,\n",
              "         'kats': 1,\n",
              "         'starting': 286,\n",
              "         'wear': 443,\n",
              "         'belly': 46,\n",
              "         'minute': 1346,\n",
              "         'promise': 638,\n",
              "         'boys': 743,\n",
              "         'present': 292,\n",
              "         'shell': 495,\n",
              "         'scare': 185,\n",
              "         'them': 7208,\n",
              "         'discuss': 213,\n",
              "         'tomorrow': 1583,\n",
              "         'has': 4569,\n",
              "         'hot': 632,\n",
              "         'rod': 64,\n",
              "         'bend': 53,\n",
              "         'rules': 240,\n",
              "         'whatever': 1066,\n",
              "         'fine': 2471,\n",
              "         'prisoner': 67,\n",
              "         'house': 2089,\n",
              "         'daughter': 546,\n",
              "         'possession': 79,\n",
              "         'missing': 323,\n",
              "         'captain': 862,\n",
              "         'oppression': 7,\n",
              "         'men': 1467,\n",
              "         'pleasure': 324,\n",
              "         'brucie': 1,\n",
              "         'pegged': 19,\n",
              "         'fan': 136,\n",
              "         'preteen': 3,\n",
              "         'bellybutton': 3,\n",
              "         'ring': 323,\n",
              "         'couple': 981,\n",
              "         'minors': 12,\n",
              "         'come': 8509,\n",
              "         'padua': 2,\n",
              "         'girls': 720,\n",
              "         'tall': 109,\n",
              "         'decent': 116,\n",
              "         'body': 720,\n",
              "         'other': 3340,\n",
              "         'kinda': 419,\n",
              "         'short': 318,\n",
              "         'undersexed': 2,\n",
              "         'sent': 673,\n",
              "         'em': 1620,\n",
              "         'through': 2100,\n",
              "         'new': 2741,\n",
              "         'cmon': 536,\n",
              "         'tour': 93,\n",
              "         'which': 1660,\n",
              "         'dakota': 20,\n",
              "         'north': 222,\n",
              "         'howd': 488,\n",
              "         'live': 1690,\n",
              "         'outnumbered': 6,\n",
              "         'by': 4866,\n",
              "         'cows': 36,\n",
              "         'many': 1648,\n",
              "         'old': 2969,\n",
              "         'thirtytwo': 22,\n",
              "         'thousand': 1057,\n",
              "         'most': 1452,\n",
              "         'evil': 307,\n",
              "         'these': 3406,\n",
              "         'seen': 1863,\n",
              "         'horse': 271,\n",
              "         'jack': 1026,\n",
              "         'off': 4779,\n",
              "         'clint': 8,\n",
              "         'eastwood': 6,\n",
              "         'girl': 2391,\n",
              "         'burn': 172,\n",
              "         'pine': 20,\n",
              "         'perish': 10,\n",
              "         'stratford': 10,\n",
              "         'haircut': 39,\n",
              "         'matter': 1675,\n",
              "         'older': 176,\n",
              "         'impossibility': 4,\n",
              "         'theyre': 3890,\n",
              "         'bred': 17,\n",
              "         'their': 2501,\n",
              "         'mothers': 284,\n",
              "         'liked': 424,\n",
              "         'grandmothers': 18,\n",
              "         'gene': 35,\n",
              "         'pool': 177,\n",
              "         'rarely': 31,\n",
              "         'diluted': 2,\n",
              "         'shiteating': 3,\n",
              "         'grin': 4,\n",
              "         'permashitgrin': 1,\n",
              "         'moron': 68,\n",
              "         'number': 826,\n",
              "         'twelve': 384,\n",
              "         'model': 94,\n",
              "         'mostly': 193,\n",
              "         'regional': 14,\n",
              "         'moms': 105,\n",
              "         'canada': 43,\n",
              "         'signed': 128,\n",
              "         'tutor': 13,\n",
              "         'chance': 984,\n",
              "         'consecrate': 1,\n",
              "         'minor': 73,\n",
              "         'encounter': 22,\n",
              "         'shrew': 1,\n",
              "         'biancas': 3,\n",
              "         'mewling': 1,\n",
              "         'rampalian': 1,\n",
              "         'wretch': 5,\n",
              "         'herself': 213,\n",
              "         'teach': 272,\n",
              "         'dazzle': 3,\n",
              "         'charm': 54,\n",
              "         'falls': 106,\n",
              "         'love': 3994,\n",
              "         'unlikely': 27,\n",
              "         'still': 3649,\n",
              "         'makes': 1209,\n",
              "         'hell': 3710,\n",
              "         'thrives': 2,\n",
              "         'danger': 207,\n",
              "         'criminal': 169,\n",
              "         'lit': 37,\n",
              "         'state': 477,\n",
              "         'trooper': 17,\n",
              "         'fire': 742,\n",
              "         'alcatraz': 2,\n",
              "         'felons': 3,\n",
              "         'honors': 18,\n",
              "         'biology': 12,\n",
              "         'serious': 787,\n",
              "         'man': 6906,\n",
              "         'whacked': 31,\n",
              "         'sold': 220,\n",
              "         'his': 8551,\n",
              "         'liver': 25,\n",
              "         'black': 737,\n",
              "         'market': 145,\n",
              "         'buy': 827,\n",
              "         'speakers': 6,\n",
              "         'reputation': 115,\n",
              "         'weve': 1785,\n",
              "         'outrank': 2,\n",
              "         'strictly': 51,\n",
              "         'alist': 2,\n",
              "         'side': 827,\n",
              "         'hated': 162,\n",
              "         'those': 3210,\n",
              "         'gotta': 2246,\n",
              "         'few': 1451,\n",
              "         'clients': 84,\n",
              "         'wall': 249,\n",
              "         'street': 673,\n",
              "         'involved': 378,\n",
              "         'choice': 452,\n",
              "         'besides': 515,\n",
              "         'enemy': 187,\n",
              "         'orchestrating': 1,\n",
              "         'battle': 110,\n",
              "         'position': 261,\n",
              "         'power': 676,\n",
              "         'golden': 65,\n",
              "         'opportunity': 143,\n",
              "         'katarina': 3,\n",
              "         'case': 1278,\n",
              "         'schoolwide': 2,\n",
              "         'blow': 435,\n",
              "         'bent': 48,\n",
              "         'piss': 125,\n",
              "         'himself': 645,\n",
              "         'joy': 66,\n",
              "         'ultimate': 39,\n",
              "         'kiss': 364,\n",
              "         'ass': 1043,\n",
              "         'hates': 137,\n",
              "         'smokers': 4,\n",
              "         'lung': 33,\n",
              "         'cancer': 134,\n",
              "         'issue': 139,\n",
              "         'favorite': 234,\n",
              "         'uncle': 360,\n",
              "         'fortyone': 11,\n",
              "         'assail': 1,\n",
              "         'ears': 150,\n",
              "         'band': 171,\n",
              "         'already': 1511,\n",
              "         'whole': 1689,\n",
              "         'extremely': 102,\n",
              "         'unfortunate': 62,\n",
              "         'maneuver': 17,\n",
              "         'picks': 37,\n",
              "         'carries': 22,\n",
              "         'while': 1445,\n",
              "         'talking': 2690,\n",
              "         'buttholus': 2,\n",
              "         'extremus': 2,\n",
              "         'making': 960,\n",
              "         'progress': 96,\n",
              "         'm': 96,\n",
              "         'humiliated': 24,\n",
              "         'sacrifice': 54,\n",
              "         'yourself': 2210,\n",
              "         'altar': 10,\n",
              "         'dignity': 38,\n",
              "         'score': 116,\n",
              "         'best': 1671,\n",
              "         'scenario': 21,\n",
              "         'payroll': 30,\n",
              "         'awhile': 169,\n",
              "         'non': 36,\n",
              "         'prisonmovie': 1,\n",
              "         'type': 267,\n",
              "         'whatve': 25,\n",
              "         'retrieved': 4,\n",
              "         'certain': 395,\n",
              "         'pieces': 147,\n",
              "         'information': 469,\n",
              "         'miss': 1691,\n",
              "         'youll': 2796,\n",
              "         'helpful': 53,\n",
              "         'thai': 10,\n",
              "         'food': 536,\n",
              "         'feminist': 7,\n",
              "         'prose': 6,\n",
              "         'angry': 251,\n",
              "         'stinky': 10,\n",
              "         'music': 438,\n",
              "         'indierock': 1,\n",
              "         'persuasion': 4,\n",
              "         'noodles': 7,\n",
              "         'book': 754,\n",
              "         'around': 3391,\n",
              "         'chicks': 73,\n",
              "         'play': 1423,\n",
              "         'partial': 29,\n",
              "         'whatd': 471,\n",
              "         'don': 198,\n",
              "         'decided': 325,\n",
              "         'nail': 91,\n",
              "         'drunk': 384,\n",
              "         'remember': 2679,\n",
              "         'suns': 25,\n",
              "         'direct': 123,\n",
              "         'quote': 63,\n",
              "         'needs': 606,\n",
              "         'time': 8172,\n",
              "         'cool': 625,\n",
              "         'day': 2880,\n",
              "         'makin': 91,\n",
              "         'headway': 3,\n",
              "         'kissed': 76,\n",
              "         'worst': 227,\n",
              "         'vintage': 8,\n",
              "         'reading': 285,\n",
              "         'sassy': 11,\n",
              "         'noticed': 208,\n",
              "         'featured': 3,\n",
              "         'big': 2744,\n",
              "         'kmart': 7,\n",
              "         'spread': 74,\n",
              "         'elbow': 13,\n",
              "         'tough': 398,\n",
              "         'running': 758,\n",
              "         'rest': 905,\n",
              "         'ya': 1678,\n",
              "         'leave': 2485,\n",
              "         'alone': 1362,\n",
              "         'legs': 185,\n",
              "         'rack': 23,\n",
              "         'sparky': 10,\n",
              "         'money': 3437,\n",
              "         'take': 7002,\n",
              "         'cake': 107,\n",
              "         'verona': 19,\n",
              "         'pick': 779,\n",
              "         'tab': 27,\n",
              "         'pay': 1074,\n",
              "         'gets': 993,\n",
              "         'catch': 516,\n",
              "         'bucks': 397,\n",
              "         'thirty': 463,\n",
              "         'negotiation': 16,\n",
              "         'fifty': 569,\n",
              "         'results': 56,\n",
              "         'watching': 402,\n",
              "         'bitch': 504,\n",
              "         'trash': 61,\n",
              "         'car': 1948,\n",
              "         'count': 350,\n",
              "         'under': 1068,\n",
              "         'control': 522,\n",
              "         'acts': 41,\n",
              "         'crazed': 8,\n",
              "         'image': 91,\n",
              "         'upped': 9,\n",
              "         'price': 285,\n",
              "         'hundred': 1392,\n",
              "         'deals': 82,\n",
              "         'human': 509,\n",
              "         'limothe': 1,\n",
              "         'flowers': 155,\n",
              "         'another': 2060,\n",
              "         'tux': 6,\n",
              "         'barbie': 14,\n",
              "         'n': 109,\n",
              "         'ken': 36,\n",
              "         'shit': 2940,\n",
              "         'lost': 1133,\n",
              "         'nope': 229,\n",
              "         'came': 2074,\n",
              "         'chat': 82,\n",
              "         'run': 1496,\n",
              "         'idea': 1708,\n",
              "         'interested': 521,\n",
              "         'insane': 222,\n",
              "         'conversation': 192,\n",
              "         'purpose': 162,\n",
              "         'recruit': 15,\n",
              "         'wholl': 41,\n",
              "         'whos': 1478,\n",
              "         'job': 1985,\n",
              "         'helpin': 9,\n",
              "         'uh': 2229,\n",
              "         'took': 1378,\n",
              "         'bathes': 3,\n",
              "         'together': 1390,\n",
              "         'kids': 1143,\n",
              "         'better': 3436,\n",
              "         'fuck': 2598,\n",
              "         'heavily': 24,\n",
              "         'invested': 19,\n",
              "         'higher': 91,\n",
              "         'random': 56,\n",
              "         'skid': 8,\n",
              "         'pat': 56,\n",
              "         'gone': 1303,\n",
              "         'porn': 25,\n",
              "         'movies': 309,\n",
              "         'incapable': 24,\n",
              "         'interesting': 417,\n",
              "         'block': 127,\n",
              "         'e': 63,\n",
              "         'mandella': 1,\n",
              "         'eat': 954,\n",
              "         'starving': 49,\n",
              "         'very': 5095,\n",
              "         'slow': 315,\n",
              "         'die': 1170,\n",
              "         'attempted': 22,\n",
              "         'slit': 27,\n",
              "         'realize': 369,\n",
              "         'institution': 57,\n",
              "         'severely': 10,\n",
              "         'lacking': 23,\n",
              "         'killing': 380,\n",
              "         'william': 137,\n",
              "         'beyond': 196,\n",
              "         'imagine': 405,\n",
              "         'during': 252,\n",
              "         'sex': 602,\n",
              "         'foul': 38,\n",
              "         'raging': 8,\n",
              "         'fit': 247,\n",
              "         'sarah': 121,\n",
              "         'lawrence': 19,\n",
              "         'insists': 17,\n",
              "         'maledominated': 1,\n",
              "         'puking': 7,\n",
              "         'frat': 9,\n",
              "         'golf': 67,\n",
              "         'team': 327,\n",
              "         'proven': 33,\n",
              "         'heterosexuality': 2,\n",
              "         'appreciate': 353,\n",
              "         'efforts': 25,\n",
              "         'toward': 114,\n",
              "         'speedy': 3,\n",
              "         'death': 928,\n",
              "         'consuming': 7,\n",
              "         'precious': 71,\n",
              "         'tiara': 2,\n",
              "         'thisll': 54,\n",
              "         'work': 3572,\n",
              "         'cares': 173,\n",
              "         'officially': 45,\n",
              "         'opposed': 41,\n",
              "         'suburban': 8,\n",
              "         'activity': 42,\n",
              "         'wheres': 1178,\n",
              "         'done': 2170,\n",
              "         'favor': 402,\n",
              "         'backfired': 2,\n",
              "         'puked': 3,\n",
              "         'rejected': 18,\n",
              "         'bastion': 4,\n",
              "         'commercial': 57,\n",
              "         'excess': 8,\n",
              "         'dates': 67,\n",
              "         'sound': 643,\n",
              "         'betty': 244,\n",
              "         'archie': 24,\n",
              "         'taking': 1002,\n",
              "         'veronica': 87,\n",
              "         'dress': 309,\n",
              "         'anyway': 1300,\n",
              "         'looking': 1803,\n",
              "         'wrong': 2490,\n",
              "         'perspective': 31,\n",
              "         'statement': 119,\n",
              "         'us': 7005,\n",
              "         'meet': 1365,\n",
              "         'honey': 909,\n",
              "         'progressed': 3,\n",
              "         'fullon': 4,\n",
              "         'hallucinations': 15,\n",
              "         'doin': 489,\n",
              "         'sweating': 32,\n",
              "         'pig': 156,\n",
              "         'attention': 267,\n",
              "         'mission': 254,\n",
              "         'friday': 168,\n",
              "         'places': 237,\n",
              "         '7eleven': 4,\n",
              "         'burnside': 2,\n",
              "         'screwboy': 2,\n",
              "         'lot': 2521,\n",
              "         'than': 3281,\n",
              "         'warrant': 80,\n",
              "         'strong': 312,\n",
              "         'emotion': 35,\n",
              "         'spend': 343,\n",
              "         'dollar': 236,\n",
              "         'track': 192,\n",
              "         'ponies': 18,\n",
              "         'flat': 121,\n",
              "         'beer': 296,\n",
              "         'eyes': 828,\n",
              "         'hand': 891,\n",
              "         'covered': 124,\n",
              "         'vomit': 35,\n",
              "         'seventhirty': 12,\n",
              "         'following': 203,\n",
              "         'laundromat': 8,\n",
              "         'saw': 2020,\n",
              "         'talker': 10,\n",
              "         'depends': 183,\n",
              "         'topic': 22,\n",
              "         'fenders': 2,\n",
              "         'whip': 41,\n",
              "         'into': 3618,\n",
              "         'verbal': 25,\n",
              "         'frenzy': 6,\n",
              "         'show': 1723,\n",
              "         'excuse': 845,\n",
              "         'sort': 825,\n",
              "         'bikini': 10,\n",
              "         'kill': 2499,\n",
              "         'raincoats': 4,\n",
              "         'trashed': 14,\n",
              "         'funny': 933,\n",
              "         'down': 5401,\n",
              "         'concussion': 15,\n",
              "         'dog': 602,\n",
              "         'woke': 123,\n",
              "         'vegetable': 24,\n",
              "         'patronizing': 10,\n",
              "         'words': 569,\n",
              "         'shitfaced': 7,\n",
              "         'affection': 25,\n",
              "         'blind': 205,\n",
              "         'hatred': 23,\n",
              "         'whyd': 194,\n",
              "         'itd': 158,\n",
              "         'mainline': 2,\n",
              "         'tequila': 20,\n",
              "         'laid': 171,\n",
              "         'above': 156,\n",
              "         'wake': 360,\n",
              "         'jail': 336,\n",
              "         'werent': 675,\n",
              "         'father': 2055,\n",
              "         ...})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_freq = Counter()\n",
        "for pair in pairs:\n",
        "  word_freq.update(pair[0])\n",
        "  word_freq.update(pair[1])\n",
        "\n",
        "word_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2ImfRPxKsSJ"
      },
      "outputs": [],
      "source": [
        "# Minimum word frequency threshold\n",
        "min_word_freq = 5\n",
        "\n",
        "# Filter words that meet the minimum frequency requirement\n",
        "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
        "\n",
        "# Create word-to-index mapping, starting from 1\n",
        "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
        "\n",
        "# Add special tokens to the word map\n",
        "word_map['<unk>'] = len(word_map) + 1  # Unknown words\n",
        "word_map['<start>'] = len(word_map) + 1  # Start token\n",
        "word_map['<end>'] = len(word_map) + 1  # End token\n",
        "word_map['<pad>'] = 0  # Padding token (assigned index 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhB1toNKMnTi"
      },
      "outputs": [],
      "source": [
        "# Save word map to JSON file\n",
        "import json\n",
        "with open(\"WORDMAP_corpus.json\", \"w\") as j:\n",
        "    json.dump(word_map, j)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Text Sequences for Model Training\n",
        "Following code converts the preprocessed text pairs into numerical sequences suitable for neural network training, while handling special tokens and padding.\n",
        "\n",
        "#### Encoding Functions:\n",
        "\n",
        "1. **`encode_question(question_words, word_map)`**:\n",
        "   - Converts a question into numerical indices\n",
        "   - **Process**:\n",
        "     - Each word is looked up in `word_map` (uses `<unk>` for missing words)\n",
        "     - Padding (`<pad> = 0`) is added to reach `max_len`\n",
        "   - **Example**: `[\"how\", \"are\", \"you\"]` → `[12, 25, 63, 0, 0, ...]` (for `max_len=25`)\n",
        "\n",
        "2. **`encode_reply(answer_words, word_map)`**:\n",
        "   - Converts an answer with special sequence tokens\n",
        "   - **Process**:\n",
        "     - Starts with `<start>` token\n",
        "     - Includes word indices (with `<unk>` for unknowns)\n",
        "     - Ends with `<end>` token\n",
        "     - Adds padding to reach `max_len`\n",
        "   - **Example**: `[\"i\", \"am\", \"fine\"]` → `[2533, 8, 42, 156, 2534, 0, 0, ...]`\n",
        "\n",
        "#### Special Token Handling:\n",
        "| Token    | Purpose                          | Example ID |\n",
        "|----------|----------------------------------|------------|\n",
        "| `<pad>`  | Padding for fixed-length sequences | 0         |\n",
        "| `<unk>`  | Unknown/low-frequency words      | 2532      |\n",
        "| `<start>`| Start-of-sequence marker         | 2533      |\n",
        "| `<end>`  | End-of-sequence marker           | 2534      |\n",
        "\n",
        "#### Full Encoding Process:\n",
        "1. Iterates through all QA pairs\n",
        "2. Encodes questions using `encode_question()`\n",
        "3. Encodes answers using `encode_reply()`\n",
        "4. Stores encoded pairs in `pairs_encoded`\n",
        "\n",
        "#### Why This Matters:\n",
        "- Converts variable-length text to fixed-length numerical arrays\n",
        "- Special tokens help the model learn:\n",
        "  - When sequences start/end (`<start>`, `<end>`)\n",
        "  - How to handle padding in batches (`<pad>`)\n",
        "  - How to deal with unknown vocabulary (`<unk>`)\n",
        "\n"
      ],
      "metadata": {
        "id": "Gazxi2WulYGi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vufClDC_NYgh"
      },
      "outputs": [],
      "source": [
        "# Encode question by converting words to indices and padding to max_len\n",
        "def encode_question(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map[\"<unk>\"]) for word in words] + [word_map[\"<pad>\"]] * (max_len - len(words))\n",
        "    return enc_c\n",
        "\n",
        "# Encode reply with start/end tokens and padding to max_len\n",
        "def encode_reply(words, word_map):\n",
        "    enc_c = [word_map[\"<start>\"]] + [word_map.get(word, word_map[\"<unk>\"]) for word in words] + [word_map[\"<end>\"]] + [word_map[\"<pad>\"]] * (max_len - len(words))\n",
        "    return enc_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXUdR12RRVVS",
        "outputId": "91b41082-aea3-4cd9-af83-6543e23c1ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can we make this quick roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad again\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18241,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 18240,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 24,\n",
              " 28,\n",
              " 18242,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "print(\" \".join(pairs[0][0]))\n",
        "encode_reply(pairs[0][1], word_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jlx88BKERwNY"
      },
      "outputs": [],
      "source": [
        "# Initialize list to store encoded question-answer pairs\n",
        "pairs_encoded = []\n",
        "\n",
        "# Iterate through each question-answer pair\n",
        "for pair in pairs:\n",
        "    # Encode the question part\n",
        "    ques = encode_question(pair[0], word_map)\n",
        "    # Encode the answer part\n",
        "    ans = encode_reply(pair[1], word_map)\n",
        "    # Add encoded pair to the list\n",
        "    pairs_encoded.append([ques, ans])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHPtNlFLVx3i"
      },
      "outputs": [],
      "source": [
        "# Save pairs encoded to JSON file\n",
        "import json\n",
        "with open(\"pairs_encoded.json\", \"w\") as w:\n",
        "  json.dump(pairs_encoded, w)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Data Pipeline for Dialogue Pairs\n",
        "This code creates a custom PyTorch Dataset and DataLoader to efficiently handle batches of encoded question-answer pairs for model training.\n",
        "\n",
        "#### Key Components:\n",
        "\n",
        "1. **Custom Dataset Class**:\n",
        "   - Inherits from `torch.utils.data.Dataset`\n",
        "   - **`__init__`**:\n",
        "     - Loads pre-encoded pairs from JSON file (`pairs_encoded.json`)\n",
        "     - Stores dataset size\n",
        "   - **`__getitem__`**:\n",
        "     - Converts encoded sequences to `LongTensor`\n",
        "     - Returns (question, reply) tuple for a given index\n",
        "   - **`__len__`**:\n",
        "     - Returns total number of pairs\n",
        "\n",
        "2. **DataLoader Setup**:\n",
        "   - Creates `train_loader` with:\n",
        "     - Batch size of 100 samples\n",
        "     - Shuffling enabled (`shuffle=True`)\n",
        "     - Pinned memory for faster GPU transfer (`pin_memory=True`)\n",
        "\n",
        "3. **Output Shapes**:\n",
        "   - **Questions**: `[100, 25]` (batch_size × max_question_length)\n",
        "   - **Replies**: `[100, 27]` (batch_size × max_reply_length + 2 for <start>/<end> tokens)\n",
        "\n",
        "#### Why This Matters:\n",
        "- **Efficient Training**:\n",
        "  - Batched processing speeds up training\n",
        "  - Automatic shuffling improves model generalization\n",
        "- **GPU Optimization**:\n",
        "  - `pin_memory=True` enables faster CPU-to-GPU transfers\n"
      ],
      "metadata": {
        "id": "AEGWfgrymnrR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TzIVntBVL55"
      },
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Custom Dataset class\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        # Load encoded pairs from JSON file\n",
        "        self.pairs = json.load(open(path))\n",
        "        # Store dataset size\n",
        "        self.dataset_size = len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Convert question and reply to LongTensors\n",
        "        question = torch.LongTensor(self.pairs[index][0])\n",
        "        reply = torch.LongTensor(self.pairs[index][1])\n",
        "        return question, reply\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return total number of pairs\n",
        "        return self.dataset_size\n",
        "\n",
        "# Create dataset instance\n",
        "dataset = Dataset(path=\"pairs_encoded.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LzGzcItXrtx",
        "outputId": "49b946f0-4d1b-4ba9-8096-6dcc1b8edff7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100, 25]), torch.Size([100, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Import DataLoader from PyTorch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_loader = DataLoader(dataset, batch_size=100, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Get a batch of data and check shapes\n",
        "question, reply = next(iter(train_loader))\n",
        "question.shape, reply.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NXsl0tSYKob",
        "outputId": "8ca90cb7-bece-4ff9-d374-69f83a401c8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18241,    91,   336,    19,  2855,   125,   144,    92,   130, 18242,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "reply[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LGKGK6S9fmwa",
        "outputId": "5b2eab48-a842-4f67-ac6a-54ed8edf2a9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mask Creation for Transformer Model**  \n",
        "This function generates three masks for a seq2seq Transformer:\n",
        "\n",
        "1. **Question Mask** (`question_mask`):  \n",
        "   - Binary mask (1 for real tokens, 0 for padding)  \n",
        "   - Shape: `[batch, 1, 1, max_len]` (for encoder self-attention)\n",
        "\n",
        "2. **Reply Input Mask** (`reply_input_mask`):  \n",
        "   - Combines padding mask and look-ahead mask  \n",
        "   - Prevents decoder from seeing future tokens  \n",
        "   - Shape: `[batch, 1, max_len, max_len]`\n",
        "\n",
        "3. **Reply Target Mask** (`reply_target_mask`):  \n",
        "   - Simple padding mask for loss calculation  \n",
        "   - Shape: `[batch, max_len]`\n",
        "\n",
        "Key operations:  \n",
        "- `subsequent_mask()` creates triangular matrix for causal masking  \n",
        "- All masks are moved to the specified device (GPU/CPU)  \n",
        "- Used in Transformer's attention mechanisms"
      ],
      "metadata": {
        "id": "kB6u3K3Onmu7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiV274g6btSq"
      },
      "outputs": [],
      "source": [
        "def create_masks(question, reply_input, reply_target):\n",
        "    # Create subsequent mask for decoder attention\n",
        "    def subsequent_mask(size):\n",
        "        return torch.triu(torch.ones(size, size), diagonal=1).bool()\n",
        "\n",
        "    # Create question mask (encoder mask)\n",
        "    question_mask = (question != 0).unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "    # Create reply input mask (decoder mask)\n",
        "    reply_input_mask = (reply_input != 0).unsqueeze(1)\n",
        "    reply_input_mask = reply_input_mask.to(device)\n",
        "    subsequent_mask = subsequent_mask(reply_input.size(-1)).unsqueeze(0)\n",
        "    subsequent_mask = subsequent_mask.to(device)\n",
        "    reply_input_mask = reply_input_mask & (~subsequent_mask)\n",
        "    reply_input_mask = reply_input_mask.unsqueeze(1)\n",
        "\n",
        "    # Create reply target mask\n",
        "    reply_target_mask = (reply_target != 0)\n",
        "\n",
        "    # Move all masks to device\n",
        "    question_mask = question_mask.to(device)\n",
        "    reply_input_mask = reply_input_mask.to(device)\n",
        "    reply_target_mask = reply_target_mask.to(device)\n",
        "\n",
        "    return question_mask, reply_input_mask, reply_target_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings with Positional Encoding\n",
        "Creates token embeddings + positional encoding for Transformer models.\n",
        "\n",
        "**Key Features**:\n",
        "- `nn.Embedding`: Converts token IDs to vectors (`d_model` dim)\n",
        "- Sinusoidal positional encoding: Adds sequence position info\n",
        "- Scaling: Embeddings scaled by `√d_model`\n",
        "- Dropout: Regularization via `nn.Dropout`\n",
        "\n",
        "**Positional Encoding**:\n",
        "- Uses alternating sin/cos functions\n",
        "- Unique pattern for each position/dimension\n",
        "- Pre-computed for efficiency\n",
        "\n",
        "**Input/Output**:\n",
        "- Input: Token IDs (batch × seq_len)\n",
        "- Output: Embeddings (batch × seq_len × d_model)"
      ],
      "metadata": {
        "id": "erIvUPJGrNYU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-8q954tfcQx"
      },
      "outputs": [],
      "source": [
        "import math  # Math module for mathematical operations\n",
        "from torch import nn  # PyTorch neural network module\n",
        "\n",
        "class Embeddings(nn.Module):  # Embedding layer with positional encoding\n",
        "  def __init__(self, vocab_size, d_model, dropout, max_len=50):  # Initialize embedding layer\n",
        "    super().__init__()  # Initialize parent class\n",
        "    self.d_model = d_model  # Dimension of embeddings\n",
        "    self.dropout = nn.Dropout(dropout)  # Dropout layer for regularization\n",
        "    self.embed = nn.Embedding(vocab_size, d_model)  # Word embedding lookup table\n",
        "    self.pe = self.create_positional_encoding(max_len, d_model)  # Positional encoding\n",
        "\n",
        "  def create_positional_encoding(self, max_len, d_model):  # Generate positional encodings\n",
        "    pe = torch.zeros(max_len, d_model).to(device)  # Initialize positional encoding matrix\n",
        "    for pos in range(max_len):  # Loop over positions\n",
        "      for i in range(0, d_model, 2):  # Loop over embedding dimensions (step 2)\n",
        "        pe[pos, i]     = math.sin(pos / (10000 ** ((2 * i)       / d_model)))  # Sine for even indices\n",
        "        pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1)) / d_model)))  # Cosine for odd indices\n",
        "\n",
        "    pe = pe.unsqueeze(0)  # Add batch dimension\n",
        "    return pe  # Return positional encodings\n",
        "\n",
        "  def forward(self, encoded_words):  # Forward pass\n",
        "    embeddings  = self.embed(encoded_words) * math.sqrt(self.d_model)  # Scale embeddings\n",
        "    embeddings += self.pe[:, :embeddings.size(1)]  # Add positional encoding\n",
        "    embeddings  = self.dropout(embeddings)  # Apply dropout\n",
        "    return embeddings  # Return final embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Head Attention\n",
        "Implements scaled dot-product attention with multiple heads.\n",
        "\n",
        "**Key Components**:\n",
        "- Linear projections for Q/K/V\n",
        "- Split into `heads` sub-spaces (`d_k = d_model/heads`)\n",
        "- Scaled attention scores with masking\n",
        "- Dropout on attention weights\n",
        "- Concatenation + final linear projection\n",
        "\n",
        "**Operations**:\n",
        "1. Projects Q/K/V (shape: `[batch, seq_len, d_model]`)\n",
        "2. Splits into heads (`[batch, heads, seq_len, d_k]`)\n",
        "3. Computes attention scores:\n",
        "   - `Q * (K.V / √d_k)`\n",
        "   - Masks + softmax\n",
        "4. Weighted sum of values\n",
        "5. Concatenates heads + projects back\n",
        "\n",
        "**Input/Output**:\n",
        "- Input: Q/K/V + attention mask\n",
        "- Output: Context vectors (`[batch, seq_len, d_model]`)"
      ],
      "metadata": {
        "id": "cEyJypH4rhBy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKnMhXri_j41"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):  # Multi-head attention mechanism\n",
        "  def __init__(self, heads, d_model, dropout):  # Initialize attention heads\n",
        "    super().__init__()  # Initialize parent class\n",
        "    assert d_model % heads == 0, f\"d_model ({d_model}) must be divisible by heads ({heads})\"  # Check divisibility\n",
        "    self.heads = heads  # Number of attention heads\n",
        "    self.d_model = d_model  # Model dimension\n",
        "    self.d_k = self.d_model // self.heads  # Dimension per head\n",
        "    self.dropout = nn.Dropout(dropout)  # Dropout for attention weights\n",
        "    self.query  = nn.Linear(self.d_model, self.d_model)  # Query projection\n",
        "    self.key    = nn.Linear(self.d_model, self.d_model)  # Key projection\n",
        "    self.value  = nn.Linear(self.d_model, self.d_model)  # Value projection\n",
        "    self.concat = nn.Linear(self.d_model, self.d_model)  # Final linear layer\n",
        "\n",
        "  def forward(self, query, key, value, mask):  # Forward pass with masking\n",
        "    query = self.query(query)     # (batch_size, max_len, 512)  # Project queries\n",
        "    key   = self.key(key)         # (batch_size, max_len, 512)  # Project keys\n",
        "    value = self.value(value)     # (batch_size, max_len, 512)  # Project values\n",
        "\n",
        "    # Reshape and permute for multi-head attention\n",
        "    query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  # (batch_size, 8, max_len, d_k)\n",
        "    key   = key.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)    # (batch_size, 8, max_len, d_k)\n",
        "    value = value.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  # (batch_size, 8, max_len, d_k)\n",
        "\n",
        "    # Scaled dot-product attention\n",
        "    scores  = torch.matmul(query, key.permute(0, 1, 3, 2)) / math.sqrt(query.size(-1))  # Attention scores\n",
        "    scores  = scores.masked_fill(mask==0, -1e9)  # Apply mask (set masked positions to -inf)\n",
        "    weights = torch.softmax(scores, dim=-1)  # Softmax over last dimension\n",
        "    weights = self.dropout(weights)  # Apply dropout to attention weights\n",
        "\n",
        "    # Compute context vectors\n",
        "    context = torch.matmul(weights, value)  # Weighted sum of values\n",
        "    # Reshape back to original dimensions\n",
        "    context = context.permute(0, 2, 1, 3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
        "    interacted = self.concat(context)  # Final linear transformation\n",
        "\n",
        "    return interacted  # Output after multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FeedForward Network\n",
        "Position-wise fully connected layer for Transformers.\n",
        "\n",
        "**Structure**:\n",
        "1. Expansion: `d_model → middle_dim` (default 2048)\n",
        "2. ReLU activation\n",
        "3. Dropout for regularization\n",
        "4. Projection back to `d_model`\n",
        "\n",
        "**Purpose**:\n",
        "- Adds non-linearity after attention\n",
        "- Processes each position independently\n",
        "- Typically applied to each token separately\n",
        "\n",
        "**Input/Output**:\n",
        "- Input: `[batch, seq_len, d_model]`\n",
        "- Output: `[batch, seq_len, d_model]` (same shape)"
      ],
      "metadata": {
        "id": "V8420uGpsNPT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS9YaXRYGKnh"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, d_model, dropout, middle_dim=2048):\n",
        "    super().__init__()\n",
        "    # Model dimensions and dropout\n",
        "    self.d_model    = d_model\n",
        "    self.dropout    = dropout\n",
        "    self.middle_dim = middle_dim\n",
        "\n",
        "    # Two linear layers with ReLU and dropout\n",
        "    self.fc1     = nn.Linear(self.d_model, self.middle_dim)  # Expansion\n",
        "    self.fc2     = nn.Linear(self.middle_dim, self.d_model)  # Projection back\n",
        "    self.dropout = nn.Dropout(self.dropout)\n",
        "    self.relu    = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Sequential processing: fc1 -> ReLU -> dropout -> fc2\n",
        "    return self.fc2(self.dropout(self.relu(self.fc1(x))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Encoder Layer\n",
        "Processes input through self-attention and feed-forward layers.\n",
        "\n",
        "**Components**:\n",
        "- Multi-head self-attention\n",
        "- Layer normalization (residual connection)\n",
        "- Position-wise feed-forward network\n",
        "- Second layer norm (residual connection)\n",
        "\n",
        "**Flow**:\n",
        "1. Self-attention on input embeddings\n",
        "2. Add & normalize (residual connection)\n",
        "3. Feed-forward processing\n",
        "4. Add & normalize again\n",
        "\n",
        "**Input/Output**:\n",
        "- Input: Embeddings + padding mask\n",
        "- Output: Encoded representations (same shape)"
      ],
      "metadata": {
        "id": "PfVSenLjsvub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0-kX7PZI4xG"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, d_model, heads, dropout):\n",
        "    super().__init__()\n",
        "    # Initialize model dimensions and components\n",
        "    self.d_model = d_model\n",
        "    self.heads    = heads\n",
        "    self.dropout  = dropout\n",
        "\n",
        "    # Encoder layers\n",
        "    self.multi_head   = MultiHeadAttention(self.heads, self.d_model, self.dropout)\n",
        "    self.feed_forward = FeedForward(self.d_model, self.dropout, middle_dim=2048)\n",
        "    self.layer_norm   = nn.LayerNorm(self.d_model)\n",
        "    self.dropout      = nn.Dropout(self.dropout)\n",
        "\n",
        "  def forward(self, embeddings, mask):\n",
        "    # Self-attention with residual connection\n",
        "    interacted   = self.dropout(self.multi_head(embeddings, embeddings, embeddings, mask))\n",
        "    interacted   = self.layer_norm(interacted + embeddings)\n",
        "\n",
        "    # Feed-forward with residual connection\n",
        "    feed_forward = self.dropout(self.feed_forward(interacted))\n",
        "    encoded      = self.layer_norm(feed_forward + interacted)\n",
        "\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Decoder Layer\n",
        "Processes target sequences using self-attention and encoder outputs.\n",
        "\n",
        "**Key Components**:\n",
        "- **Self-attention**: Masked multi-head attention on target sequence\n",
        "- **Encoder attention**: Attends to encoder outputs\n",
        "- **Feed-forward**: Position-wise processing\n",
        "- **Residual connections**: With layer normalization after each step\n",
        "\n",
        "**Inputs**:\n",
        "- `embeddings`: Target token embeddings\n",
        "- `encoded`: Encoder outputs\n",
        "- `src_mask`: Padding mask for encoder outputs\n",
        "- `target_mask`: Combined padding and look-ahead mask\n",
        "\n",
        "**Output**:\n",
        "- Decoded representations (same shape as input embeddings)\n",
        "\n",
        "**Flow**:\n",
        "1. Masked self-attention on targets\n",
        "2. Attention over encoder outputs\n",
        "3. Feed-forward transformation"
      ],
      "metadata": {
        "id": "QN0uadG4s67T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmAIJHaMJ1--"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize model dimensions\n",
        "        self.d_model = d_model\n",
        "        self.heads   = heads\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Decoder components\n",
        "        self.layernorm      = nn.LayerNorm(self.d_model)\n",
        "        self.self_multihead = MultiHeadAttention(self.heads, self.d_model, self.dropout)\n",
        "        self.src_multihead  = MultiHeadAttention(self.heads, self.d_model, self.dropout)\n",
        "        self.feed_forward   = FeedForward(self.d_model, self.dropout)\n",
        "        self.dropout        = nn.Dropout(self.dropout)\n",
        "\n",
        "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
        "        # Self-attention layer with target mask\n",
        "        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n",
        "        query = self.layernorm(query + embeddings)\n",
        "\n",
        "        # Source attention layer with encoder outputs\n",
        "        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n",
        "        interacted = self.layernorm(interacted + query)\n",
        "\n",
        "        # Feed forward network\n",
        "        feed_forward = self.dropout(self.feed_forward(interacted))\n",
        "        decoded      = self.layernorm(feed_forward + interacted)\n",
        "\n",
        "        return decoded"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Model\n",
        "Complete sequence-to-sequence Transformer architecture.\n",
        "\n",
        "**Components**:\n",
        "- **Embedding layer**: Token + positional embeddings\n",
        "- **Encoder stack**: N identical layers (self-attention + FFN)\n",
        "- **Decoder stack**: N identical layers (self-attention + encoder-attention + FFN)\n",
        "- **Output layer**: Linear projection to vocabulary size\n",
        "\n",
        "**Key Features**:\n",
        "- `encode()`: Processes source sequence\n",
        "- `decode()`: Generates target sequence using encoder outputs\n",
        "- Final log-softmax for probability distribution\n",
        "\n",
        "**Inputs**:\n",
        "- `src_words`: Source token IDs\n",
        "- `target_words`: Target token IDs (shifted right)\n",
        "- `src_mask`: Source padding mask\n",
        "- `target_mask`: Target look-ahead + padding mask\n",
        "\n",
        "**Output**:\n",
        "- Log probabilities over vocabulary (batch × seq_len × vocab_size)"
      ],
      "metadata": {
        "id": "SsQgndG8tEVr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlVVtjMGeFdF"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, d_model, heads, num_layers, word_map, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    # Initialize model parameters\n",
        "    self.d_model    = d_model\n",
        "    self.heads      = heads\n",
        "    self.num_layers = num_layers\n",
        "    self.word_map   = word_map\n",
        "    self.dropout    = dropout\n",
        "    self.vocab      = len(self.word_map)\n",
        "\n",
        "    # Model components\n",
        "    self.embed   = Embeddings(self.vocab, self.d_model, self.dropout)\n",
        "    self.encoder = nn.ModuleList([Encoder(self.d_model, self.heads, self.dropout) for _ in range(self.num_layers)])\n",
        "    self.decoder = nn.ModuleList([Decoder(self.d_model, self.heads, self.dropout) for _ in range(self.num_layers)])\n",
        "    self.logit   = nn.Linear(self.d_model, self.vocab)\n",
        "\n",
        "  def encode(self, src_words, src_mask):\n",
        "    # Process source sequence through encoder stack\n",
        "    src_embeddings = self.embed(src_words)\n",
        "    for layer in self.encoder:\n",
        "      src_embeddings = layer(src_embeddings, src_mask)\n",
        "    return src_embeddings\n",
        "\n",
        "  def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
        "    # Process target sequence through decoder stack\n",
        "    target_embeddings = self.embed(target_words)\n",
        "    for layer in self.decoder:\n",
        "      target_embeddings = layer(target_embeddings, src_embeddings, src_mask, target_mask)\n",
        "    return target_embeddings\n",
        "\n",
        "  def forward(self, src_words, src_mask, target_words, target_mask):\n",
        "    # Full transformer forward pass\n",
        "    encoded = self.encode(src_words, src_mask)\n",
        "    decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
        "    out = torch.log_softmax(self.logit(decoded), dim=2)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Purpose**: Implements warmup learning rate schedule for Transformer training\n",
        "\n",
        "**Key Features**:\n",
        "- Linear warmup followed by inverse square root decay\n",
        "- Learning rate formula:\n",
        "  `lr = d_model^(-0.5) * min(step^(-0.5), step*warmup^(-1.5))`\n",
        "- Automatically updates optimizer's LR each step\n",
        "\n",
        "**Usage**:\n",
        "1. Wraps any PyTorch optimizer\n",
        "2. Call `step()` instead of optimizer.step()\n",
        "3. Warmup typically ~4000-8000 steps"
      ],
      "metadata": {
        "id": "IgaMY1p0tZoz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1sBpWcCgWNF"
      },
      "outputs": [],
      "source": [
        "class AdamWarmUp:\n",
        "  def __init__(self, model_size, warmup_size, optimizer):\n",
        "    # Initialize learning rate scheduler parameters\n",
        "    self.model_size   = model_size\n",
        "    self.warmup_size  = warmup_size\n",
        "    self.optimizer    = optimizer\n",
        "    self.current_step = 0\n",
        "    self.lr          = 0\n",
        "\n",
        "  def get_lr(self):\n",
        "    # Calculate learning rate with warmup\n",
        "    return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_size ** (-1.5))\n",
        "\n",
        "  def step(self):\n",
        "    # Update learning rate and optimizer step\n",
        "    self.current_step += 1\n",
        "    lr = self.get_lr()\n",
        "    for param_group in self.optimizer.param_groups:\n",
        "      param_group['lr'] = lr\n",
        "    self.lr = lr\n",
        "    self.optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Purpose**: KLDivLoss with label smoothing regularization\n",
        "\n",
        "**Key Features**:\n",
        "- Distributes `smooth` probability mass over all classes\n",
        "- Keeps `confidence` (1-smooth) for true class\n",
        "- Masks padding positions (zero loss)\n",
        "- Helps prevent overconfidence in predictions\n",
        "\n",
        "**Parameters**:\n",
        "- `size`: Vocabulary size\n",
        "- `smooth`: Smoothing factor (e.g., 0.1)\n",
        "- Processes batches of shape `(seq_len, vocab_size)`"
      ],
      "metadata": {
        "id": "2fb0sxxDtXBq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiFpmgGmvKoo"
      },
      "outputs": [],
      "source": [
        "class LossWithLS(nn.Module):\n",
        "  def __init__(self, size, smooth):\n",
        "    super().__init__()\n",
        "\n",
        "    # Initialize loss components and smoothing parameters\n",
        "    self.criterion  = nn.KLDivLoss(size_average=False, reduce=False)\n",
        "    self.smooth     = smooth\n",
        "    self.confidence = 1 - self.smooth\n",
        "    self.size       = size\n",
        "\n",
        "  def forward(self, prediction, target, mask):\n",
        "    # Reshape tensors for loss calculation\n",
        "    prediction = prediction.view(-1, prediction.size(-1))  # Flatten predictions\n",
        "    target = target.contiguous().view(-1)  # Flatten targets\n",
        "    mask = mask.float()  # Convert mask to float\n",
        "    mask = mask.view(-1)  # Flatten mask\n",
        "\n",
        "    # Apply label smoothing\n",
        "    labels = prediction.data.clone()\n",
        "    labels.fill_(self.smooth / (self.size - 1))  # Uniform distribution\n",
        "    target = target.data.unsqueeze(1)\n",
        "    labels.scatter_(1, target, self.confidence)  # Add confidence to true class\n",
        "\n",
        "    # Calculate and mask the loss\n",
        "    loss = self.criterion(prediction, labels)  # Compute KL divergence\n",
        "    loss = (loss.sum(1) * mask).sum() / mask.sum()  # Apply mask and normalize\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omNsG8xPxuVe"
      },
      "outputs": [],
      "source": [
        "d_model   = 512\n",
        "heads      = 8\n",
        "num_layers = 4\n",
        "\n",
        "with open(\"WORDMAP_corpus.json\", \"r\") as j:\n",
        "  word_map = json.load(j)\n",
        "\n",
        "transformer = Transformer(d_model = d_model,\n",
        "                          heads = heads,\n",
        "                          num_layers = num_layers,\n",
        "                          word_map = word_map,\n",
        "                          dropout = 0.1).to(device)\n",
        "adam_optimizer = torch.optim.Adam(params = transformer.parameters(), lr = 0, betas = (0.9, 0.98), eps=1e-9)\n",
        "transformer_optimizer = AdamWarmUp(model_size=d_model, warmup_size=4000, optimizer=adam_optimizer)\n",
        "criterion = LossWithLS(size=(len(word_map)), smooth=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Training Loop\n",
        "\n",
        "**Key Components**:\n",
        "- **Input Handling**:\n",
        "  - Splits target into `reply_input` (shift right) and `reply_target` (shift left)\n",
        "  - Generates attention masks for encoder/decoder\n",
        "\n",
        "**Training Process**:\n",
        "1. Forward pass:\n",
        "   - Processes question through encoder\n",
        "   - Generates predictions from decoder\n",
        "2. Loss Calculation:\n",
        "   - Uses label-smoothed cross-entropy\n",
        "   - Masks padding positions\n",
        "3. Backpropagation:\n",
        "   - Optimizer step with warmup scheduling\n",
        "   - Gradient zeroing\n",
        "\n",
        "**Logging**:\n",
        "- Prints loss every 250 batches\n",
        "- Saves model checkpoint per epoch\n",
        "- Tracks epoch losses in `total_losses`\n",
        "\n",
        "**Hyperparameters**:\n",
        "- Runs for specified epochs (2 in example)\n",
        "- Uses Adam optimizer with warmup\n",
        "- Batch processing via DataLoader\n",
        "\n",
        "**Output**:\n",
        "- Returns list of average epoch losses\n",
        "- Saves model weights (`transformer_1.pth`, etc.)"
      ],
      "metadata": {
        "id": "1SKdRzi1tpCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkiOmn8K2z9a"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train(train_loader, transformer, criterion, epochs, device):\n",
        "    # Initialize training mode and loss tracking\n",
        "    transformer.train()\n",
        "    total_losses = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        losses = 0\n",
        "        # Process each batch with progress tracking\n",
        "        for batch_number, (question, reply) in enumerate(train_loader, 1):\n",
        "            samples = question.shape[0]\n",
        "            question = question.to(device)\n",
        "            reply = reply.to(device)\n",
        "\n",
        "            # Prepare input/target sequences for teacher forcing\n",
        "            reply_input = reply[:, :-1]    # Exclude last token for input\n",
        "            reply_target = reply[:, 1:]    # Exclude first token for target\n",
        "\n",
        "            # Create attention masks\n",
        "            question_mask, reply_input_mask, reply_target_mask = create_masks(\n",
        "                question, reply_input, reply_target)\n",
        "\n",
        "            # Forward pass\n",
        "            out = transformer(question, question_mask, reply_input, reply_input_mask)\n",
        "\n",
        "            # Calculate loss and update model\n",
        "            loss = criterion(out, reply_target, reply_target_mask)\n",
        "            losses += loss.item()\n",
        "\n",
        "            # Backpropagation and optimization\n",
        "            transformer_optimizer.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            transformer_optimizer.step()\n",
        "\n",
        "            # Periodic progress reporting\n",
        "            if batch_number % 250 == 0:\n",
        "                print(f\"[Batch/Epoch]: [{batch_number}/{len(train_loader)}/{epoch+1}] | Loss: {loss.item():.5f}\")\n",
        "\n",
        "        # Calculate and store epoch metrics\n",
        "        epoch_loss = losses / len(train_loader)\n",
        "        total_losses.append(epoch_loss)\n",
        "\n",
        "        # Save model checkpoint\n",
        "        torch.save(transformer.state_dict(), f\"transformer_{epoch+1}.pth\")\n",
        "\n",
        "    return total_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "3d1be745f19741068f521d63250046cd",
            "f723d315798d45bdaf00a1e97e251896",
            "02496bedfafe4e549101e61719df736f",
            "c0813a05026f4b01999da56128097f50",
            "26833ef9e2804b14b542909fea5e7427",
            "f0463d3c31804499888d114cb9b0e202",
            "c980a141bbed4b3da56376b2e0ea3722",
            "f208d7867b4e45639a7f3a3275e85e0d",
            "39aaecc91c534039b1e07db60a333cf4",
            "c6fa31bb617147c481776093112bf0ba",
            "da13250988c94e439674fe508a1f38ff"
          ]
        },
        "id": "O-z2iex1wOK6",
        "outputId": "a615b434-3286-460f-abb2-9e66c0a87254"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d1be745f19741068f521d63250046cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch/Epoch]: [250/2217/1] | Loss: 4.10102\n",
            "[Batch/Epoch]: [500/2217/1] | Loss: 3.80231\n",
            "[Batch/Epoch]: [750/2217/1] | Loss: 3.57598\n",
            "[Batch/Epoch]: [1000/2217/1] | Loss: 3.58401\n",
            "[Batch/Epoch]: [1250/2217/1] | Loss: 3.60321\n",
            "[Batch/Epoch]: [1500/2217/1] | Loss: 3.37097\n",
            "[Batch/Epoch]: [1750/2217/1] | Loss: 3.42831\n",
            "[Batch/Epoch]: [2000/2217/1] | Loss: 3.47049\n",
            "[Batch/Epoch]: [250/2217/2] | Loss: 3.40443\n",
            "[Batch/Epoch]: [500/2217/2] | Loss: 3.33700\n",
            "[Batch/Epoch]: [750/2217/2] | Loss: 3.23393\n",
            "[Batch/Epoch]: [1000/2217/2] | Loss: 3.36568\n",
            "[Batch/Epoch]: [1250/2217/2] | Loss: 3.30729\n",
            "[Batch/Epoch]: [1500/2217/2] | Loss: 3.31851\n",
            "[Batch/Epoch]: [1750/2217/2] | Loss: 3.25867\n",
            "[Batch/Epoch]: [2000/2217/2] | Loss: 3.35394\n"
          ]
        }
      ],
      "source": [
        "total_losses = train(train_loader, transformer, criterion, 2, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "vAvkqS6EzVKT",
        "outputId": "2136cdc5-87e6-4fd0-9b7b-6a9cf845d1a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78b737154790>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt  # Import the matplotlib plotting library\n",
        "\n",
        "plt.figure(figsize=(15, 7))       # Create a new figure with size 15x7 inches\n",
        "\n",
        "plt.plot(range(len(total_losses)), total_losses, 'r--' ,label=\"Train Loss\")\n",
        "# Plot training losses with red dashed line and label\n",
        "plt.legend()\n",
        "# Display the legend to identify plotted lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB3kxZ4KqiFS",
        "outputId": "07e23138-c6ff-4f6d-a4de-1c1c66511d44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint_path = \"transformer_2.pth\"  # Replace with your saved file\n",
        "state_dict = torch.load(checkpoint_path, map_location=device)  # Load to CPU/GPU\n",
        "transformer.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Decoding Function\n",
        "\n",
        "**Purpose**: Generates responses using either greedy search or top-k sampling\n",
        "\n",
        "**Key Features**:\n",
        "- Supports two decoding modes:\n",
        "  - `top_k=1`: Greedy decoding (always picks highest probability word)\n",
        "  - `top_k>1`: Random sampling from top-k candidates\n",
        "- Handles sequence termination when `<end>` token is generated\n",
        "- Converts token IDs back to words using vocabulary mapping\n",
        "\n",
        "**Workflow**:\n",
        "1. Encodes input question\n",
        "2. Initializes sequence with `<start>` token\n",
        "3. Iteratively decodes:\n",
        "   - Creates target mask for each step\n",
        "   - Gets next word probabilities\n",
        "   - Selects next word based on chosen strategy\n",
        "4. Stops when max length reached or `<end>` token generated\n",
        "\n",
        "**Inputs**:\n",
        "- `question`: Encoded input sequence\n",
        "- `question_mask`: Attention mask for input\n",
        "- `max_len`: Maximum response length\n",
        "- `word_map`: Vocabulary dictionary\n",
        "- `top_k`: Controls decoding strategy\n",
        "\n",
        "**Output**: Generated response string"
      ],
      "metadata": {
        "id": "Isf8AhXRt3G6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWSOlVNFptTZ"
      },
      "outputs": [],
      "source": [
        "def evaluate(transformer, question, question_mask, max_len, word_map, top_k=1):\n",
        "    \"\"\"\n",
        "    Performs decoding using either Greedy (top_k=1) or Top-k sampling (top_k > 1 or None)\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Initialize vocabulary and model mode\n",
        "    rev_word_map = {v: k for k, v in word_map.items()}\n",
        "    transformer.eval()\n",
        "    start_token = word_map['<start>']\n",
        "    end_token = word_map['<end>']\n",
        "\n",
        "    # Encode input question\n",
        "    encoded = transformer.encode(question, question_mask)\n",
        "    words = torch.LongTensor([[start_token]]).to(device)  # Initialize with start token\n",
        "\n",
        "    # Generate output sequence\n",
        "    for step in range(max_len - 1):\n",
        "        # Create target mask for decoder\n",
        "        size = words.shape[1]\n",
        "        target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(torch.uint8)\n",
        "        target_mask = target_mask.to(device).unsqueeze(0)\n",
        "\n",
        "        # Decode current sequence\n",
        "        decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
        "        predictions = transformer.logit(decoded[:, -1])  # Get last prediction\n",
        "        probs = torch.softmax(predictions, dim=1).squeeze(0)  # Convert to probabilities\n",
        "\n",
        "        # Select next word (greedy or sampling)\n",
        "        if top_k != 1:\n",
        "            if top_k is None:\n",
        "                top_ch = np.arange(len(word_map))\n",
        "                p = probs.detach().cpu().numpy()\n",
        "            else:\n",
        "                p, top_ch = torch.topk(probs, k=top_k)\n",
        "                p = p.detach().cpu().numpy()\n",
        "                top_ch = top_ch.detach().cpu().numpy()\n",
        "            next_word = np.random.choice(top_ch, p=p/p.sum())\n",
        "        else:\n",
        "            next_word = torch.argmax(probs).item()\n",
        "\n",
        "        # Stop if end token generated\n",
        "        if next_word == end_token:\n",
        "            break\n",
        "\n",
        "        # Append new word to sequence\n",
        "        next_word_tensor = torch.LongTensor([[next_word]]).to(device)\n",
        "        words = torch.cat([words, next_word_tensor], dim=1)\n",
        "\n",
        "    # Convert indices to words\n",
        "    words = words.squeeze(0).tolist()\n",
        "    sen_idx = [w for w in words if w != start_token]\n",
        "    sentence = \" \".join([rev_word_map[idx] for idx in sen_idx])\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm2QnWg6puaq",
        "outputId": "2aa73376-c2e8-4756-9625-83c86534242e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: tell me your name\n",
            "Max len: 10\n",
            "you dont know what i mean\n",
            "Question: how are you today\n",
            "Max len: 10\n",
            "i was just trying to help you\n",
            "Question: do you know me\n",
            "Max len: 10\n",
            "no i was going to tell you\n",
            "Question: hello\n",
            "Max len: 10\n",
            "i dont know what to do with you\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "while(1):\n",
        "    # Get user input\n",
        "    question = input(\"Question: \")\n",
        "    if question == \"quit\":\n",
        "        break\n",
        "\n",
        "    # Process input sequence\n",
        "    max_len = input(\"Max len: \")\n",
        "    enc_qus = [word_map.get(word, word_map[\"<unk>\"]) for word in question.split()]  # Convert words to indices\n",
        "\n",
        "    # Prepare tensors for model\n",
        "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)  # Add batch dimension\n",
        "    question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  # Create attention mask\n",
        "\n",
        "    # Generate and print response\n",
        "    sentence = evaluate(transformer, question, question_mask, int(max_len), word_map, top_k=5)\n",
        "    print(\"\\nResponse:\", sentence, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPE2KUSiWPjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d1be745f19741068f521d63250046cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f723d315798d45bdaf00a1e97e251896",
              "IPY_MODEL_02496bedfafe4e549101e61719df736f",
              "IPY_MODEL_c0813a05026f4b01999da56128097f50"
            ],
            "layout": "IPY_MODEL_26833ef9e2804b14b542909fea5e7427"
          }
        },
        "f723d315798d45bdaf00a1e97e251896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0463d3c31804499888d114cb9b0e202",
            "placeholder": "​",
            "style": "IPY_MODEL_c980a141bbed4b3da56376b2e0ea3722",
            "value": "100%"
          }
        },
        "02496bedfafe4e549101e61719df736f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f208d7867b4e45639a7f3a3275e85e0d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39aaecc91c534039b1e07db60a333cf4",
            "value": 2
          }
        },
        "c0813a05026f4b01999da56128097f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6fa31bb617147c481776093112bf0ba",
            "placeholder": "​",
            "style": "IPY_MODEL_da13250988c94e439674fe508a1f38ff",
            "value": " 2/2 [15:12&lt;00:00, 456.91s/it]"
          }
        },
        "26833ef9e2804b14b542909fea5e7427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0463d3c31804499888d114cb9b0e202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c980a141bbed4b3da56376b2e0ea3722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f208d7867b4e45639a7f3a3275e85e0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39aaecc91c534039b1e07db60a333cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6fa31bb617147c481776093112bf0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da13250988c94e439674fe508a1f38ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}