{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSYvvV6NqD4E"
   },
   "source": [
    "# Seq2Seq Chatbot Implementation with PyTorch By **Mahdi Momeni**\n",
    "\n",
    "## Overview\n",
    "This notebook implements a sequence-to-sequence (Seq2Seq) neural network for a simple chatbot using PyTorch. The model follows an encoder-decoder architecture with GRU (Gated Recurrent Unit) layers, designed to handle conversational data and generate responses.\n",
    "\n",
    "## Model Architecture\n",
    "The system consists of two main components:\n",
    "1. **Encoder**:\n",
    "   - Embedding layer (vocab_size=2570, embedding_dim=128)\n",
    "   - 2-layer GRU (hidden_size=128) with dropout (p=0.2)\n",
    "   \n",
    "2. **Decoder**:\n",
    "   - Embedding layer (matching encoder dimensions)\n",
    "   - 2-layer GRU (hidden_size=128) with dropout (p=0.2)\n",
    "   - Additional dropout layer (p=0.3)\n",
    "   - Fully connected output layer (hidden_size ->> vocab_size)\n",
    "\n",
    "## Data Representation\n",
    "- Input/output sequences are padded to length 24\n",
    "- Special tokens:\n",
    "  - `<SOS>`: Start of sequence\n",
    "  - `<EOS>`: End of sequence\n",
    "  - `<PAD>`: Padding token\n",
    "- Batch size: 32\n",
    "- Vocabulary size: 2570 unique tokens\n",
    "\n",
    "## Training Process\n",
    "The model processes data in the following format:\n",
    "- Encoder input: `[batch_size, seq_len]` (32, 24)\n",
    "- Decoder input: `[batch_size, seq_len-1]` (not actually but a little teacher-forced)\n",
    "- Target output: `[batch_size, seq_len-1]` (reshaped for loss calculation)\n",
    "\n",
    "## Performance Considerations\n",
    "- Dropout layers are included to prevent overfitting\n",
    "- The model uses batch-first tensor organization\n",
    "- Hidden states are maintained between encoder and decoder\n",
    "- Output is processed through a linear layer to vocabulary size\n",
    "\n",
    "This implementation serves as a foundation for building more advanced conversational AI systems with potential for extensions like attention mechanisms or beam search decoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qa28oRlLDjIu"
   },
   "source": [
    "## **Data Loading and Initial Exploration**  \n",
    "\n",
    "The following code loads the raw dialog data from the `dialogs.txt` file and performs a basic exploratory analysis:  \n",
    "- **Preview**: Displays the first 100 characters to inspect formatting.  \n",
    "- **Character Count**: Measures the total number of characters in the dataset.  \n",
    "- **Word Count**: Estimates the dataset size by counting whitespace-separated tokens.  \n",
    "\n",
    "This initial step helps assess the dataset's scale and structure before further preprocessing (tokenization, cleaning, and splitting into training pairs).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OmKiA8fpk4c",
    "outputId": "e4ccf3de-df82-4334-c5ec-db53ed07d062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi, how are you doing?\ti'm fine. how about yourself?\n",
      "i'm fine. how about yourself?\ti'm pretty good. \n",
      "Character's length: 243885\n",
      "Word's length: 47952\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "with open(\"dialogs.txt\", \"r\") as f:\n",
    "  text = f.read()\n",
    "  print(text[:100])\n",
    "  print(f\"Character's length: {len(text)}\")\n",
    "  print(f\"Word's length: {len(text.split())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF4ZAG3sEyeV"
   },
   "source": [
    "## **Text Normalization and Preprocessing**\n",
    "\n",
    "This step prepares raw dialog data for tokenization by applying critical formatting rules:\n",
    "\n",
    "### **Key Operations**\n",
    "1. **Case Normalization**:  \n",
    "   Converts all text to lowercase to reduce vocabulary complexity.\n",
    "\n",
    "2. **Punctuation Standardization**:  \n",
    "   Isolates key punctuation marks (`, . ? !`) with whitespace to ensure proper tokenization by:\n",
    "   - Adding spaces around each symbol  \n",
    "\n",
    "3. **Output**:  \n",
    "   Processed text is saved to `manipulated_text.txt` for downstream tasks.\n",
    "\n",
    "### **Why This Matters**\n",
    "- **Consistency**: Prevents model confusion from irregular spacing (e.g., \"hello!\" vs \"hello !\").  \n",
    "- **Reproducibility**: Saved intermediate file allows inspection and reuse without reprocessing.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Implementation Notes**\n",
    "- Uses Python's `str.translate()` for efficient bulk character replacement  \n",
    "- Preserves original line structure (conversational turns remain intact)  \n",
    "- Modifiable `change_chars` dictionary can extend to other symbols as needed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "JYZXbc9Yq4BT"
   },
   "outputs": [],
   "source": [
    "def manipulate_text(path):\n",
    "    # Define a function 'manipulate_text' that takes a file path ('path') as input\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        # Open the file at 'path' in read mode ('r') and assign it to file object 'f'\n",
    "\n",
    "        whole_text = f.read().lower()\n",
    "        # Read the entire file content, convert it to lowercase, and store in 'whole_text'\n",
    "\n",
    "        change_chars = {ord(\",\"): \" , \", ord(\".\"): \" . \", ord(\"?\"): \" ? \", ord(\"!\"): \" ! \"}\n",
    "        # Create a translation dictionary:\n",
    "        # - Keys: Unicode code points of punctuation (',', '.', '?', '!')\n",
    "        # - Values: Padded versions (e.g., comma becomes ' , ')\n",
    "\n",
    "        whole_text = whole_text.translate(change_chars)\n",
    "        # Apply the translation to 'whole_text', replacing punctuation with padded versions\n",
    "\n",
    "    with open(\"manipulated_text.txt\", 'w') as f2:\n",
    "        # Open (or create) 'manipulated_text.txt' in write mode ('w') as file object 'f2'\n",
    "\n",
    "      f2.write(whole_text)\n",
    "      # Write the modified 'whole_text' to the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "SrwQR43qVIuq"
   },
   "outputs": [],
   "source": [
    "manipulate_text(\"dialogs.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkPU1rVjHKcj"
   },
   "source": [
    "## **Loading Conversation Pairs**\n",
    "\n",
    "The processed text is loaded into a structured DataFrame with:\n",
    "- **Input**: Speaker's initial utterance  \n",
    "- **Target**: Corresponding response  \n",
    "\n",
    "This tabular format enables direct pairing of training samples for the seq2seq model. The first 5 rows are displayed to verify correct formatting.\n",
    "\n",
    "---\n",
    "\n",
    "Key features:\n",
    "- Clear separation of input/target pairs  \n",
    "- Proper handling of punctuation (from previous normalization)  \n",
    "- Ready for tokenization and sequence processing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "kiWakjDroqPr",
    "outputId": "1e9e1af5-4d88-41b2-ded5-1d2fc0f19715"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"# Display the first 5 rows of the DataFrame for inspection\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i'm fine .  how about yourself ? \",\n          \"i've been great .  what about you ? \",\n          \"i'm pretty good .  thanks for asking . \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i'm pretty good .  thanks for asking . \",\n          \"i've been good .  i'm in school right now . \",\n          \"no problem .  so how have you been ? \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-72b00949-c893-4c59-8ba3-f2b46a142dce\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi ,  how are you doing ?</td>\n",
       "      <td>i'm fine .  how about yourself ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine .  how about yourself ?</td>\n",
       "      <td>i'm pretty good .  thanks for asking .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good .  thanks for asking .</td>\n",
       "      <td>no problem .  so how have you been ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem .  so how have you been ?</td>\n",
       "      <td>i've been great .  what about you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great .  what about you ?</td>\n",
       "      <td>i've been good .  i'm in school right now .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72b00949-c893-4c59-8ba3-f2b46a142dce')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-72b00949-c893-4c59-8ba3-f2b46a142dce button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-72b00949-c893-4c59-8ba3-f2b46a142dce');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-19f92974-283b-4db6-83f1-acaaba61d96e\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19f92974-283b-4db6-83f1-acaaba61d96e')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-19f92974-283b-4db6-83f1-acaaba61d96e button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                     Input  \\\n",
       "0               hi ,  how are you doing ?    \n",
       "1        i'm fine .  how about yourself ?    \n",
       "2  i'm pretty good .  thanks for asking .    \n",
       "3    no problem .  so how have you been ?    \n",
       "4     i've been great .  what about you ?    \n",
       "\n",
       "                                         Target  \n",
       "0             i'm fine .  how about yourself ?   \n",
       "1       i'm pretty good .  thanks for asking .   \n",
       "2         no problem .  so how have you been ?   \n",
       "3          i've been great .  what about you ?   \n",
       "4  i've been good .  i'm in school right now .   "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Import the Pandas library and alias it as 'pd' for convenience\n",
    "\n",
    "df = pd.read_csv('manipulated_text.txt', sep='\\t', names=['Input', 'Target'])\n",
    "# Read a CSV (or text) file into a Pandas DataFrame:\n",
    "# - File: 'manipulated_text.txt'\n",
    "# - Separator: Tab ('\\t')\n",
    "# - Column names: 'Input' and 'Target' (since the file has no headers)\n",
    "\n",
    "df.head(5)\n",
    "# Display the first 5 rows of the DataFrame for inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bsae2cBaIFPV"
   },
   "source": [
    "## **Vocabulary Dictionary Implementation**\n",
    "\n",
    "Following class creates a bidirectional word-integer mapping essential for text processing in neural networks:\n",
    "\n",
    "### **Core Functionality**\n",
    "- **word2int**: Dictionary mapping words to unique indices  \n",
    "- **int2word**: Reverse dictionary mapping indices back to words  \n",
    "- **Dynamic Vocabulary**: Automatically expands with new words via `add_word()`  \n",
    "\n",
    "### **Key Methods**\n",
    "1. `add_word(word)`  \n",
    "   - Assigns a new index to unseen words  \n",
    "   - Maintains consistent two-way mapping  \n",
    "\n",
    "2. `__len__()`  \n",
    "   - Returns current vocabulary size  \n",
    "\n",
    "### **Purpose**\n",
    "- Enables conversion between tokens and numerical representations  \n",
    "- Serves as the foundation for embedding layer initialization  \n",
    "- Preserves index consistency throughout training/inference  \n",
    "\n",
    "*Note: Special tokens (`<SOS>`, `<EOS>`, `<PAD>`) should be added first in most implementations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "d8wIGEzfpxXc"
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    # Define a class 'Dictionary' to map words to unique integers and vice versa\n",
    "\n",
    "    def __init__(self):\n",
    "        # Constructor method: Initializes the dictionary with empty mappings and index 0\n",
    "        self.word2int = {}  # Dictionary to map words to integers (word -> index)\n",
    "        self.int2word = {}  # Dictionary to map integers back to words (index -> word)\n",
    "        self.idx = 0        # Counter to assign the next available index\n",
    "\n",
    "    def add_word(self, word):\n",
    "        # Method to add a word to the dictionary if it doesn't already exist\n",
    "        if word not in self.word2int:  # Check if the word is not already in word2int\n",
    "            self.word2int[word] = self.idx  # Map the word to the current index\n",
    "            self.int2word[self.idx] = word  # Map the index back to the word\n",
    "            self.idx += 1  # Increment index for the next new word\n",
    "\n",
    "    def __len__(self):\n",
    "        # Special method to return the number of words in the dictionary\n",
    "        return len(self.word2int)  # The length of word2int gives the total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "4e3XRMFS5qIc"
   },
   "outputs": [],
   "source": [
    "# Create an instance of Dictionary\n",
    "dictionary = Dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khKmj1kSJDV1"
   },
   "source": [
    "## **Vocabulary Creation & Sentence Encoding**\n",
    "\n",
    "This section:\n",
    "1. **Builds vocabulary** by scanning all words in Input/Target columns  \n",
    "2. **Converts sentences** to integer sequences using the dictionary  \n",
    "\n",
    "Key points:\n",
    "- Each unique word gets assigned an integer ID  \n",
    "- Same word in Input/Target receives the same ID  \n",
    "- Output dataframe (`int_df`) contains numericalized sequences  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "C69Zk5Ud5uh9"
   },
   "outputs": [],
   "source": [
    "tags = ['<SOS>', '<PAD>', '<EOS>']\n",
    "# Define special tokens: Start-of-Sequence, Padding, and End-of-Sequence\n",
    "\n",
    "for tag in tags:\n",
    "    dictionary.add_word(tag)\n",
    "    # Add each special token to the dictionary (ensures they have consistent integer IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "qYAqCIGk1ba8"
   },
   "outputs": [],
   "source": [
    "def sentence_to_ints(sentence):\n",
    "    # Convert a sentence (string) to a list of integer IDs using the dictionary\n",
    "    return [dictionary.word2int[word] for word in sentence.split()]\n",
    "    # Splits the sentence into words and looks up each word's integer ID\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Iterate over each row in the DataFrame (ignoring the index with '_')\n",
    "    for word in row['Input'].split():\n",
    "        dictionary.add_word(word)\n",
    "        # Add each word in the 'Input' column to the dictionary\n",
    "    for word in row['Target'].split():\n",
    "        dictionary.add_word(word)\n",
    "        # Add each word in the 'Target' column to the dictionary\n",
    "\n",
    "int_df = pd.DataFrame(columns=['Input', 'Target'])\n",
    "# Create a new DataFrame to store integer-encoded sentences\n",
    "\n",
    "int_df['Input'] = df['Input'].apply(sentence_to_ints)\n",
    "# Convert 'Input' text to integer sequences and store in the new DataFrame\n",
    "\n",
    "int_df['Target'] = df['Target'].apply(sentence_to_ints)\n",
    "# Convert 'Target' text to integer sequences and store in the new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "grbAMsVv10EV",
    "outputId": "76ea3e0a-12d4-4b26-b5af-46acb5487e75"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"int_df\",\n  \"rows\": 3725,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "int_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-0db7eb52-0275-404b-9633-c11ce5980757\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>[10, 11, 12, 5, 13, 14, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10, 11, 12, 5, 13, 14, 9]</td>\n",
       "      <td>[10, 15, 16, 12, 17, 18, 19, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10, 15, 16, 12, 17, 18, 19, 12]</td>\n",
       "      <td>[20, 21, 12, 22, 5, 23, 7, 24, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20, 21, 12, 22, 5, 23, 7, 24, 9]</td>\n",
       "      <td>[25, 24, 26, 12, 27, 13, 7, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25, 24, 26, 12, 27, 13, 7, 9]</td>\n",
       "      <td>[25, 24, 16, 12, 10, 28, 29, 30, 31, 12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0db7eb52-0275-404b-9633-c11ce5980757')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0db7eb52-0275-404b-9633-c11ce5980757 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0db7eb52-0275-404b-9633-c11ce5980757');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-171022c2-44c9-498b-9cc7-69ab72fd7a73\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-171022c2-44c9-498b-9cc7-69ab72fd7a73')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-171022c2-44c9-498b-9cc7-69ab72fd7a73 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                               Input                                    Target\n",
       "0              [3, 4, 5, 6, 7, 8, 9]                [10, 11, 12, 5, 13, 14, 9]\n",
       "1         [10, 11, 12, 5, 13, 14, 9]          [10, 15, 16, 12, 17, 18, 19, 12]\n",
       "2   [10, 15, 16, 12, 17, 18, 19, 12]         [20, 21, 12, 22, 5, 23, 7, 24, 9]\n",
       "3  [20, 21, 12, 22, 5, 23, 7, 24, 9]            [25, 24, 26, 12, 27, 13, 7, 9]\n",
       "4     [25, 24, 26, 12, 27, 13, 7, 9]  [25, 24, 16, 12, 10, 28, 29, 30, 31, 12]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7aGHOSMmLAf1",
    "outputId": "593e6d43-52a6-440c-d799-fb813658977f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2570\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsZZPnILKDd9"
   },
   "source": [
    "## **Sequence Padding & Special Tokens**\n",
    "\n",
    "This step prepares numericalized sequences for the seq2seq model by:\n",
    "\n",
    "1. **Analyzing Sequence Lengths**:\n",
    "   - Calculates max input and target lengths\n",
    "   - Determines overall padding requirement\n",
    "\n",
    "2. **Applying Padding**:\n",
    "   - Adds `<SOS>` (start) and `<EOS>` (end) tokens to each sequence\n",
    "   - Pads with `<PAD>` tokens to ensure uniform length\n",
    "\n",
    "\n",
    "*Key Benefit*: Creates properly formatted tensors for batch processing while preserving sequence boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4C5_mbJ3pHc",
    "outputId": "57cf5a9e-2e55-459c-efbf-8526463ec7d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 22, 22)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths = int_df['Input'].apply(len)\n",
    "# Calculate the length of each 'Input' sequence in int_df and store in input_lengths\n",
    "\n",
    "target_lengths = int_df['Target'].apply(len)\n",
    "# Calculate the length of each 'Target' sequence in int_df and store in target_lengths\n",
    "\n",
    "max_input_length = max(input_lengths)\n",
    "# Find the maximum sequence length in input_lengths\n",
    "\n",
    "max_target_length = max(target_lengths)\n",
    "# Find the maximum sequence length in target_lengths\n",
    "\n",
    "max_length = max(max_input_length, max_target_length)\n",
    "# Determine the overall maximum sequence length between inputs and targets\n",
    "\n",
    "max_input_length, max_target_length, max_length\n",
    "# Return a tuple of (max_input_length, max_target_length, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "lfvIhRNg4dVc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import NumPy library for array operations\n",
    "\n",
    "def add_padd(list_of_ints, max_length):\n",
    "    # Function to pad a sequence of integers to a fixed length with special tokens\n",
    "    pad = dictionary.word2int['<PAD>']\n",
    "    # Get the integer ID for the padding token '<PAD>' from the dictionary\n",
    "\n",
    "    return np.array(\n",
    "        [dictionary.word2int['<SOS>']] +  # Start with Start-of-Sequence token\n",
    "        list_of_ints +                     # Original sequence\n",
    "        [pad] * (max_length - len(list_of_ints)) +  # Padding tokens to reach max_length\n",
    "        [dictionary.word2int['<EOS>']]     # End with End-of-Sequence token\n",
    "    )\n",
    "    # Returns a NumPy array with the padded sequence\n",
    "\n",
    "int_df['Input'] = int_df['Input'].apply(lambda x: add_padd(x, max_length))\n",
    "# Apply padding to every sequence in the 'Input' column using the max_length\n",
    "\n",
    "int_df['Target'] = int_df['Target'].apply(lambda x: add_padd(x, max_length))\n",
    "# Apply padding to every sequence in the 'Target' column using the max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "naVtA5so5SEV",
    "outputId": "cea65e65-ca15-4bf9-ca79-829ec1fd7eed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"int_df\",\n  \"rows\": 3725,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "int_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-4d0fad34-bac8-4eef-a9c1-2d16216c232f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 3, 4, 5, 6, 7, 8, 9, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 10, 11, 12, 5, 13, 14, 9, 1, 1, 1, 1, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 10, 11, 12, 5, 13, 14, 9, 1, 1, 1, 1, 1, 1...</td>\n",
       "      <td>[0, 10, 15, 16, 12, 17, 18, 19, 12, 1, 1, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 10, 15, 16, 12, 17, 18, 19, 12, 1, 1, 1, 1...</td>\n",
       "      <td>[0, 20, 21, 12, 22, 5, 23, 7, 24, 9, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 20, 21, 12, 22, 5, 23, 7, 24, 9, 1, 1, 1, ...</td>\n",
       "      <td>[0, 25, 24, 26, 12, 27, 13, 7, 9, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 25, 24, 26, 12, 27, 13, 7, 9, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 25, 24, 16, 12, 10, 28, 29, 30, 31, 12, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>[0, 136, 42, 16, 586, 12, 267, 40, 62, 680, 12...</td>\n",
       "      <td>[0, 6, 7, 2569, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>[0, 6, 7, 2569, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 106, 12, 255, 77, 236, 12, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>[0, 106, 12, 255, 77, 236, 12, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 125, 398, 186, 280, 30, 1503, 12, 759, 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>[0, 125, 398, 186, 280, 30, 1503, 12, 759, 129...</td>\n",
       "      <td>[0, 115, 35, 32, 255, 77, 1424, 47, 77, 30, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>[0, 115, 35, 32, 255, 77, 1424, 47, 77, 30, 15...</td>\n",
       "      <td>[0, 609, 2478, 589, 12, 67, 182, 280, 730, 150...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3725 rows Ã— 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d0fad34-bac8-4eef-a9c1-2d16216c232f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-4d0fad34-bac8-4eef-a9c1-2d16216c232f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-4d0fad34-bac8-4eef-a9c1-2d16216c232f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-38c332f1-9c98-4ec5-b746-8e1a1bb5ca6c\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38c332f1-9c98-4ec5-b746-8e1a1bb5ca6c')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-38c332f1-9c98-4ec5-b746-8e1a1bb5ca6c button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "0     [0, 3, 4, 5, 6, 7, 8, 9, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1     [0, 10, 11, 12, 5, 13, 14, 9, 1, 1, 1, 1, 1, 1...   \n",
       "2     [0, 10, 15, 16, 12, 17, 18, 19, 12, 1, 1, 1, 1...   \n",
       "3     [0, 20, 21, 12, 22, 5, 23, 7, 24, 9, 1, 1, 1, ...   \n",
       "4     [0, 25, 24, 26, 12, 27, 13, 7, 9, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "3720  [0, 136, 42, 16, 586, 12, 267, 40, 62, 680, 12...   \n",
       "3721  [0, 6, 7, 2569, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3722  [0, 106, 12, 255, 77, 236, 12, 1, 1, 1, 1, 1, ...   \n",
       "3723  [0, 125, 398, 186, 280, 30, 1503, 12, 759, 129...   \n",
       "3724  [0, 115, 35, 32, 255, 77, 1424, 47, 77, 30, 15...   \n",
       "\n",
       "                                                 Target  \n",
       "0     [0, 10, 11, 12, 5, 13, 14, 9, 1, 1, 1, 1, 1, 1...  \n",
       "1     [0, 10, 15, 16, 12, 17, 18, 19, 12, 1, 1, 1, 1...  \n",
       "2     [0, 20, 21, 12, 22, 5, 23, 7, 24, 9, 1, 1, 1, ...  \n",
       "3     [0, 25, 24, 26, 12, 27, 13, 7, 9, 1, 1, 1, 1, ...  \n",
       "4     [0, 25, 24, 16, 12, 10, 28, 29, 30, 31, 12, 1,...  \n",
       "...                                                 ...  \n",
       "3720  [0, 6, 7, 2569, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3721  [0, 106, 12, 255, 77, 236, 12, 1, 1, 1, 1, 1, ...  \n",
       "3722  [0, 125, 398, 186, 280, 30, 1503, 12, 759, 129...  \n",
       "3723  [0, 115, 35, 32, 255, 77, 1424, 47, 77, 30, 15...  \n",
       "3724  [0, 609, 2478, 589, 12, 67, 182, 280, 730, 150...  \n",
       "\n",
       "[3725 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpSmYtijLW7F"
   },
   "source": [
    "### **Sequence Format Verification**  \n",
    "\n",
    "This code checks the padded sequences by:  \n",
    "- Displaying the integer representation  \n",
    "- Converting back to text (with `<SOS>`, `<EOS>`, and `<PAD>` tokens visible)  \n",
    "- Confirming proper padding and special token handling  \n",
    "\n",
    "*Ensures data is correctly structured before training.*  \n",
    "\n",
    "---\n",
    "\n",
    "**Key Points:**  \n",
    "âœ” Validates padding length  \n",
    "âœ” Verifies special token placement  \n",
    "âœ” Confirms reversible encoding/decoding  \n",
    "\n",
    "*(Example shows first input-target pair from the dataset.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "T_DGCwIx5S4s",
    "outputId": "ac2612c6-e589-41a7-9839-80346c6e7103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4 5 6 7 8 9 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<SOS> hi , how are you doing ? <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(int_df[\"Input\"][0])\n",
    "# Print the first padded input sequence from the DataFrame (as integer IDs)\n",
    "\n",
    "t = \"\"\n",
    "# Initialize an empty string to reconstruct the text from integer IDs\n",
    "\n",
    "for intw in int_df[\"Input\"][0]:\n",
    "    # Iterate through each integer in the first input sequence\n",
    "    if intw != dictionary.word2int['<EOS>']:\n",
    "        # If the integer is NOT the End-of-Sequence token:\n",
    "        t += dictionary.int2word[intw] + \" \"\n",
    "        # Look up its corresponding word and add to string with a space\n",
    "    else:\n",
    "        # If the integer IS the End-of-Sequence token:\n",
    "        t += dictionary.int2word[intw]\n",
    "        # Add the token without a trailing space (end of reconstruction)\n",
    "\n",
    "t\n",
    "# Return/print the reconstructed text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "uEOY_WUp8BoE",
    "outputId": "e7e3fed8-a6c2-42cb-d2a0-ca4df9f08e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 10 11 12  5 13 14  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"<SOS> i'm fine . how about yourself ? <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <EOS>\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(int_df[\"Target\"][0])\n",
    "# Print the first padded target sequence from the DataFrame (as integer IDs)\n",
    "\n",
    "t = \"\"\n",
    "# Initialize an empty string to reconstruct the text from integer IDs\n",
    "\n",
    "for intw in int_df[\"Target\"][0]:\n",
    "    # Iterate through each integer in the first target sequence\n",
    "\n",
    "    if intw != dictionary.word2int['<EOS>']:\n",
    "        # If current integer is NOT the End-of-Sequence token:\n",
    "        t += dictionary.int2word[intw] + \" \"\n",
    "        # Convert integer to word and add it with a trailing space\n",
    "\n",
    "    else:\n",
    "        # If current integer IS the End-of-Sequence token:\n",
    "        t += dictionary.int2word[intw]\n",
    "        # Add the <EOS> token without trailing space\n",
    "\n",
    "t\n",
    "# Output the reconstructed text string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5It2EC4MDgG"
   },
   "source": [
    "### **Data Conversion for Model Input**  \n",
    "\n",
    "This step transforms the DataFrame into a NumPy array with the required 3D structure for training:  \n",
    "\n",
    "- **Input Shape**: `(3725, 2, 24)`  \n",
    "  - `3725` conversation pairs  \n",
    "  - `2` columns (input and target sequences)  \n",
    "  - `24` tokens per sequence (padded length)  \n",
    "\n",
    "*Ready for train test split, tensor conversion and batch loading.*  \n",
    "\n",
    "---\n",
    "\n",
    "**Why This Matters:**  \n",
    "âœ” Ensures compatibility with PyTorch's `DataLoader`  \n",
    "âœ” Maintains sequence alignment between inputs and targets  \n",
    "âœ” Verifies consistent dimensionality for the encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZIFMU4q6b9t",
    "outputId": "cdec9beb-1104-4f8b-8088-d191c4f5cd04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3725, 2)\n",
      "[array([0, 3, 4, 5, 6, 7, 8, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 2])\n",
      " array([ 0, 10, 11, 12,  5, 13, 14,  9,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  2])                                       ]\n",
      "(3725, 2, 24)\n",
      "[[ 0  3  4  5  6  7  8  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2]\n",
      " [ 0 10 11 12  5 13 14  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2]]\n"
     ]
    }
   ],
   "source": [
    "array = int_df.to_numpy()\n",
    "# Convert the DataFrame (with Input and Target columns) to a NumPy array\n",
    "# Resulting shape will be (num_samples, 2) where each sample has [Input, Target]\n",
    "\n",
    "print(array.shape)\n",
    "# Print the shape of the array (number of samples Ã— 2 columns)\n",
    "\n",
    "print(array[0])\n",
    "# Print the first sample (both Input and Target sequences as arrays)\n",
    "\n",
    "new_array = np.stack([np.stack(row) for row in array])\n",
    "# Double stacking:\n",
    "# 1. Inner np.stack(row) converts each [Input, Target] pair into a stacked array\n",
    "# 2. Outer np.stack combines all samples into one 3D array\n",
    "# Final shape will be (num_samples, 2, sequence_length)\n",
    "\n",
    "print(new_array.shape)\n",
    "# Print the new 3D array shape (samples Ã— input/target Ã— sequence_length)\n",
    "\n",
    "print(new_array[0])\n",
    "# Print the first sample's stacked Input and Target sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WkvhGPTNrS9"
   },
   "source": [
    "### **Dataset Splitting for Training and Evaluation**  \n",
    "\n",
    "This code prepares the data for model development by:  \n",
    "\n",
    "1. **Splitting into Train/Test Sets**  \n",
    "   - **80% Training** (2980 samples) â€“ For model learning  \n",
    "   - **20% Testing** (745 samples) â€“ For final evaluation  \n",
    "   - Randomized shuffling (`shuffle=True`) with fixed `random_state=42` for reproducibility  \n",
    "\n",
    "2. **Output Verification**  \n",
    "   - Confirms the split maintains the 3D structure `(samples, input/target, sequence_length)`  \n",
    "   - Sample inspection shows preserved tokenization and padding  \n",
    "\n",
    "*Next Step: These arrays will be converted to PyTorch tensors for training.*  \n",
    "\n",
    "---\n",
    "\n",
    "**Key Details:**  \n",
    "âœ” **Stratified Shuffling**: Ensures balanced distribution of conversation patterns  \n",
    "âœ” **Reproducibility**: Fixed random seed guarantees consistent splits across runs  \n",
    "âœ” **Integrity Check**: First sample shows proper `<SOS>`, `<EOS>`, and `<PAD>` token placement  \n",
    "\n",
    "*(Example displays token IDs from the first training pair.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "UJIgQPTXBKr8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Import the train-test split function from scikit-learn\n",
    "\n",
    "# Split the data (e.g., 80% train, 20% test)\n",
    "train_data, test_data = train_test_split(\n",
    "    new_array,          # The 3D numpy array containing all samples (shape: NÃ—2Ã—L)\n",
    "    test_size=0.2,      # 20% of data will be allocated to test set\n",
    "    shuffle=True,       # Shuffle the data before splitting\n",
    "    random_state=42     # Seed for reproducibility (ensures same split every time)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kGA0hidBRt1",
    "outputId": "3923f186-f0ef-4a65-9be8-35ffa0008582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2980, 2, 24) (745, 2, 24)\n",
      "[[   0  170   38  305   26 1377   12    1    1    1    1    1    1    1\n",
      "     1    1    1    1    1    1    1    1    1    2]\n",
      " [   0   27  819    9    1    1    1    1    1    1    1    1    1    1\n",
      "     1    1    1    1    1    1    1    1    1    2]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)\n",
    "# Prints the shapes of the training and test sets:\n",
    "# - train_data.shape -> (num_train_samples, 2, sequence_length)\n",
    "# - test_data.shape  -> (num_test_samples, 2, sequence_length)\n",
    "# Example output: (800, 2, 20) (200, 2, 20) for an 80/20 split of 1000 samples\n",
    "\n",
    "print(train_data[0])\n",
    "# Prints the first training sample, which contains:\n",
    "# - train_data[0][0] -> Padded Input sequence (with SOS/PAD/EOS tokens)\n",
    "# - train_data[0][1] -> Corresponding padded Target sequence\n",
    "# Example structure:\n",
    "# [\n",
    "#   [SOS_ID, word1_ID, word2_ID, ..., PAD_ID, EOS_ID],  # Input\n",
    "#   [SOS_ID, word1_ID, word2_ID, ..., PAD_ID, EOS_ID]   # Target\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjGyIsmIPDRN"
   },
   "source": [
    "### **PyTorch Dataset and DataLoader Setup**\n",
    "\n",
    "This section implements the data pipeline for model training:\n",
    "\n",
    "#### **Custom Dataset Class**\n",
    "- **Structure**:\n",
    "  - `x`: Input sequences (encoder inputs)\n",
    "  - `y`: Target sequences (decoder inputs/outputs)\n",
    "  - Converts NumPy arrays to PyTorch tensors automatically\n",
    "\n",
    "#### **Data Loading**\n",
    "- **Train/Test Split**:\n",
    "  - Training samples: 2980 (80%)\n",
    "  - Test samples: 745 (20%)\n",
    "- **DataLoader Configuration**:\n",
    "  - Batch size: 32 sequences\n",
    "  - Shuffling enabled for training set\n",
    "  - Automatic batching and memory management\n",
    "\n",
    "#### **Output Verification**\n",
    "- Batch shape: `(32, 24)` for both input and target\n",
    "- Maintains sequence length consistency\n",
    "- Preserves token IDs and padding\n",
    "\n",
    "*Ready for model training with proper batch iteration.*\n",
    "\n",
    "---\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "âœ” Memory-efficient data loading  \n",
    "âœ” Proper tensor conversion  \n",
    "âœ” Batch dimension first (PyTorch convention)  \n",
    "âœ” Shuffling for better training dynamics  \n",
    "\n",
    "*Next: These batches will feed directly into the encoder-decoder model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "I3ccfo_v-W40"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    # Custom PyTorch Dataset class to handle our sequence pairs\n",
    "\n",
    "    def __init__(self, array):\n",
    "        # Initialize dataset with the 3D numpy array\n",
    "        self.x = array[:, 0, :]  # Extract all input sequences (first dimension)\n",
    "        self.y = array[:, 1, :]  # Extract all target sequences (second dimension)\n",
    "        self.x = torch.from_numpy(self.x)  # Convert to PyTorch tensor\n",
    "        self.y = torch.from_numpy(self.y)  # Convert to PyTorch tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample (input-target pair) by index\n",
    "        return self.x[index], self.y[index]\n",
    "        # Returns tuple: (input_sequence, target_sequence)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns total number of samples\n",
    "        return len(self.x)\n",
    "        # Both x and y have same length so either works\n",
    "\n",
    "dataset = CustomDataset(new_array)\n",
    "# Create dataset instance using our prepared 3D array\n",
    "# new_array shape: (num_samples, 2, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dODXvoNDBOnk",
    "outputId": "d7a23bfa-8391-433e-df12-256670e6f425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2980\n",
      "Test size: 745\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_data)\n",
    "# Initialize training dataset with the pre-split training data\n",
    "# - train_data comes from train_test_split() earlier\n",
    "# - CustomDataset will extract input/target pairs and convert to tensors\n",
    "\n",
    "test_dataset = CustomDataset(test_data)\n",
    "# Initialize test dataset with the pre-split test data\n",
    "# - Same processing as training data but with held-out samples\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")  # Should be ~2980 (80% of 3725)\n",
    "# Print number of samples in training set (approximately 80% of total data)\n",
    "# The exact number depends on your original dataset size\n",
    "\n",
    "print(f\"Test size: {len(test_dataset)}\")   # Should be ~745 (20% of 3725)\n",
    "# Print number of samples in test set (approximately 20% of total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NnkXzUhLByJl",
    "outputId": "bb13f799-39ec-45c6-b5a3-54badef969a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 24]) torch.Size([32, 24])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "# Set the number of samples per training batch (common sizes: 32, 64, 128)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,          # Training dataset we created\n",
    "    batch_size=batch_size,  # Number of samples per batch\n",
    "    shuffle=True            # Shuffle samples every epoch (important for training)\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,           # Test dataset we created\n",
    "    batch_size=batch_size,  # Same batch size for consistency\n",
    "    shuffle=True            # Shuffling test can be useful for evaluation\n",
    ")\n",
    "\n",
    "# Get the first batch from the training dataloader\n",
    "batch_x, batch_y = next(iter(train_dataloader))\n",
    "# - iter() creates an iterator from the dataloader\n",
    "# - next() gets the first batch\n",
    "# - batch_x contains input sequences, batch_y contains target sequences\n",
    "\n",
    "print(batch_x.shape, batch_y.shape)\n",
    "# Print the shapes of the batched tensors:\n",
    "# - For batch_size=32 and max_sequence_length=20:\n",
    "#   Output: torch.Size([32, 20]) torch.Size([32, 20])\n",
    "# - First dimension is batch size, second is sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qv9f_Ew3Qaxc"
   },
   "source": [
    "## **Model Architecture Overview**\n",
    "\n",
    "This implements a basic Seq2Seq model for QA System functionality:\n",
    "\n",
    "#### **Core Components**\n",
    "- **Encoder**:\n",
    "  - Embedding layer (2570 vocab -> 128-dim)\n",
    "  - 2-layer GRU (hidden_size=128) with 20% dropout\n",
    "  - Processes input sequences into hidden states\n",
    "\n",
    "- **Decoder**:\n",
    "  - Matching embedding layer\n",
    "  - 2-layer GRU (same hidden size)\n",
    "  - Additional dropout (30%) for regularization\n",
    "  - Final linear layer to predict output tokens (128 -> 2570 vocab)\n",
    "\n",
    "#### **Current Limitations**\n",
    "âš  **No attention mechanism**\n",
    "\n",
    "#### **Design Choices**\n",
    "- Shared vocabulary size (2570 tokens)\n",
    "- Consistent hidden dimensions (128)\n",
    "- Dropout for both encoder (20%) and decoder (30%)\n",
    "- Batch-first tensor organization\n",
    "\n",
    "*This foundation enables basic conversation flow while maintaining extensibility for future improvements.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "duoXUasLCZmV"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super().__init__()  # Initialize parent class (nn.Module)\n",
    "\n",
    "        # Store architecture parameters\n",
    "        self.vocab_size  = vocab_size   # Size of vocabulary (number of unique tokens)\n",
    "        self.embed_size  = embed_size   # Dimension of word embeddings\n",
    "        self.hidden_size = hidden_size  # Dimension of GRU hidden states\n",
    "        self.num_layers  = num_layers   # Number of stacked GRU layers\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Auto-detect device\n",
    "\n",
    "        # Layer definitions\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        # Converts token indices to dense vectors of size embed_size\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.embed_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,  # Expects input as (batch, seq_len, features)\n",
    "            dropout=0.2       # Dropout between GRU layers (if num_layers > 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input shape: (batch_size, sequence_length)\n",
    "        # hidden shape: (num_layers, batch_size, hidden_size)\n",
    "\n",
    "        x = input  # Store input tokens\n",
    "        x = self.embedding(x)  # Convert to embeddings -> (batch_size, seq_len, embed_size)\n",
    "        x, hidden = self.gru(x, hidden)  # Process through GRU\n",
    "\n",
    "        # Returns:\n",
    "        # x - All hidden states (batch_size, seq_len, hidden_size)\n",
    "        # hidden - Final hidden state (num_layers, batch_size, hidden_size)\n",
    "        return x, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with zeros\n",
    "        hidden = torch.zeros(\n",
    "            self.num_layers,\n",
    "            batch_size,\n",
    "            self.hidden_size\n",
    "        ).to(self.device)  # Places on GPU if available\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "3H0CoJHeHoHN"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super().__init__()  # Initialize parent class (nn.Module)\n",
    "\n",
    "        # Store architecture parameters\n",
    "        self.vocab_size = vocab_size  # Size of output vocabulary\n",
    "        self.embed_size = embed_size  # Dimension of word embeddings\n",
    "        self.hidden_size = hidden_size  # GRU hidden state size\n",
    "        self.num_layers = num_layers  # Number of GRU layers\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Auto-detect device\n",
    "\n",
    "        # Layer definitions\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        # Converts token indices to dense vectors\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.embed_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,  # Expects (batch, seq_len, features)\n",
    "            dropout=0.2  # Dropout between GRU layers (if num_layers > 1)\n",
    "        )\n",
    "\n",
    "        self.drop_out = nn.Dropout(0.3, inplace=False)\n",
    "        # Additional dropout for regularization\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        # Final layer to predict next-token probabilities\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input shape: (batch_size, 1) [single token at each step]\n",
    "        # hidden shape: (num_layers, batch_size, hidden_size)\n",
    "\n",
    "        x = self.embedding(input)  # (batch_size, 1, embed_size)\n",
    "\n",
    "        # GRU processing (single step)\n",
    "        output, hidden = self.gru(x, hidden)  # output: (batch_size, 1, hidden_size)\n",
    "\n",
    "        x = self.drop_out(output)  # Apply dropout\n",
    "        x = x.reshape(-1, self.hidden_size)  # Flatten to (batch_size * seq_length, hidden_size)\n",
    "        x = self.fc(x)  # (batch_size, vocab_size) [logits]\n",
    "\n",
    "        return x, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with zeros\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1AI7wd0IaX9",
    "outputId": "2c7ee759-aee9-4056-d45d-fce8e7439df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(2570, 128)\n",
      "  (gru): GRU(128, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      ")\n",
      "DecoderRNN(\n",
      "  (embedding): Embedding(2570, 128)\n",
      "  (gru): GRU(128, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (drop_out): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=2570, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size  = len(dictionary.word2int)\n",
    "# Get total vocabulary size from dictionary (includes all words + special tokens)\n",
    "\n",
    "embed_size  = 128\n",
    "# Dimension of word embeddings (typical range: 100-300)\n",
    "\n",
    "hidden_size = 128\n",
    "# Size of GRU hidden states (often same as embed_size for simplicity)\n",
    "\n",
    "num_layers  = 2\n",
    "# Number of stacked GRU layers (more layers = more complex patterns)\n",
    "\n",
    "# Initialize Encoder\n",
    "encoder_net = EncoderRNN(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_size=embed_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers\n",
    ")\n",
    "# Creates:\n",
    "# 1. Embedding layer (vocab_size -> embed_size)\n",
    "# 2. GRU layer (embed_size -> hidden_size)\n",
    "\n",
    "# Initialize Decoder\n",
    "decoder_net = DecoderRNN(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_size=embed_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers\n",
    ")\n",
    "# Creates:\n",
    "# 1. Embedding layer (same as encoder)\n",
    "# 2. GRU layer (same config as encoder)\n",
    "# 3. Additional dropout\n",
    "# 4. Final linear layer (hidden_size -> vocab_size)\n",
    "\n",
    "# Print model architectures\n",
    "print(encoder_net)\n",
    "print(decoder_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaZnF2g2RjSV"
   },
   "source": [
    "### **Model Forward Pass Verification**\n",
    "\n",
    "This test run validates the model's data flow and tensor shapes:\n",
    "\n",
    "#### **Key Operations**\n",
    "- **Device Setup**: Automatically uses GPU if available\n",
    "- **Encoder**:\n",
    "  - Input: `[32, 24]` (batch, seq_len)\n",
    "  - Output: `[32, 24, 128]` (sequence representations)\n",
    "- **Decoder**:\n",
    "  - Input: `[32, 23]` (teacher-forced, right-shifted)\n",
    "  - Output: `[736, 2570]` (flattened logits for loss calculation)\n",
    "\n",
    "#### **Shape Verification**\n",
    "âœ” Maintains consistent hidden dimensions (128)  \n",
    "âœ” Proper sequence length handling (24->23 for teacher forcing)  \n",
    "âœ” Correct output reshaping for cross-entropy loss  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpYInVVxgkKh",
    "outputId": "d7e80814-1152-40e8-d9c1-8bb7a1262399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input: torch.Size([32, 24])\n",
      "Encoder hidden in: torch.Size([2, 32, 128])\n",
      "Encoder output: torch.Size([32, 24, 128])\n",
      "Encoder hidden out: torch.Size([2, 32, 128])\n",
      "\n",
      "Decoder input: torch.Size([32, 23])\n",
      "Decoder hidden in: torch.Size([2, 32, 128])\n",
      "Decoder output: torch.Size([736, 2570])\n",
      "Decoder hidden out: torch.Size([2, 32, 128])\n",
      "Target: torch.Size([32, 23])\n",
      "Target reshaped: torch.Size([736])\n"
     ]
    }
   ],
   "source": [
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move models to device\n",
    "encoder_net = encoder_net.to(device)\n",
    "decoder_net = decoder_net.to(device)\n",
    "\n",
    "# Get a batch from dataloader\n",
    "batch_x, batch_y = next(iter(train_dataloader))\n",
    "batch_size = batch_x.shape[0]\n",
    "\n",
    "# --- ENCODER PASS ---\n",
    "encoder_input = batch_x.to(device)  # Shape: [batch_size, seq_len]\n",
    "print(f\"Encoder input: {encoder_input.shape}\")\n",
    "# Example: [32, 20] (batch of 32 sequences, each length 20)\n",
    "\n",
    "encoder_hidden = encoder_net.init_hidden(batch_size)  # Shape: [num_layers, batch_size, hidden_size]\n",
    "print(f\"Encoder hidden in: {encoder_hidden.shape}\")\n",
    "# Example: [2, 32, 128] (2 layers, 32 sequences, 128-dim hidden state)\n",
    "\n",
    "encoder_output, encoder_hidden = encoder_net(encoder_input, encoder_hidden)\n",
    "print(f\"Encoder output: {encoder_output.shape}\")  # Shape: [batch_size, seq_len, hidden_size]\n",
    "# Example: [32, 20, 128] (all hidden states for each sequence position)\n",
    "print(f\"Encoder hidden out: {encoder_hidden.shape}\\n\")  # Shape same as input hidden\n",
    "# Example: [2, 32, 128] (final hidden state at each layer)\n",
    "\n",
    "# --- DECODER PASS ---\n",
    "# Teacher forcing: feed previous target as next input (shifted by one)\n",
    "decoder_input = batch_y[:, :-1].to(device)  # Remove last token, Shape: [batch_size, seq_len-1]\n",
    "print(f\"Decoder input: {decoder_input.shape}\")\n",
    "# Example: [32, 19] (original seq_len=20, now 19 for teacher forcing)\n",
    "\n",
    "decoder_hidden = encoder_hidden  # Initialize with encoder's final hidden state\n",
    "print(f\"Decoder hidden in: {decoder_hidden.shape}\")  # Shape: [num_layers, batch_size, hidden_size]\n",
    "# Example: [2, 32, 128]\n",
    "\n",
    "decoder_output, decoder_hidden = decoder_net(decoder_input, decoder_hidden)\n",
    "print(f\"Decoder output: {decoder_output.shape}\")  # Shape: [batch_size*(seq_len-1), vocab_size]\n",
    "# Example: [608, 5000] (32*19=608, vocab_size=5000)\n",
    "print(f\"Decoder hidden out: {decoder_hidden.shape}\")  # Shape same as input hidden\n",
    "# Example: [2, 32, 128]\n",
    "\n",
    "# --- TARGETS FOR LOSS CALCULATION ---\n",
    "target = batch_y[:, 1:].to(device)  # Remove first token (shifted right), Shape: [batch_size, seq_len-1]\n",
    "print(f\"Target: {target.shape}\")\n",
    "# Example: [32, 19] (compare with decoder output)\n",
    "print(f\"Target reshaped: {target.reshape(-1,).shape}\")  # Flattened for loss: [batch_size*(seq_len-1)]\n",
    "# Example: [608] (matches first dim of decoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQMAaJRpSW-t"
   },
   "source": [
    "## **Seq2Seq Model Training Implementation**\n",
    "\n",
    "This section implements the complete training loop for the encoder-decoder chatbot (QA System) model with the following key components:\n",
    "\n",
    "### **Training Configuration**\n",
    "- **Optimizers**:\n",
    "  - Separate Adam optimizers for encoder/decoder (lr=0.001)\n",
    "  - Weight decay (L2 regularization) of 1e-5\n",
    "- **Loss Function**:\n",
    "  - CrossEntropyLoss with:\n",
    "    - Padding index ignored (`<PAD>`)\n",
    "    - Label smoothing (0.1) for regularization\n",
    "- **Training Protocol**:\n",
    "  - Batch processing (size=32)\n",
    "  - Gradient clipping (max_norm=5)\n",
    "  - Early stopping (patience=3)\n",
    "  - Best model checkpointing\n",
    "\n",
    "### **Key Training Steps**\n",
    "1. **Forward Pass**:\n",
    "   - Encoder processes input sequence -> hidden states\n",
    "   - Decoder uses teacher forcing (shifted targets)\n",
    "   - Target reshaped for loss calculation\n",
    "\n",
    "2. **Backward Pass**:\n",
    "   - Gradient computation via backpropagation\n",
    "   - Gradient clipping for stability\n",
    "   - Parameter updates\n",
    "\n",
    "3. **Validation**:\n",
    "   - Full inference mode (no gradients)\n",
    "   - Identical forward pass as training\n",
    "   - Tracks best validation loss\n",
    "\n",
    "### **Training Monitoring**\n",
    "- Per-epoch metrics:\n",
    "  - Training loss (average per batch)\n",
    "  - Validation loss\n",
    "  - Early stopping counter\n",
    "- Progress tracking via tqdm\n",
    "- Automatic device management (GPU/CPU)\n",
    "\n",
    "### **Implementation Notes**\n",
    "- Teacher forcing: Uses shifted targets (y[:, :-1]) as decoder input\n",
    "- Target reshaping: Flattens for cross-entropy calculation\n",
    "- Memory efficiency: Processes one batch at a time\n",
    "- Reproducibility: Deterministic operations where possible\n",
    "\n",
    "*Output: Returns training/validation loss histories for analysis.*\n",
    "\n",
    "---\n",
    "\n",
    "**Visualization Ready**:\n",
    "The returned `total_train_losses` and `total_val_losses` arrays can be directly plotted to analyze learning curves and model convergence.\n",
    "\n",
    "This implementation balances computational efficiency with training stability while maintaining clear separation between training and validation phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "fcX9zXAoWgya"
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "# Import default_timer from timeit module and alias it as timer\n",
    "from tqdm.auto import tqdm\n",
    "# Import tqdm from tqdm.auto for progress bar visualization\n",
    "\n",
    "def train(encoder_net, decoder_net, train_data, test_data, dictionary,\n",
    "          device, epochs=20, lr=0.01):\n",
    "    # Define train function with parameters for encoder and decoder networks, data, dictionary, device, epochs (default 20), and learning rate (default 0.01)\n",
    "\n",
    "    # Set optimizer\n",
    "    encoder_optimizer = torch.optim.Adam(params=encoder_net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    # Initialize Adam optimizer for encoder with model parameters, specified learning rate, and weight decay of 1e-5\n",
    "    decoder_optimizer = torch.optim.Adam(params=decoder_net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    # Initialize Adam optimizer for decoder with model parameters, specified learning rate, and weight decay of 1e-5\n",
    "\n",
    "    # Set criterion\n",
    "    pad_idx = dictionary.word2int[\"<PAD>\"]\n",
    "    # Get index of padding token from dictionary\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx, label_smoothing=0.1)  # Consider ignoring padding index if you have one\n",
    "    # Initialize CrossEntropyLoss with padding index ignored and label smoothing of 0.1\n",
    "\n",
    "    total_train_losses = []\n",
    "    # Initialize empty list to store average training losses for each epoch\n",
    "    total_val_losses = []\n",
    "    # Initialize empty list to store average validation losses for each epoch\n",
    "    best_val_loss = float('inf')\n",
    "    # Initialize best validation loss as infinity\n",
    "    patience = 3\n",
    "    # Set patience for early stopping to 3 epochs\n",
    "    epochs_no_improve = 0\n",
    "    # Initialize counter for epochs with no improvement in validation loss\n",
    "    encoder_state_dict = None\n",
    "    # Initialize variable to store best encoder model weights\n",
    "    decoder_state_dict = None\n",
    "    # Initialize variable to store best decoder model weights\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Iterate over epochs with progress bar using tqdm\n",
    "        # Set models on train mode\n",
    "        encoder_net.train()\n",
    "        # Set encoder network to training mode\n",
    "        decoder_net.train()\n",
    "        # Set decoder network to training mode\n",
    "\n",
    "        train_losses, val_losses = 0, 0\n",
    "        # Initialize accumulators for training and validation losses\n",
    "        train_batches, val_batches = 0, 0\n",
    "        # Initialize counters for training and validation batches\n",
    "\n",
    "        for X, y in train_data:\n",
    "            # Iterate over batches in training data\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Move input data X and target y to specified device (e.g., GPU)\n",
    "            batch_size = X.size(0)\n",
    "            # Get batch size from the first dimension of X\n",
    "\n",
    "            # Initialize hidden state for each batch\n",
    "            encoder_hidden = encoder_net.init_hidden(batch_size)\n",
    "            # Initialize encoder's hidden state for the current batch size\n",
    "\n",
    "            # Zero gradients\n",
    "            encoder_optimizer.zero_grad()\n",
    "            # Clear gradients for encoder optimizer\n",
    "            decoder_optimizer.zero_grad()\n",
    "            # Clear gradients for decoder optimizer\n",
    "\n",
    "            # Pass through network\n",
    "            encoder_output, encoder_hidden_out = encoder_net(X, encoder_hidden)\n",
    "            # Forward pass through encoder with input X and initial hidden state\n",
    "            decoder_input = y[:, :-1]\n",
    "            # Prepare decoder input by taking all but the last token of target y\n",
    "            decoder_target = y[:, 1:].reshape((-1,))\n",
    "            # Prepare decoder target by taking all but the first token of y and flattening\n",
    "            decoder_output, _ = decoder_net(decoder_input, encoder_hidden_out)\n",
    "            # Forward pass through decoder with decoder input and encoder's hidden output\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(decoder_output, decoder_target)\n",
    "            # Compute loss between decoder output and target using defined criterion\n",
    "            train_losses += loss.item()\n",
    "            # Accumulate training loss\n",
    "            train_batches += 1\n",
    "            # Increment training batch counter\n",
    "\n",
    "            # Loss backward\n",
    "            loss.backward()\n",
    "            # Backpropagate the loss to compute gradients\n",
    "\n",
    "            # Clip gradients\n",
    "            nn.utils.clip_grad_norm_(encoder_net.parameters(), 5)\n",
    "            # Clip encoder gradients to maximum norm of 5 to prevent exploding gradients\n",
    "            nn.utils.clip_grad_norm_(decoder_net.parameters(), 5)\n",
    "            # Clip decoder gradients to maximum norm of 5 to prevent exploding gradients\n",
    "\n",
    "            # Optimizer step\n",
    "            encoder_optimizer.step()\n",
    "            # Update encoder parameters using optimizer\n",
    "            decoder_optimizer.step()\n",
    "            # Update decoder parameters using optimizer\n",
    "\n",
    "        # Validation\n",
    "        encoder_net.eval()\n",
    "        # Set encoder network to evaluation mode\n",
    "        decoder_net.eval()\n",
    "        # Set decoder network to evaluation mode\n",
    "        with torch.inference_mode():\n",
    "            # Context manager to disable gradient computation for validation\n",
    "            for X, y in test_data:\n",
    "                # Iterate over batches in test data\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                # Move input data X and target y to specified device\n",
    "                batch_size = X.size(0)\n",
    "                # Get batch size from the first dimension of X\n",
    "\n",
    "                encoder_hidden = encoder_net.init_hidden(batch_size)\n",
    "                # Initialize encoder's hidden state for the current batch size\n",
    "\n",
    "                encoder_output, encoder_hidden_out = encoder_net(X, encoder_hidden)\n",
    "                # Forward pass through encoder with input X and initial hidden state\n",
    "                decoder_input = y[:, :-1]\n",
    "                # Prepare decoder input by taking all but the last token of target y\n",
    "                decoder_target = y[:, 1:].reshape((-1,))\n",
    "                # Prepare decoder target by taking all but the first token of y and flattening\n",
    "                decoder_output, _ = decoder_net(decoder_input, encoder_hidden_out)\n",
    "                # Forward pass through decoder with decoder input and encoder's hidden output\n",
    "\n",
    "                val_loss = criterion(decoder_output, decoder_target)\n",
    "                # Compute validation loss between decoder output and target\n",
    "                val_losses += val_loss.item()\n",
    "                # Accumulate validation loss\n",
    "                val_batches += 1\n",
    "                # Increment validation batch counter\n",
    "\n",
    "        # Calculate average losses\n",
    "        avg_train_loss = train_losses / train_batches\n",
    "        # Compute average training loss for the epoch\n",
    "        avg_val_loss = val_losses / val_batches\n",
    "        # Compute average validation loss for the epoch\n",
    "        total_train_losses.append(avg_train_loss)\n",
    "        # Append average training loss to total_train_losses list\n",
    "        total_val_losses.append(avg_val_loss)\n",
    "        # Append average validation loss to total_val_losses list\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs} | Loss: {avg_train_loss:.4f} | Val loss: {avg_val_loss:.4f}\")\n",
    "        # Print epoch number, total epochs, average training loss, and average validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            # Check if current validation loss is better than the best recorded\n",
    "            print(f\"New best validation loss: {avg_val_loss:.4f}\")\n",
    "            # Print message indicating new best validation loss\n",
    "            best_val_loss = avg_val_loss\n",
    "            # Update best validation loss\n",
    "            epochs_no_improve = 0\n",
    "            # Reset counter for epochs with no improvement\n",
    "            encoder_state_dict = encoder_net.state_dict()\n",
    "            # Save current encoder model weights\n",
    "            decoder_state_dict = decoder_net.state_dict()\n",
    "            # Save current decoder model weights\n",
    "        else:\n",
    "            # If validation loss is not improved\n",
    "            epochs_no_improve += 1\n",
    "            # Increment counter for epochs with no improvement\n",
    "            if epochs_no_improve == patience:\n",
    "                # Check if number of epochs with no improvement equals patience\n",
    "                print(\"Early stopping!\")\n",
    "                # Print message indicating early stopping\n",
    "                encoder_net.load_state_dict(encoder_state_dict)  # Load best encoder weights\n",
    "                # Load the best saved encoder weights\n",
    "                decoder_net.load_state_dict(decoder_state_dict)  # Load best decoder weights\n",
    "                # Load the best saved decoder weights\n",
    "                break\n",
    "                # Exit the training loop\n",
    "\n",
    "    return total_train_losses, total_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500,
     "referenced_widgets": [
      "44cd3e1ed8484a8389cbd7fca08e298a",
      "e4b40f463b634e32adf5df1be8300eed",
      "6388916a99fd484ebfd5ff7c16999b60",
      "7b89df1f4d914218940cdb923c661afa",
      "eb114418ea9b47b3bf9466622084b9a3",
      "c5d8675de73d4b7eb87c7366cccb3159",
      "b756d811d34e4e60a5a1273276974e8b",
      "8b5a891b52d84474bdedb1d6115c00d0",
      "4ab0f762b2964e8d84c5f0344fd12188",
      "4f8d6ea332c747acacfcec7c86d47b44",
      "79e95dff0cac43f99e955af3cbea1aa9"
     ]
    },
    "id": "vDkj9n4aaJmT",
    "outputId": "f5129953-59f5-4c6e-d5f3-cdf21c7c35f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cd3e1ed8484a8389cbd7fca08e298a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20 | Loss: 5.8053 | Val loss: 5.3366\n",
      "New best validation loss: 5.3366\n",
      "Epoch: 2/20 | Loss: 5.2922 | Val loss: 5.1460\n",
      "New best validation loss: 5.1460\n",
      "Epoch: 3/20 | Loss: 5.0717 | Val loss: 4.9504\n",
      "New best validation loss: 4.9504\n",
      "Epoch: 4/20 | Loss: 4.8532 | Val loss: 4.8125\n",
      "New best validation loss: 4.8125\n",
      "Epoch: 5/20 | Loss: 4.6861 | Val loss: 4.7201\n",
      "New best validation loss: 4.7201\n",
      "Epoch: 6/20 | Loss: 4.5510 | Val loss: 4.6615\n",
      "New best validation loss: 4.6615\n",
      "Epoch: 7/20 | Loss: 4.4319 | Val loss: 4.6197\n",
      "New best validation loss: 4.6197\n",
      "Epoch: 8/20 | Loss: 4.3290 | Val loss: 4.5661\n",
      "New best validation loss: 4.5661\n",
      "Epoch: 9/20 | Loss: 4.2210 | Val loss: 4.5698\n",
      "Epoch: 10/20 | Loss: 4.1279 | Val loss: 4.5475\n",
      "New best validation loss: 4.5475\n",
      "Epoch: 11/20 | Loss: 4.0307 | Val loss: 4.5530\n",
      "Epoch: 12/20 | Loss: 3.9490 | Val loss: 4.5156\n",
      "New best validation loss: 4.5156\n",
      "Epoch: 13/20 | Loss: 3.8684 | Val loss: 4.5174\n",
      "Epoch: 14/20 | Loss: 3.7920 | Val loss: 4.5173\n",
      "Epoch: 15/20 | Loss: 3.7159 | Val loss: 4.5395\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "total_train_losses, total_val_losses = train(encoder_net=encoder_net, decoder_net=decoder_net,\n",
    "      # Call the train function with specified encoder and decoder networks\n",
    "      train_data=train_dataloader, test_data=test_dataloader,dictionary=dictionary,\n",
    "      # Pass training and testing dataloaders along with a dictionary\n",
    "      device=device, epochs=20, lr=0.001)\n",
    "      # Set the device, number of epochs, and learning rate for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "aYLr-VfvaRwR",
    "outputId": "cb1b020c-b358-46ae-ae70-f8b434c2869f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ffa56126dd0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # Import the matplotlib plotting library\n",
    "\n",
    "plt.figure(figsize=(15, 7))       # Create a new figure with size 15x7 inches\n",
    "\n",
    "plt.plot(total_train_losses, 'r--' ,label=\"Train Loss\")\n",
    "# Plot training losses with red dashed line and label\n",
    "plt.plot(total_val_losses, 'b--',label=\"Validation Loss\")\n",
    "# Plot validation losses with blue dashed line and label\n",
    "plt.legend()\n",
    "# Display the legend to identify plotted lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XxEuuoYUBQM"
   },
   "source": [
    "## **Text Generation Function**\n",
    "\n",
    "This function implements the chatbot's response generation pipeline:\n",
    "\n",
    "#### **Core Process Flow**\n",
    "1. **Input Preprocessing**:\n",
    "   - Converts input to lowercase\n",
    "   - Adds `<SOS>` and `<EOS>` tokens\n",
    "   - Translates words to integer IDs using vocabulary\n",
    "\n",
    "2. **Encoder Phase**:\n",
    "   - Processes input sequence into context vectors\n",
    "   - Generates initial hidden state for decoder\n",
    "\n",
    "3. **Decoder Phase**:\n",
    "   - Starts with `<SOS>` token\n",
    "   - Generates words sequentially using:\n",
    "     - Greedy search (`top_k=1`) or\n",
    "     - Top-K sampling (`top_k>1`) with temperature\n",
    "   - Stops at `<EOS>` or 50-word limit\n",
    "\n",
    "4. **Postprocessing**:\n",
    "   - Cleans punctuation spacing\n",
    "   - Returns natural-looking text\n",
    "\n",
    "#### **Key Parameters**\n",
    "- `top_k`: Controls diversity:\n",
    "  - `1` = deterministic/greedy\n",
    "  - `>1` = random sampling from top K options\n",
    "- `max_length`: Prevents infinite loops (50 words)\n",
    "\n",
    "#### **Example Output**\n",
    "Shows the probabilistic nature of generation - responses vary based on sampling.\n",
    "\n",
    "#### **Implementation Notes**\n",
    "- Maintains proper device placement (GPU/CPU)\n",
    "- Handles edge cases (OOV words via dictionary)\n",
    "- Includes basic punctuation formatting\n",
    "- Uses teacher-forcing during training only\n",
    "\n",
    "This function serves as the interface between the trained model and end-users, converting model outputs into human-readable responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "JZ3Yl5h3nPwB"
   },
   "outputs": [],
   "source": [
    "def generate_text(input_text, top_k, encoder_net, decoder_net, dictionary):\n",
    "  # Define a function to generate text given input and models\n",
    "    input_text = input_text.lower()\n",
    "    # Convert input text to lowercase\n",
    "    list_of_words = input_text.split()\n",
    "    # Split input text into words\n",
    "    list_of_words = [\"<SOS>\"] + list_of_words + [\"<EOS>\"]\n",
    "    # Add start-of-sequence and end-of-sequence tokens\n",
    "    int_list_of_words = []\n",
    "    # Initialize list for word indices\n",
    "\n",
    "    for word in list_of_words:\n",
    "      # Convert each word to its integer representation\n",
    "        int_list_of_words.append(dictionary.word2int[word])\n",
    "\n",
    "    encoder_input = torch.tensor(int_list_of_words).reshape(1, -1).to(device)\n",
    "    # Create tensor from word indices and reshape for batch size 1, move to device\n",
    "    encoder_init_hidden = encoder_net.init_hidden(batch_size=1)\n",
    "    # Initialize hidden state for encoder\n",
    "\n",
    "    encoder_output, encoder_hidden_out = encoder_net(encoder_input, encoder_init_hidden)\n",
    "    # Pass input through encoder\n",
    "\n",
    "    sos_tag = dictionary.word2int[\"<SOS>\"]\n",
    "    # Get integer index for <SOS>\n",
    "    eos_tag = dictionary.word2int[\"<EOS>\"]\n",
    "    # Get integer index for <EOS>\n",
    "\n",
    "    decoder_input = torch.full((1, 1), sos_tag).to(device)\n",
    "    # Initialize decoder input with <SOS> token\n",
    "    decoder_hidden = encoder_hidden_out\n",
    "    # Initialize decoder hidden state with encoder's output hidden state\n",
    "\n",
    "    generated_words = []  # Use a list to collect words\n",
    "    # Initialize list to hold generated words\n",
    "    generate = True\n",
    "    # Control variable for generation loop\n",
    "    while generate:\n",
    "      # Loop to generate words until stopping condition\n",
    "        decoder_output, decoder_hidden = decoder_net(decoder_input, decoder_hidden)\n",
    "        # Get decoder output and new hidden state\n",
    "\n",
    "        p = torch.softmax(decoder_output, dim=1).data\n",
    "        # Apply softmax to get probabilities\n",
    "        p = p.to(device)\n",
    "        # Move probabilities tensor to device\n",
    "\n",
    "        if top_k != 1:\n",
    "            # If using top-k sampling (not greedy)\n",
    "            if top_k is None:\n",
    "                # If top_k is None, consider all vocabulary indices\n",
    "                top_ch = np.arange(len(dictionary))\n",
    "            else:\n",
    "                p, top_ch = p.topk(top_k)\n",
    "                # Get top_k probabilities and indices\n",
    "                top_ch = top_ch.cpu().numpy().squeeze()\n",
    "                # Convert indices to numpy array\n",
    "\n",
    "            p = p.cpu().numpy().squeeze()\n",
    "            # Convert probabilities to numpy array\n",
    "            next_word_idx = np.random.choice(top_ch, p=p/p.sum())\n",
    "            # Sample next word index from top_k probabilities\n",
    "        else:\n",
    "            next_word_idx = p.argmax(dim=1).cpu().numpy().squeeze().item()\n",
    "            # Greedy: choose word with highest probability\n",
    "\n",
    "        next_word = dictionary.int2word[next_word_idx]\n",
    "        # Map predicted index back to word\n",
    "\n",
    "        # Stop if we hit EOS or if the sequence is too long\n",
    "        if next_word == \"<EOS>\" or len(generated_words) > 50:\n",
    "          # Stop generation if end token or max length reached\n",
    "            generate = False\n",
    "        elif next_word != \"<SOS>\":\n",
    "          # Skip adding <SOS> token to output\n",
    "            generated_words.append(next_word)\n",
    "            # Append generated word to list\n",
    "\n",
    "        decoder_input = torch.full((1, 1), next_word_idx).to(device)\n",
    "        # Set decoder input for next iteration to predicted word\n",
    "\n",
    "    # Join words with spaces, but handle punctuation properly\n",
    "    generated_text = \" \".join(generated_words)\n",
    "    # Join generated words into a string\n",
    "\n",
    "    # Basic punctuation spacing (you might need more sophisticated handling)\n",
    "    generated_text = generated_text.replace(\" ,\", \",\")\n",
    "    # Fix spacing before commas\n",
    "    generated_text = generated_text.replace(\" .\", \".\")\n",
    "    # Fix spacing before periods\n",
    "    generated_text = generated_text.replace(\" ?\", \"?\")\n",
    "    # Fix spacing before question marks\n",
    "    generated_text = generated_text.replace(\" !\", \"!\")\n",
    "    # Fix spacing before exclamation marks\n",
    "\n",
    "    return generated_text\n",
    "    # Return the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "D8QCiNlUq1Uq",
    "outputId": "ee4aae59-0736-4819-b12e-e86a8fa215c1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'i'm doing great. what about you?? i never did. you have to stand in the aisle. \" a digital is? i never heard of such a thing. i was cleaning up. i'm not a cheater. you can even mail your ballot in'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"hi , how are you doing ?\"\n",
    "# Define input text to generate from\n",
    "print(generate_text(text, top_k=3,encoder_net=encoder_net, decoder_net=decoder_net,\n",
    "              dictionary=dictionary))\n",
    "# Call generate_text with top_k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJmFlEUL5sh0",
    "outputId": "3353eb7c-bdc3-456f-b0e4-addf09915cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm going to the bathroom to be at the airport. i'm not going to the movies? i'm not a stamp. \". i'm not sure, but i don't know. what is it? i don't want to go. it will be out of fun in\n"
     ]
    }
   ],
   "source": [
    "text = \"hi , how are you doing ?\"\n",
    "print(generate_text(text, top_k=5,encoder_net=encoder_net, decoder_net=decoder_net,\n",
    "                    dictionary=dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRXqhAgoykFq",
    "outputId": "51470485-2c81-485c-f744-a29af6edb6ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm having fun. i'm not a cheater. you can even buy your ticket now. i'm not a cheater. i'm just asking. i think it's going to be warm. i really want to go to the beach. i have to go to the bathroom.\n"
     ]
    }
   ],
   "source": [
    "text = \"hi , how are you doing ?\"\n",
    "print(generate_text(text, top_k=3,encoder_net=encoder_net, decoder_net=decoder_net,\n",
    "                    dictionary=dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1HZ4BmPygkT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
