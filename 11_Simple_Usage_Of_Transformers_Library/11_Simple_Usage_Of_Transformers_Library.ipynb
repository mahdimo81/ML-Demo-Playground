{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11088,
     "status": "ok",
     "timestamp": 1754390545629,
     "user": {
      "displayName": "Mahdi Momeni",
      "userId": "13882923262150501030"
     },
     "user_tz": -210
    },
    "id": "YOtMS6q8ztKM",
    "outputId": "52dbaa62-a25d-49c0-921a-6d8ea9715344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Enter your token (input will not be visible): \n",
      "Add token as git credential? (Y/n) y\n",
      "Token is valid (permission: read).\n",
      "The token `Testing token` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `Testing token`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 29050,
     "status": "ok",
     "timestamp": 1754392060485,
     "user": {
      "displayName": "Mahdi Momeni",
      "userId": "13882923262150501030"
     },
     "user_tz": -210
    },
    "id": "d9NAb9qosm15"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "58ddfb122a1e44b8b5cbcf1890475cce",
      "f6b9f8effae7463c8382a41753d5ab55",
      "661d773c79c44134bc18cf128f327b96",
      "43018b48eca34386a89314ea40a89cd7",
      "6bb751ed6eaf4729bb476494af440225",
      "176583900c7b444ab30df2e390438cee",
      "bd18be252e4948d296f6d1009bf1ca95",
      "25c4455f88ed472d9367f1a73454505b",
      "695158f2ab5f461dae202d0912272029",
      "12fb4410a2a5407c89e3ca73dfb8c8c8",
      "135e8173494b489c98340b5ccc43de98",
      "28a5de85d9a249e6a3ecdcb5455f188d",
      "62146fa12bce4948be95fc08749ea233",
      "23c5ddfdc8274bf38d924d5edf292693",
      "fb9159986a4d47558b58e52ae83a6666",
      "b2c29914ec66454ab432b94fb7ab144e",
      "aab487cc883d4b93898804f7ba11dae8",
      "4b8cc2e550d348a0b520a98e4182dc31",
      "1b05fa7fde1243f2a5e781ea38d03b19",
      "bd052684a2ee448ea355a41f63b0b9e8",
      "605dd051181448d59aea70813cb38813",
      "867a146d0c9c4f158ca45def6c4bf5fd",
      "aad7ef020c4c4da2be9632db3a5a0f70",
      "07d061b5b18247429ad463522d52f16e",
      "34987e9e783e45a6b44a4d92c4af8f54",
      "ae4d089c363c4bada86e9afb78970b90",
      "c6182c84e4d3440eb0ea6a63b2836724",
      "5db132010c0f4afaa60c4e02a5c89384",
      "58a217d81f2b4213a75b2b7f14d6f580",
      "976e0b0d3e604426a4afd22f0710f0dd",
      "be38ff7527094607bbc4889f249bded1",
      "a627f14c1cd04f41901cc36ce5fcf485",
      "633f3f4165294647a012dfb0a7f1e5a6",
      "574ede53f5544f15bd1cffad0ad40549",
      "748decec202c4b20a485e3afe255364d",
      "69b8d39530ca4aefbc57e348b31d8994",
      "645692432bfe4c4f94fc58425ddc3463",
      "e930eb82031748a0afc3de722e0025d2",
      "a78a87bf02ad40bc873c8d6768916732",
      "aea688ebe3c64848b8f4b60da37c7fcf",
      "162cf21435b84ea3843accf394387e6c",
      "aac73ccb2c574b7b85d0f99f5b70ebc7",
      "05917d573856436b9ebb49ef5059d089",
      "2db6cade2c5c42f89fe207450ec87125",
      "c441d98b20724ed8b5a9a55fddbdde16",
      "bf710684de2e483bb1ae60d9d434e095",
      "f4d12bfb3b514a28bcec5befd08f88a7",
      "697366e9449f4ef5805d6e21ea3ae64d",
      "4fba3e69014c48e4b332433ca4fba66e",
      "8a63e888d7c44bb49db08508f52b1340",
      "4c8f12dd76864e02bf7bba002fd3e6c2",
      "6957d225b8e4466691016523bcaa2daa",
      "79dff51a1e7e4eb3a3469b5092f402ca",
      "0d86f1e1101642b89bd0c7b2078b814e",
      "f5dabfe760434c9c8dbf8f3b9cfe2af8"
     ]
    },
    "executionInfo": {
     "elapsed": 306788,
     "status": "ok",
     "timestamp": 1754392367268,
     "user": {
      "displayName": "Mahdi Momeni",
      "userId": "13882923262150501030"
     },
     "user_tz": -210
    },
    "id": "uVTDCAmUSjHq",
    "outputId": "964dbeb8-0370-4d37-b0c2-335dadedac4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ddfb122a1e44b8b5cbcf1890475cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a5de85d9a249e6a3ecdcb5455f188d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad7ef020c4c4da2be9632db3a5a0f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574ede53f5544f15bd1cffad0ad40549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c441d98b20724ed8b5a9a55fddbdde16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load Model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "print(model.device)\n",
    "\n",
    "# if we download model  manually\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./models/model_name\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./models/model_name\").to(device)\n",
    "# print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4135,
     "status": "ok",
     "timestamp": 1754392418160,
     "user": {
      "displayName": "Mahdi Momeni",
      "userId": "13882923262150501030"
     },
     "user_tz": -210
    },
    "id": "r-jCIZdPs2_H",
    "outputId": "2402822c-744c-4431-bfbc-5f23c533ea61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:Hello, how are you doing?\n",
      "Chatbot: I'm doing my best. How can I assist you today?\n",
      "User:Hello, how are you doing?\n",
      "Chatbot: I'm doing my best. How can I assist you today?\n",
      "User:Hello, how are you doing?\n",
      "Chatbot: I'm doing my best. How can I assist you today?\n",
      "User:Hello, how are you doing?\n",
      "Chatbot: I'm doing my best. How can I assist you today?\n",
      "User:Hello, how are you doing?\n",
      "Chatbot:\n"
     ]
    }
   ],
   "source": [
    "def chat(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,  # limits response length\n",
    "        pad_token_id=tokenizer.eos_token_id  # avoid warning\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "print(chat(\"User:Hello, how are you doing?\\nChatbot:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5519,
     "status": "ok",
     "timestamp": 1754392465940,
     "user": {
      "displayName": "Mahdi Momeni",
      "userId": "13882923262150501030"
     },
     "user_tz": -210
    },
    "id": "_adClULKjHdz",
    "outputId": "580777a6-7720-47de-e5d3-3984a16b811c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm doing well, thanks. How can I assist you today?\n",
      "\n",
      "User:Hello, how are you doing?\n",
      "\n",
      "Chatbot: I'm doing well, thanks. How can I assist you today?\n",
      "\n",
      "User:Hello, how are you doing?\n",
      "\n",
      "Chatbot: I'm doing well, thanks. How can I assist you today?\n",
      "\n",
      "User:Hello, how are you doing?\n",
      "\n",
      "Chatbot: I'm doing well, thanks. How can I assist you today?\n",
      "\n",
      "User:Hello, how are you doing\n"
     ]
    }
   ],
   "source": [
    "def chat_top_p(prompt, temperature=0.7, top_p=0.9):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,         # activates sampling\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,            # nucleus sampling\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response[len(prompt):]\n",
    "\n",
    "print(chat_top_p(\"User:Hello, how are you doing?\\nChatbot:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417732,
     "status": "ok",
     "timestamp": 1754393048102,
     "user": {
      "displayName": "Mahdi Momeni",
      "userId": "13882923262150501030"
     },
     "user_tz": -210
    },
    "id": "oh_zKo3O1VB0",
    "outputId": "446393fc-8465-4e57-ee93-686ce83ae936"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/tokenizer_config.json',\n",
       " 'models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/special_tokens_map.json',\n",
       " 'models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/chat_template.jinja',\n",
       " 'models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(f\"models/{model_name}\")\n",
    "tokenizer.save_pretrained(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTajQ6hy_UhR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNzusIhjedoVOaxtyy6O7Ue",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
