{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Wv7cHECizPz"
   },
   "source": [
    "# Downloading and Extracting the Cornell Movie-Dialogs Corpus\n",
    "This code downloads a dataset from Kaggle and copies it to the current working directory for easier access.\n",
    "\n",
    "#### Key Steps:\n",
    "1. **KaggleHub Download**:\n",
    "   - Uses `kagglehub.dataset_download()` to fetch the `\"rajathmc/cornell-moviedialog-corpus\"` dataset.\n",
    "   - The downloaded dataset's path is stored in `path` and printed for verification.\n",
    "\n",
    "2. **Local Directory Setup**:\n",
    "   - Imports `shutil` and `os` to handle file operations.\n",
    "   - Sets `source_path` to the downloaded dataset location.\n",
    "   - Defines `destination_path` as the current working directory (via `os.getcwd()`).\n",
    "\n",
    "3. **Copying Files**:\n",
    "   - Uses `shutil.copytree()` to recursively copy the dataset to a new folder named `\"cornell-moviedialog-corpus\"` in the current directory.\n",
    "   - Prints the destination path for confirmation.\n",
    "\n",
    "#### Notes:\n",
    "- **Prerequisites**:\n",
    "  - Requires the `kagglehub` package installed (`pip install kagglehub`).\n",
    "  - Ensure Kaggle credentials are configured if the dataset is private.\n",
    "- **Output**:\n",
    "  - The dataset files will be available in `./cornell-moviedialog-corpus/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcXD6hZ96Mq2",
    "outputId": "7eb0b37e-40e9-42b7-b94c-1bffe99df8bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/cornell-moviedialog-corpus\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rajathmc/cornell-moviedialog-corpus\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THlk_RUt7UNf",
    "outputId": "9d7b199b-a74b-4e44-d4e9-9f1a38a502c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset copied to: /content/cornell-moviedialog-corpus\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Source path (where the dataset was downloaded)\n",
    "source_path = path\n",
    "\n",
    "# Destination path (current working directory)\n",
    "destination_path = os.getcwd()  # Gets the current working directory\n",
    "\n",
    "# Copy all contents from source to destination\n",
    "shutil.copytree(source_path, os.path.join(destination_path, \"cornell-moviedialog-corpus\"))\n",
    "\n",
    "print(f\"Dataset copied to: {os.path.join(destination_path, 'cornell-moviedialog-corpus')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDQxrydqjzHK"
   },
   "source": [
    "## Processing the Cornell Movie-Dialogs Corpus\n",
    "Following code processes the movie conversations and lines from the Cornell Movie-Dialogs Corpus to extract question-answer (QA) pairs for dialogue modeling.\n",
    "\n",
    "#### Key Steps:\n",
    "\n",
    "1. **File Paths and Initialization**:\n",
    "   - `corpus_movie_conv`: Path to the conversations file (`movie_conversations.txt`).\n",
    "   - `corpus_movie_lines`: Path to the dialogue lines file (`movie_lines.txt`).\n",
    "   - `max_len`: Maximum allowed length of a sentence (25 words).\n",
    "\n",
    "2. **Reading Data**:\n",
    "   - Conversations (`conv`) and dialogue lines (`lines`) are loaded into memory.\n",
    "   - The lines file uses `latin-1` encoding to handle special characters.\n",
    "\n",
    "3. **Building a Lines Dictionary**:\n",
    "   - `lines_dict` maps each line ID (e.g., `L194`) to its corresponding text by splitting on `\" +++$+++ \"`.\n",
    "   - Example: `lines_dict[\"L194\"]` → \"First dialogue line text...\"\n",
    "\n",
    "4. **Text Preprocessing**:\n",
    "   - `remove_punc()` removes punctuation and converts text to lowercase for uniformity.\n",
    "   - Example: `\"Hello, World!\"` → `\"hello world\"`.\n",
    "\n",
    "5. **Extracting QA Pairs**:\n",
    "   - For each conversation in `conv`, the line IDs are extracted (e.g., `['L194', 'L195', ...]`).\n",
    "   - Adjacent lines are paired as questions and answers:\n",
    "     - `first`: The current line (preprocessed).\n",
    "     - `second`: The next line (preprocessed).\n",
    "   - Each pair is truncated to `max_len` words and added to `pairs`.\n",
    "\n",
    "6. **Output**:\n",
    "   - The total number of QA pairs (`221616`) is printed, showing the scale of the dataset.\n",
    "\n",
    "#### Example QA Pair:\n",
    "# Input:\n",
    "[\"hello how are you\", \"i am fine thanks\"]\n",
    "\n",
    "# Preprocessed (max_len=3):\n",
    "[[\"hello\", \"how\", \"are\"], [\"i\", \"am\", \"fine\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NBOXcSRf_9Bo"
   },
   "outputs": [],
   "source": [
    "# Paths to the movie conversation and lines files\n",
    "corpus_movie_conv = \"cornell-moviedialog-corpus/movie_conversations.txt\"\n",
    "corpus_movie_lines = \"cornell-moviedialog-corpus/movie_lines.txt\"\n",
    "\n",
    "# Maximum length for sequences\n",
    "max_len = 25\n",
    "\n",
    "# Read conversation data\n",
    "with open(corpus_movie_conv, \"r\") as c:\n",
    "    conv = c.readlines()\n",
    "\n",
    "# Read movie lines with Latin-1 encoding\n",
    "with open(corpus_movie_lines, \"r\", encoding='latin-1') as l:\n",
    "    lines = l.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQ72pyuNBPUQ",
    "outputId": "77fe0a1e-6f33-4a96-a108-b6ee0c9aba41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n',\n",
       " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n',\n",
       " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n',\n",
       " 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n',\n",
       " \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\",\n",
       " 'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n',\n",
       " \"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\",\n",
       " 'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n',\n",
       " 'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n',\n",
       " 'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2aPEJu68CTOq"
   },
   "outputs": [],
   "source": [
    "lines_dict = {}\n",
    "for line in lines:\n",
    "  objects = line.split(\" +++$+++ \")\n",
    "  lines_dict[objects[0]] = objects[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TU_-YoGTDEFg"
   },
   "outputs": [],
   "source": [
    "def remove_punc(string):\n",
    "    # Define punctuation characters to remove\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punc = \"\"\n",
    "\n",
    "    # Iterate through each character and remove punctuation\n",
    "    for char in string:\n",
    "        if char not in punctuations:\n",
    "            no_punc += char\n",
    "\n",
    "    # Return the cleaned string in lowercase\n",
    "    return no_punc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pw5Pg9ndEn74",
    "outputId": "8787feb3-925d-427c-e8f2-8519d5cfcec5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L194', 'L195', 'L196', 'L197']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(conv[0].split(\" +++$+++ \")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "i4zBLgENFOK3"
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store conversation pairs\n",
    "pairs = []\n",
    "\n",
    "# Iterate through each conversation in the conversation data\n",
    "for con in conv:\n",
    "    # Extract the list of line IDs involved in the conversation\n",
    "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
    "\n",
    "    # Iterate through each line ID to form question-answer pairs\n",
    "    for i in range(len(ids)):\n",
    "        qa_pairs = []\n",
    "\n",
    "        # Skip the last line as it doesn't have a subsequent line to pair with\n",
    "        if i == len(ids) - 1:\n",
    "            break\n",
    "\n",
    "        # Get and clean the current line and the next line\n",
    "        first = remove_punc(lines_dict[ids[i]].strip())\n",
    "        second = remove_punc(lines_dict[ids[i + 1]].strip())\n",
    "\n",
    "        # Split the lines into words and limit to max_len words\n",
    "        qa_pairs.append(first.split()[:max_len])\n",
    "        qa_pairs.append(second.split()[:max_len])\n",
    "\n",
    "        # Add the question-answer pair to the pairs list\n",
    "        pairs.append(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVY1yd4UI5sw",
    "outputId": "c03efd14-4c65-4df2-e40b-eacebf134452"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221616"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IRp76v5k0_S"
   },
   "source": [
    "### Building Vocabulary from Dialogue Pairs\n",
    "Following code creates a vocabulary mapping for the dialogue pairs by analyzing word frequencies and assigning special tokens.\n",
    "\n",
    "#### Key Steps:\n",
    "\n",
    "1. **Word Frequency Counting**:\n",
    "   - Uses `Counter` from `collections` to count occurrences of each word across all question-answer pairs.\n",
    "   - Iterates through `pairs`, updating counts for words in both questions (`pair[0]`) and answers (`pair[1]`).\n",
    "\n",
    "2. **Vocabulary Filtering**:\n",
    "   - Keeps only words that appear more than `min_word_freq` (5) times to filter out rare words.\n",
    "   - This helps reduce vocabulary size and eliminates noise from infrequent words.\n",
    "\n",
    "3. **Word-to-Index Mapping**:\n",
    "   - Creates `word_map` dictionary where each word is assigned a unique integer:\n",
    "     - Frequent words are numbered sequentially starting from 1\n",
    "     - Adds four special tokens:\n",
    "       - `<pad>` → 0 (for padding shorter sequences)\n",
    "       - `<unk>` → for unknown/rare words\n",
    "       - `<start>` → to mark beginning of sequences\n",
    "       - `<end>` → to mark end of sequences\n",
    "\n",
    "4. **Vocabulary Persistence**:\n",
    "   - Saves the `word_map` dictionary as a JSON file (`WORDMAP_corpus.json`) for later use in model training.\n",
    "\n",
    "#### Example Output:\n",
    "{\n",
    "  \"`<pad>`\": 0,\n",
    "  \"hello\": 1,\n",
    "  \"how\": 2,\n",
    "  ...\n",
    "  \"`<unk>`\": 2532,\n",
    "  \"`<start>`\": 2533,\n",
    "  \"`<end>`\": 2534\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Auv1vfsQJTCv",
    "outputId": "4f4ac065-e739-4f57-ae78-f4af85903a60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'can': 14103,\n",
       "         'we': 25912,\n",
       "         'make': 5821,\n",
       "         'this': 30502,\n",
       "         'quick': 310,\n",
       "         'roxanne': 1,\n",
       "         'korrine': 1,\n",
       "         'and': 52131,\n",
       "         'andrew': 49,\n",
       "         'barrett': 20,\n",
       "         'are': 21713,\n",
       "         'having': 1081,\n",
       "         'an': 8827,\n",
       "         'incredibly': 49,\n",
       "         'horrendous': 4,\n",
       "         'public': 306,\n",
       "         'break': 799,\n",
       "         'up': 14316,\n",
       "         'on': 23908,\n",
       "         'the': 120903,\n",
       "         'quad': 2,\n",
       "         'again': 2807,\n",
       "         'well': 16263,\n",
       "         'i': 137639,\n",
       "         'thought': 4202,\n",
       "         'wed': 541,\n",
       "         'start': 1459,\n",
       "         'with': 21394,\n",
       "         'pronunciation': 2,\n",
       "         'if': 16727,\n",
       "         'thats': 14742,\n",
       "         'okay': 5946,\n",
       "         'you': 169695,\n",
       "         'not': 26496,\n",
       "         'hacking': 18,\n",
       "         'gagging': 9,\n",
       "         'spitting': 15,\n",
       "         'part': 1260,\n",
       "         'please': 3258,\n",
       "         'then': 7532,\n",
       "         'how': 14001,\n",
       "         'bout': 393,\n",
       "         'try': 1998,\n",
       "         'out': 16100,\n",
       "         'some': 8153,\n",
       "         'french': 306,\n",
       "         'cuisine': 11,\n",
       "         'saturday': 184,\n",
       "         'night': 3489,\n",
       "         'youre': 18180,\n",
       "         'asking': 691,\n",
       "         'me': 41056,\n",
       "         'so': 16697,\n",
       "         'cute': 259,\n",
       "         'whats': 6573,\n",
       "         'your': 26791,\n",
       "         'name': 2839,\n",
       "         'forget': 1316,\n",
       "         'it': 60011,\n",
       "         'no': 27124,\n",
       "         'its': 24458,\n",
       "         'my': 26250,\n",
       "         'fault': 456,\n",
       "         'didnt': 8043,\n",
       "         'have': 27982,\n",
       "         'a': 89110,\n",
       "         'proper': 126,\n",
       "         'introduction': 19,\n",
       "         'cameron': 34,\n",
       "         'thing': 4976,\n",
       "         'is': 37374,\n",
       "         'im': 30345,\n",
       "         'at': 13283,\n",
       "         'mercy': 62,\n",
       "         'of': 47393,\n",
       "         'particularly': 102,\n",
       "         'hideous': 19,\n",
       "         'breed': 31,\n",
       "         'loser': 113,\n",
       "         'sister': 585,\n",
       "         'cant': 8757,\n",
       "         'date': 507,\n",
       "         'until': 1236,\n",
       "         'she': 11346,\n",
       "         'does': 3336,\n",
       "         'seems': 751,\n",
       "         'like': 19130,\n",
       "         'could': 7311,\n",
       "         'get': 17562,\n",
       "         'easy': 1089,\n",
       "         'enough': 2295,\n",
       "         'why': 12219,\n",
       "         'unsolved': 13,\n",
       "         'mystery': 84,\n",
       "         'used': 1767,\n",
       "         'to': 100667,\n",
       "         'be': 24193,\n",
       "         'really': 6196,\n",
       "         'popular': 94,\n",
       "         'when': 9007,\n",
       "         'started': 709,\n",
       "         'high': 749,\n",
       "         'school': 1358,\n",
       "         'was': 25287,\n",
       "         'just': 20634,\n",
       "         'got': 14745,\n",
       "         'sick': 852,\n",
       "         'or': 7778,\n",
       "         'something': 6827,\n",
       "         'shame': 149,\n",
       "         'gosh': 103,\n",
       "         'only': 5044,\n",
       "         'find': 3549,\n",
       "         'kat': 39,\n",
       "         'boyfriend': 253,\n",
       "         'let': 4589,\n",
       "         'see': 10288,\n",
       "         'what': 44771,\n",
       "         'do': 30487,\n",
       "         'cesc': 1,\n",
       "         'ma': 309,\n",
       "         'tete': 1,\n",
       "         'head': 1438,\n",
       "         'right': 12793,\n",
       "         'ready': 1076,\n",
       "         'for': 29046,\n",
       "         'quiz': 9,\n",
       "         'dont': 33134,\n",
       "         'want': 14744,\n",
       "         'know': 29121,\n",
       "         'say': 8124,\n",
       "         'that': 44755,\n",
       "         'though': 842,\n",
       "         'useful': 66,\n",
       "         'things': 3447,\n",
       "         'where': 7504,\n",
       "         'good': 9381,\n",
       "         'stores': 35,\n",
       "         'much': 4715,\n",
       "         'because': 4218,\n",
       "         'such': 1326,\n",
       "         'nice': 2319,\n",
       "         'one': 12865,\n",
       "         'our': 4763,\n",
       "         'little': 5569,\n",
       "         'wench': 10,\n",
       "         'plan': 611,\n",
       "         'progressing': 3,\n",
       "         'theres': 5085,\n",
       "         'someone': 2121,\n",
       "         'think': 14340,\n",
       "         'might': 2406,\n",
       "         'there': 12922,\n",
       "         'mind': 2249,\n",
       "         'counted': 31,\n",
       "         'help': 3299,\n",
       "         'cause': 1230,\n",
       "         'thug': 7,\n",
       "         'obviously': 224,\n",
       "         'failing': 19,\n",
       "         'arent': 1347,\n",
       "         'ever': 3652,\n",
       "         'going': 11379,\n",
       "         'word': 1164,\n",
       "         'as': 9332,\n",
       "         'gentleman': 153,\n",
       "         'sweet': 442,\n",
       "         'hair': 532,\n",
       "         'look': 7492,\n",
       "         'ebers': 1,\n",
       "         'deep': 314,\n",
       "         'conditioner': 11,\n",
       "         'every': 2226,\n",
       "         'two': 4538,\n",
       "         'days': 1424,\n",
       "         'never': 7067,\n",
       "         'use': 1444,\n",
       "         'blowdryer': 2,\n",
       "         'without': 1488,\n",
       "         'diffuser': 1,\n",
       "         'attachment': 5,\n",
       "         'sure': 6049,\n",
       "         'wanna': 1241,\n",
       "         'go': 12495,\n",
       "         'but': 22026,\n",
       "         'unless': 479,\n",
       "         'goes': 873,\n",
       "         'workin': 92,\n",
       "         'doesnt': 3054,\n",
       "         'seem': 738,\n",
       "         'goin': 604,\n",
       "         'him': 14721,\n",
       "         'shes': 3954,\n",
       "         'lesbian': 28,\n",
       "         'found': 1550,\n",
       "         'picture': 549,\n",
       "         'jared': 3,\n",
       "         'leto': 6,\n",
       "         'in': 41692,\n",
       "         'her': 11430,\n",
       "         'drawers': 15,\n",
       "         'pretty': 1791,\n",
       "         'harboring': 6,\n",
       "         'samesex': 3,\n",
       "         'tendencies': 6,\n",
       "         'kind': 2730,\n",
       "         'guy': 3124,\n",
       "         'likes': 369,\n",
       "         'ones': 702,\n",
       "         'who': 9152,\n",
       "         'knows': 1204,\n",
       "         'all': 18850,\n",
       "         'ive': 7039,\n",
       "         'heard': 1976,\n",
       "         'shed': 281,\n",
       "         'dip': 24,\n",
       "         'before': 3587,\n",
       "         'dating': 86,\n",
       "         'smokes': 38,\n",
       "         'hi': 1204,\n",
       "         'looks': 1232,\n",
       "         'worked': 569,\n",
       "         'tonight': 1819,\n",
       "         'huh': 2286,\n",
       "         'chastity': 12,\n",
       "         'believe': 3360,\n",
       "         'share': 248,\n",
       "         'art': 290,\n",
       "         'instructor': 6,\n",
       "         'fun': 658,\n",
       "         'tons': 51,\n",
       "         'looked': 555,\n",
       "         'back': 7418,\n",
       "         'party': 809,\n",
       "         'always': 3299,\n",
       "         'seemed': 238,\n",
       "         'occupied': 25,\n",
       "         'wanted': 2354,\n",
       "         'did': 11887,\n",
       "         'had': 7015,\n",
       "         'been': 8487,\n",
       "         'selfish': 56,\n",
       "         'guillermo': 1,\n",
       "         'says': 1567,\n",
       "         'any': 5405,\n",
       "         'lighter': 28,\n",
       "         'gonna': 5323,\n",
       "         'extra': 200,\n",
       "         '90210': 1,\n",
       "         'listen': 2434,\n",
       "         'crap': 273,\n",
       "         'endless': 20,\n",
       "         'blonde': 105,\n",
       "         'babble': 7,\n",
       "         'boring': 144,\n",
       "         'myself': 1445,\n",
       "         'thank': 2557,\n",
       "         'god': 2881,\n",
       "         'hear': 2351,\n",
       "         'more': 5498,\n",
       "         'story': 1143,\n",
       "         'about': 18683,\n",
       "         'coiffure': 4,\n",
       "         'figured': 438,\n",
       "         'youd': 1980,\n",
       "         'stuff': 1427,\n",
       "         'eventually': 103,\n",
       "         'real': 2247,\n",
       "         'fear': 302,\n",
       "         'wearing': 334,\n",
       "         'pastels': 2,\n",
       "         'kidding': 587,\n",
       "         'sometimes': 934,\n",
       "         'become': 400,\n",
       "         'persona': 4,\n",
       "         'quit': 461,\n",
       "         'need': 5194,\n",
       "         'learn': 541,\n",
       "         'lie': 600,\n",
       "         'wow': 348,\n",
       "         'lets': 3125,\n",
       "         'hope': 1256,\n",
       "         'they': 15365,\n",
       "         'change': 966,\n",
       "         'he': 24379,\n",
       "         'here': 15848,\n",
       "         'joey': 164,\n",
       "         'great': 2823,\n",
       "         'would': 7917,\n",
       "         'getting': 2127,\n",
       "         'drink': 1073,\n",
       "         'practically': 131,\n",
       "         'proposed': 44,\n",
       "         'same': 1858,\n",
       "         'dermatologist': 3,\n",
       "         'mean': 7183,\n",
       "         'dr': 1071,\n",
       "         'bonchowski': 1,\n",
       "         'hes': 8639,\n",
       "         'exactly': 1380,\n",
       "         'relevant': 23,\n",
       "         'oily': 7,\n",
       "         'dry': 168,\n",
       "         'combination': 58,\n",
       "         'hed': 532,\n",
       "         'different': 1030,\n",
       "         'bianca': 31,\n",
       "         'highlights': 6,\n",
       "         'dorsey': 8,\n",
       "         'include': 53,\n",
       "         'dooropening': 1,\n",
       "         'coatholding': 1,\n",
       "         'wonder': 505,\n",
       "         'guys': 2071,\n",
       "         'were': 14085,\n",
       "         'supposed': 1253,\n",
       "         'actually': 1166,\n",
       "         'id': 3964,\n",
       "         'give': 4358,\n",
       "         'private': 399,\n",
       "         'line': 678,\n",
       "         'home': 2769,\n",
       "         'twenty': 742,\n",
       "         'minutes': 1168,\n",
       "         'til': 167,\n",
       "         're': 64,\n",
       "         'sophomore': 13,\n",
       "         'prom': 101,\n",
       "         'expensive': 110,\n",
       "         'bogey': 11,\n",
       "         'lowenbraus': 1,\n",
       "         'hopefully': 28,\n",
       "         'yeah': 10451,\n",
       "         'sears': 9,\n",
       "         'catalog': 5,\n",
       "         'tube': 37,\n",
       "         'sock': 19,\n",
       "         'gig': 59,\n",
       "         'huge': 126,\n",
       "         'ad': 66,\n",
       "         'queen': 179,\n",
       "         'harry': 598,\n",
       "         'gay': 118,\n",
       "         'cruise': 30,\n",
       "         'ill': 8849,\n",
       "         'uniform': 85,\n",
       "         'neat': 70,\n",
       "         'agent': 391,\n",
       "         'shot': 993,\n",
       "         'being': 1941,\n",
       "         'prada': 4,\n",
       "         'next': 1543,\n",
       "         'year': 1055,\n",
       "         'hey': 3185,\n",
       "         'cheeks': 23,\n",
       "         'concentrating': 16,\n",
       "         'awfully': 71,\n",
       "         'hard': 1385,\n",
       "         'considering': 87,\n",
       "         'gym': 27,\n",
       "         'class': 413,\n",
       "         'talk': 4268,\n",
       "         'deal': 1253,\n",
       "         't': 95,\n",
       "         'whereve': 29,\n",
       "         'nowhere': 175,\n",
       "         'daddy': 696,\n",
       "         'potential': 59,\n",
       "         'smack': 21,\n",
       "         'way': 6112,\n",
       "         'least': 1088,\n",
       "         'bra': 28,\n",
       "         'oh': 10884,\n",
       "         'becoming': 83,\n",
       "         'normal': 256,\n",
       "         'means': 850,\n",
       "         'gigglepuss': 6,\n",
       "         'playing': 546,\n",
       "         'club': 307,\n",
       "         'skunk': 15,\n",
       "         'bothering': 92,\n",
       "         'ask': 2462,\n",
       "         'lowensteins': 3,\n",
       "         'freak': 142,\n",
       "         'torture': 71,\n",
       "         'suck': 108,\n",
       "         'ruining': 35,\n",
       "         'life': 3326,\n",
       "         'wont': 3337,\n",
       "         'too': 6295,\n",
       "         'busy': 449,\n",
       "         'listening': 311,\n",
       "         'bitches': 46,\n",
       "         'prozac': 6,\n",
       "         'completely': 372,\n",
       "         'wretched': 24,\n",
       "         'clouted': 1,\n",
       "         'fen': 1,\n",
       "         'sucked': 44,\n",
       "         'hedgepig': 1,\n",
       "         'even': 3907,\n",
       "         'shakespeare': 53,\n",
       "         'maybe': 5188,\n",
       "         'youve': 3787,\n",
       "         'friend': 1826,\n",
       "         'mandellas': 1,\n",
       "         'guess': 2647,\n",
       "         'since': 1437,\n",
       "         'allowed': 153,\n",
       "         'should': 4563,\n",
       "         'obsess': 1,\n",
       "         'over': 4909,\n",
       "         'dead': 2470,\n",
       "         'unbalanced': 2,\n",
       "         'now': 12037,\n",
       "         'tell': 8991,\n",
       "         'social': 127,\n",
       "         'advice': 235,\n",
       "         'from': 8496,\n",
       "         'act': 503,\n",
       "         'totally': 322,\n",
       "         'apeshit': 3,\n",
       "         'welcome': 341,\n",
       "         'hate': 1041,\n",
       "         'sit': 1044,\n",
       "         'susie': 79,\n",
       "         'care': 2058,\n",
       "         'firm': 109,\n",
       "         'believer': 21,\n",
       "         'doing': 4013,\n",
       "         'own': 1961,\n",
       "         'reasons': 172,\n",
       "         'else': 2336,\n",
       "         's': 97,\n",
       "         'wish': 1030,\n",
       "         'luxury': 19,\n",
       "         'asked': 1091,\n",
       "         'won': 261,\n",
       "         'told': 3710,\n",
       "         'went': 1891,\n",
       "         '9th': 14,\n",
       "         'month': 403,\n",
       "         'total': 165,\n",
       "         'babe': 146,\n",
       "         'said': 5404,\n",
       "         'everyone': 811,\n",
       "         'once': 1541,\n",
       "         'afterwards': 50,\n",
       "         'anymore': 906,\n",
       "         'wasnt': 2242,\n",
       "         'pissed': 151,\n",
       "         'broke': 405,\n",
       "         'after': 3015,\n",
       "         'swore': 62,\n",
       "         'anything': 4396,\n",
       "         'havent': 1917,\n",
       "         'except': 531,\n",
       "         'bogeys': 3,\n",
       "         'decisions': 48,\n",
       "         'wouldve': 190,\n",
       "         'instead': 320,\n",
       "         'helping': 169,\n",
       "         'stupid': 768,\n",
       "         'repeat': 123,\n",
       "         'mistakes': 80,\n",
       "         'protecting': 81,\n",
       "         'keep': 2831,\n",
       "         'locked': 224,\n",
       "         'away': 2955,\n",
       "         'dark': 471,\n",
       "         'experience': 273,\n",
       "         'experiences': 33,\n",
       "         'trust': 967,\n",
       "         'people': 5029,\n",
       "         'will': 7901,\n",
       "         'beautiful': 1043,\n",
       "         'last': 3386,\n",
       "         'set': 921,\n",
       "         'damage': 148,\n",
       "         'send': 800,\n",
       "         'therapy': 86,\n",
       "         'forever': 263,\n",
       "         'woman': 1418,\n",
       "         'complete': 190,\n",
       "         'fruitloop': 1,\n",
       "         'patrick': 119,\n",
       "         'perm': 8,\n",
       "         'upset': 367,\n",
       "         'boy': 1874,\n",
       "         'starts': 160,\n",
       "         'end': 969,\n",
       "         'discussion': 64,\n",
       "         'neither': 346,\n",
       "         'sleep': 1090,\n",
       "         'fair': 404,\n",
       "         'mutant': 27,\n",
       "         'point': 1305,\n",
       "         'wherere': 43,\n",
       "         'must': 3306,\n",
       "         'attempting': 21,\n",
       "         'small': 559,\n",
       "         'study': 215,\n",
       "         'group': 238,\n",
       "         'friends': 1322,\n",
       "         'otherwise': 187,\n",
       "         'known': 545,\n",
       "         'orgy': 11,\n",
       "         'knew': 1951,\n",
       "         'forbid': 21,\n",
       "         'gloria': 30,\n",
       "         'steinem': 3,\n",
       "         'isnt': 3129,\n",
       "         'expect': 571,\n",
       "         'kats': 1,\n",
       "         'starting': 286,\n",
       "         'wear': 443,\n",
       "         'belly': 46,\n",
       "         'minute': 1346,\n",
       "         'promise': 638,\n",
       "         'boys': 743,\n",
       "         'present': 292,\n",
       "         'shell': 495,\n",
       "         'scare': 185,\n",
       "         'them': 7208,\n",
       "         'discuss': 213,\n",
       "         'tomorrow': 1583,\n",
       "         'has': 4569,\n",
       "         'hot': 632,\n",
       "         'rod': 64,\n",
       "         'bend': 53,\n",
       "         'rules': 240,\n",
       "         'whatever': 1066,\n",
       "         'fine': 2471,\n",
       "         'prisoner': 67,\n",
       "         'house': 2089,\n",
       "         'daughter': 546,\n",
       "         'possession': 79,\n",
       "         'missing': 323,\n",
       "         'captain': 862,\n",
       "         'oppression': 7,\n",
       "         'men': 1467,\n",
       "         'pleasure': 324,\n",
       "         'brucie': 1,\n",
       "         'pegged': 19,\n",
       "         'fan': 136,\n",
       "         'preteen': 3,\n",
       "         'bellybutton': 3,\n",
       "         'ring': 323,\n",
       "         'couple': 981,\n",
       "         'minors': 12,\n",
       "         'come': 8509,\n",
       "         'padua': 2,\n",
       "         'girls': 720,\n",
       "         'tall': 109,\n",
       "         'decent': 116,\n",
       "         'body': 720,\n",
       "         'other': 3340,\n",
       "         'kinda': 419,\n",
       "         'short': 318,\n",
       "         'undersexed': 2,\n",
       "         'sent': 673,\n",
       "         'em': 1620,\n",
       "         'through': 2100,\n",
       "         'new': 2741,\n",
       "         'cmon': 536,\n",
       "         'tour': 93,\n",
       "         'which': 1660,\n",
       "         'dakota': 20,\n",
       "         'north': 222,\n",
       "         'howd': 488,\n",
       "         'live': 1690,\n",
       "         'outnumbered': 6,\n",
       "         'by': 4866,\n",
       "         'cows': 36,\n",
       "         'many': 1648,\n",
       "         'old': 2969,\n",
       "         'thirtytwo': 22,\n",
       "         'thousand': 1057,\n",
       "         'most': 1452,\n",
       "         'evil': 307,\n",
       "         'these': 3406,\n",
       "         'seen': 1863,\n",
       "         'horse': 271,\n",
       "         'jack': 1026,\n",
       "         'off': 4779,\n",
       "         'clint': 8,\n",
       "         'eastwood': 6,\n",
       "         'girl': 2391,\n",
       "         'burn': 172,\n",
       "         'pine': 20,\n",
       "         'perish': 10,\n",
       "         'stratford': 10,\n",
       "         'haircut': 39,\n",
       "         'matter': 1675,\n",
       "         'older': 176,\n",
       "         'impossibility': 4,\n",
       "         'theyre': 3890,\n",
       "         'bred': 17,\n",
       "         'their': 2501,\n",
       "         'mothers': 284,\n",
       "         'liked': 424,\n",
       "         'grandmothers': 18,\n",
       "         'gene': 35,\n",
       "         'pool': 177,\n",
       "         'rarely': 31,\n",
       "         'diluted': 2,\n",
       "         'shiteating': 3,\n",
       "         'grin': 4,\n",
       "         'permashitgrin': 1,\n",
       "         'moron': 68,\n",
       "         'number': 826,\n",
       "         'twelve': 384,\n",
       "         'model': 94,\n",
       "         'mostly': 193,\n",
       "         'regional': 14,\n",
       "         'moms': 105,\n",
       "         'canada': 43,\n",
       "         'signed': 128,\n",
       "         'tutor': 13,\n",
       "         'chance': 984,\n",
       "         'consecrate': 1,\n",
       "         'minor': 73,\n",
       "         'encounter': 22,\n",
       "         'shrew': 1,\n",
       "         'biancas': 3,\n",
       "         'mewling': 1,\n",
       "         'rampalian': 1,\n",
       "         'wretch': 5,\n",
       "         'herself': 213,\n",
       "         'teach': 272,\n",
       "         'dazzle': 3,\n",
       "         'charm': 54,\n",
       "         'falls': 106,\n",
       "         'love': 3994,\n",
       "         'unlikely': 27,\n",
       "         'still': 3649,\n",
       "         'makes': 1209,\n",
       "         'hell': 3710,\n",
       "         'thrives': 2,\n",
       "         'danger': 207,\n",
       "         'criminal': 169,\n",
       "         'lit': 37,\n",
       "         'state': 477,\n",
       "         'trooper': 17,\n",
       "         'fire': 742,\n",
       "         'alcatraz': 2,\n",
       "         'felons': 3,\n",
       "         'honors': 18,\n",
       "         'biology': 12,\n",
       "         'serious': 787,\n",
       "         'man': 6906,\n",
       "         'whacked': 31,\n",
       "         'sold': 220,\n",
       "         'his': 8551,\n",
       "         'liver': 25,\n",
       "         'black': 737,\n",
       "         'market': 145,\n",
       "         'buy': 827,\n",
       "         'speakers': 6,\n",
       "         'reputation': 115,\n",
       "         'weve': 1785,\n",
       "         'outrank': 2,\n",
       "         'strictly': 51,\n",
       "         'alist': 2,\n",
       "         'side': 827,\n",
       "         'hated': 162,\n",
       "         'those': 3210,\n",
       "         'gotta': 2246,\n",
       "         'few': 1451,\n",
       "         'clients': 84,\n",
       "         'wall': 249,\n",
       "         'street': 673,\n",
       "         'involved': 378,\n",
       "         'choice': 452,\n",
       "         'besides': 515,\n",
       "         'enemy': 187,\n",
       "         'orchestrating': 1,\n",
       "         'battle': 110,\n",
       "         'position': 261,\n",
       "         'power': 676,\n",
       "         'golden': 65,\n",
       "         'opportunity': 143,\n",
       "         'katarina': 3,\n",
       "         'case': 1278,\n",
       "         'schoolwide': 2,\n",
       "         'blow': 435,\n",
       "         'bent': 48,\n",
       "         'piss': 125,\n",
       "         'himself': 645,\n",
       "         'joy': 66,\n",
       "         'ultimate': 39,\n",
       "         'kiss': 364,\n",
       "         'ass': 1043,\n",
       "         'hates': 137,\n",
       "         'smokers': 4,\n",
       "         'lung': 33,\n",
       "         'cancer': 134,\n",
       "         'issue': 139,\n",
       "         'favorite': 234,\n",
       "         'uncle': 360,\n",
       "         'fortyone': 11,\n",
       "         'assail': 1,\n",
       "         'ears': 150,\n",
       "         'band': 171,\n",
       "         'already': 1511,\n",
       "         'whole': 1689,\n",
       "         'extremely': 102,\n",
       "         'unfortunate': 62,\n",
       "         'maneuver': 17,\n",
       "         'picks': 37,\n",
       "         'carries': 22,\n",
       "         'while': 1445,\n",
       "         'talking': 2690,\n",
       "         'buttholus': 2,\n",
       "         'extremus': 2,\n",
       "         'making': 960,\n",
       "         'progress': 96,\n",
       "         'm': 96,\n",
       "         'humiliated': 24,\n",
       "         'sacrifice': 54,\n",
       "         'yourself': 2210,\n",
       "         'altar': 10,\n",
       "         'dignity': 38,\n",
       "         'score': 116,\n",
       "         'best': 1671,\n",
       "         'scenario': 21,\n",
       "         'payroll': 30,\n",
       "         'awhile': 169,\n",
       "         'non': 36,\n",
       "         'prisonmovie': 1,\n",
       "         'type': 267,\n",
       "         'whatve': 25,\n",
       "         'retrieved': 4,\n",
       "         'certain': 395,\n",
       "         'pieces': 147,\n",
       "         'information': 469,\n",
       "         'miss': 1691,\n",
       "         'youll': 2796,\n",
       "         'helpful': 53,\n",
       "         'thai': 10,\n",
       "         'food': 536,\n",
       "         'feminist': 7,\n",
       "         'prose': 6,\n",
       "         'angry': 251,\n",
       "         'stinky': 10,\n",
       "         'music': 438,\n",
       "         'indierock': 1,\n",
       "         'persuasion': 4,\n",
       "         'noodles': 7,\n",
       "         'book': 754,\n",
       "         'around': 3391,\n",
       "         'chicks': 73,\n",
       "         'play': 1423,\n",
       "         'partial': 29,\n",
       "         'whatd': 471,\n",
       "         'don': 198,\n",
       "         'decided': 325,\n",
       "         'nail': 91,\n",
       "         'drunk': 384,\n",
       "         'remember': 2679,\n",
       "         'suns': 25,\n",
       "         'direct': 123,\n",
       "         'quote': 63,\n",
       "         'needs': 606,\n",
       "         'time': 8172,\n",
       "         'cool': 625,\n",
       "         'day': 2880,\n",
       "         'makin': 91,\n",
       "         'headway': 3,\n",
       "         'kissed': 76,\n",
       "         'worst': 227,\n",
       "         'vintage': 8,\n",
       "         'reading': 285,\n",
       "         'sassy': 11,\n",
       "         'noticed': 208,\n",
       "         'featured': 3,\n",
       "         'big': 2744,\n",
       "         'kmart': 7,\n",
       "         'spread': 74,\n",
       "         'elbow': 13,\n",
       "         'tough': 398,\n",
       "         'running': 758,\n",
       "         'rest': 905,\n",
       "         'ya': 1678,\n",
       "         'leave': 2485,\n",
       "         'alone': 1362,\n",
       "         'legs': 185,\n",
       "         'rack': 23,\n",
       "         'sparky': 10,\n",
       "         'money': 3437,\n",
       "         'take': 7002,\n",
       "         'cake': 107,\n",
       "         'verona': 19,\n",
       "         'pick': 779,\n",
       "         'tab': 27,\n",
       "         'pay': 1074,\n",
       "         'gets': 993,\n",
       "         'catch': 516,\n",
       "         'bucks': 397,\n",
       "         'thirty': 463,\n",
       "         'negotiation': 16,\n",
       "         'fifty': 569,\n",
       "         'results': 56,\n",
       "         'watching': 402,\n",
       "         'bitch': 504,\n",
       "         'trash': 61,\n",
       "         'car': 1948,\n",
       "         'count': 350,\n",
       "         'under': 1068,\n",
       "         'control': 522,\n",
       "         'acts': 41,\n",
       "         'crazed': 8,\n",
       "         'image': 91,\n",
       "         'upped': 9,\n",
       "         'price': 285,\n",
       "         'hundred': 1392,\n",
       "         'deals': 82,\n",
       "         'human': 509,\n",
       "         'limothe': 1,\n",
       "         'flowers': 155,\n",
       "         'another': 2060,\n",
       "         'tux': 6,\n",
       "         'barbie': 14,\n",
       "         'n': 109,\n",
       "         'ken': 36,\n",
       "         'shit': 2940,\n",
       "         'lost': 1133,\n",
       "         'nope': 229,\n",
       "         'came': 2074,\n",
       "         'chat': 82,\n",
       "         'run': 1496,\n",
       "         'idea': 1708,\n",
       "         'interested': 521,\n",
       "         'insane': 222,\n",
       "         'conversation': 192,\n",
       "         'purpose': 162,\n",
       "         'recruit': 15,\n",
       "         'wholl': 41,\n",
       "         'whos': 1478,\n",
       "         'job': 1985,\n",
       "         'helpin': 9,\n",
       "         'uh': 2229,\n",
       "         'took': 1378,\n",
       "         'bathes': 3,\n",
       "         'together': 1390,\n",
       "         'kids': 1143,\n",
       "         'better': 3436,\n",
       "         'fuck': 2598,\n",
       "         'heavily': 24,\n",
       "         'invested': 19,\n",
       "         'higher': 91,\n",
       "         'random': 56,\n",
       "         'skid': 8,\n",
       "         'pat': 56,\n",
       "         'gone': 1303,\n",
       "         'porn': 25,\n",
       "         'movies': 309,\n",
       "         'incapable': 24,\n",
       "         'interesting': 417,\n",
       "         'block': 127,\n",
       "         'e': 63,\n",
       "         'mandella': 1,\n",
       "         'eat': 954,\n",
       "         'starving': 49,\n",
       "         'very': 5095,\n",
       "         'slow': 315,\n",
       "         'die': 1170,\n",
       "         'attempted': 22,\n",
       "         'slit': 27,\n",
       "         'realize': 369,\n",
       "         'institution': 57,\n",
       "         'severely': 10,\n",
       "         'lacking': 23,\n",
       "         'killing': 380,\n",
       "         'william': 137,\n",
       "         'beyond': 196,\n",
       "         'imagine': 405,\n",
       "         'during': 252,\n",
       "         'sex': 602,\n",
       "         'foul': 38,\n",
       "         'raging': 8,\n",
       "         'fit': 247,\n",
       "         'sarah': 121,\n",
       "         'lawrence': 19,\n",
       "         'insists': 17,\n",
       "         'maledominated': 1,\n",
       "         'puking': 7,\n",
       "         'frat': 9,\n",
       "         'golf': 67,\n",
       "         'team': 327,\n",
       "         'proven': 33,\n",
       "         'heterosexuality': 2,\n",
       "         'appreciate': 353,\n",
       "         'efforts': 25,\n",
       "         'toward': 114,\n",
       "         'speedy': 3,\n",
       "         'death': 928,\n",
       "         'consuming': 7,\n",
       "         'precious': 71,\n",
       "         'tiara': 2,\n",
       "         'thisll': 54,\n",
       "         'work': 3572,\n",
       "         'cares': 173,\n",
       "         'officially': 45,\n",
       "         'opposed': 41,\n",
       "         'suburban': 8,\n",
       "         'activity': 42,\n",
       "         'wheres': 1178,\n",
       "         'done': 2170,\n",
       "         'favor': 402,\n",
       "         'backfired': 2,\n",
       "         'puked': 3,\n",
       "         'rejected': 18,\n",
       "         'bastion': 4,\n",
       "         'commercial': 57,\n",
       "         'excess': 8,\n",
       "         'dates': 67,\n",
       "         'sound': 643,\n",
       "         'betty': 244,\n",
       "         'archie': 24,\n",
       "         'taking': 1002,\n",
       "         'veronica': 87,\n",
       "         'dress': 309,\n",
       "         'anyway': 1300,\n",
       "         'looking': 1803,\n",
       "         'wrong': 2490,\n",
       "         'perspective': 31,\n",
       "         'statement': 119,\n",
       "         'us': 7005,\n",
       "         'meet': 1365,\n",
       "         'honey': 909,\n",
       "         'progressed': 3,\n",
       "         'fullon': 4,\n",
       "         'hallucinations': 15,\n",
       "         'doin': 489,\n",
       "         'sweating': 32,\n",
       "         'pig': 156,\n",
       "         'attention': 267,\n",
       "         'mission': 254,\n",
       "         'friday': 168,\n",
       "         'places': 237,\n",
       "         '7eleven': 4,\n",
       "         'burnside': 2,\n",
       "         'screwboy': 2,\n",
       "         'lot': 2521,\n",
       "         'than': 3281,\n",
       "         'warrant': 80,\n",
       "         'strong': 312,\n",
       "         'emotion': 35,\n",
       "         'spend': 343,\n",
       "         'dollar': 236,\n",
       "         'track': 192,\n",
       "         'ponies': 18,\n",
       "         'flat': 121,\n",
       "         'beer': 296,\n",
       "         'eyes': 828,\n",
       "         'hand': 891,\n",
       "         'covered': 124,\n",
       "         'vomit': 35,\n",
       "         'seventhirty': 12,\n",
       "         'following': 203,\n",
       "         'laundromat': 8,\n",
       "         'saw': 2020,\n",
       "         'talker': 10,\n",
       "         'depends': 183,\n",
       "         'topic': 22,\n",
       "         'fenders': 2,\n",
       "         'whip': 41,\n",
       "         'into': 3618,\n",
       "         'verbal': 25,\n",
       "         'frenzy': 6,\n",
       "         'show': 1723,\n",
       "         'excuse': 845,\n",
       "         'sort': 825,\n",
       "         'bikini': 10,\n",
       "         'kill': 2499,\n",
       "         'raincoats': 4,\n",
       "         'trashed': 14,\n",
       "         'funny': 933,\n",
       "         'down': 5401,\n",
       "         'concussion': 15,\n",
       "         'dog': 602,\n",
       "         'woke': 123,\n",
       "         'vegetable': 24,\n",
       "         'patronizing': 10,\n",
       "         'words': 569,\n",
       "         'shitfaced': 7,\n",
       "         'affection': 25,\n",
       "         'blind': 205,\n",
       "         'hatred': 23,\n",
       "         'whyd': 194,\n",
       "         'itd': 158,\n",
       "         'mainline': 2,\n",
       "         'tequila': 20,\n",
       "         'laid': 171,\n",
       "         'above': 156,\n",
       "         'wake': 360,\n",
       "         'jail': 336,\n",
       "         'werent': 675,\n",
       "         'father': 2055,\n",
       "         ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_freq = Counter()\n",
    "for pair in pairs:\n",
    "  word_freq.update(pair[0])\n",
    "  word_freq.update(pair[1])\n",
    "\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "c2ImfRPxKsSJ"
   },
   "outputs": [],
   "source": [
    "# Minimum word frequency threshold\n",
    "min_word_freq = 5\n",
    "\n",
    "# Filter words that meet the minimum frequency requirement\n",
    "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
    "\n",
    "# Create word-to-index mapping, starting from 1\n",
    "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
    "\n",
    "# Add special tokens to the word map\n",
    "word_map['<unk>'] = len(word_map) + 1  # Unknown words\n",
    "word_map['<start>'] = len(word_map) + 1  # Start token\n",
    "word_map['<end>'] = len(word_map) + 1  # End token\n",
    "word_map['<pad>'] = 0  # Padding token (assigned index 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dhB1toNKMnTi"
   },
   "outputs": [],
   "source": [
    "# Save word map to JSON file\n",
    "import json\n",
    "with open(\"WORDMAP_corpus.json\", \"w\") as j:\n",
    "    json.dump(word_map, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gazxi2WulYGi"
   },
   "source": [
    "### Encoding Text Sequences for Model Training\n",
    "Following code converts the preprocessed text pairs into numerical sequences suitable for neural network training, while handling special tokens and padding.\n",
    "\n",
    "#### Encoding Functions:\n",
    "\n",
    "1. **`encode_question(question_words, word_map)`**:\n",
    "   - Converts a question into numerical indices\n",
    "   - **Process**:\n",
    "     - Each word is looked up in `word_map` (uses `<unk>` for missing words)\n",
    "     - Padding (`<pad> = 0`) is added to reach `max_len`\n",
    "   - **Example**: `[\"how\", \"are\", \"you\"]` → `[12, 25, 63, 0, 0, ...]` (for `max_len=25`)\n",
    "\n",
    "2. **`encode_reply(answer_words, word_map)`**:\n",
    "   - Converts an answer with special sequence tokens\n",
    "   - **Process**:\n",
    "     - Starts with `<start>` token\n",
    "     - Includes word indices (with `<unk>` for unknowns)\n",
    "     - Ends with `<end>` token\n",
    "     - Adds padding to reach `max_len`\n",
    "   - **Example**: `[\"i\", \"am\", \"fine\"]` → `[2533, 8, 42, 156, 2534, 0, 0, ...]`\n",
    "\n",
    "#### Special Token Handling:\n",
    "| Token    | Purpose                          | Example ID |\n",
    "|----------|----------------------------------|------------|\n",
    "| `<pad>`  | Padding for fixed-length sequences | 0         |\n",
    "| `<unk>`  | Unknown/low-frequency words      | 2532      |\n",
    "| `<start>`| Start-of-sequence marker         | 2533      |\n",
    "| `<end>`  | End-of-sequence marker           | 2534      |\n",
    "\n",
    "#### Full Encoding Process:\n",
    "1. Iterates through all QA pairs\n",
    "2. Encodes questions using `encode_question()`\n",
    "3. Encodes answers using `encode_reply()`\n",
    "4. Stores encoded pairs in `pairs_encoded`\n",
    "\n",
    "#### Why This Matters:\n",
    "- Converts variable-length text to fixed-length numerical arrays\n",
    "- Special tokens help the model learn:\n",
    "  - When sequences start/end (`<start>`, `<end>`)\n",
    "  - How to handle padding in batches (`<pad>`)\n",
    "  - How to deal with unknown vocabulary (`<unk>`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vufClDC_NYgh"
   },
   "outputs": [],
   "source": [
    "# Encode question by converting words to indices and padding to max_len\n",
    "def encode_question(words, word_map):\n",
    "    enc_c = [word_map.get(word, word_map[\"<unk>\"]) for word in words] + [word_map[\"<pad>\"]] * (max_len - len(words))\n",
    "    return enc_c\n",
    "\n",
    "# Encode reply with start/end tokens and padding to max_len\n",
    "def encode_reply(words, word_map):\n",
    "    enc_c = [word_map[\"<start>\"]] + [word_map.get(word, word_map[\"<unk>\"]) for word in words] + [word_map[\"<end>\"]] + [word_map[\"<pad>\"]] * (max_len - len(words))\n",
    "    return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXUdR12RRVVS",
    "outputId": "69308369-b7a6-4e2a-e49b-d2626ec975fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can we make this quick roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad again\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[18241,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 18240,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 24,\n",
       " 28,\n",
       " 18242,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" \".join(pairs[0][0]))\n",
    "encode_reply(pairs[0][1], word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Jlx88BKERwNY"
   },
   "outputs": [],
   "source": [
    "# Initialize list to store encoded question-answer pairs\n",
    "pairs_encoded = []\n",
    "\n",
    "# Iterate through each question-answer pair\n",
    "for pair in pairs:\n",
    "    # Encode the question part\n",
    "    ques = encode_question(pair[0], word_map)\n",
    "    # Encode the answer part\n",
    "    ans = encode_reply(pair[1], word_map)\n",
    "    # Add encoded pair to the list\n",
    "    pairs_encoded.append([ques, ans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yHPtNlFLVx3i"
   },
   "outputs": [],
   "source": [
    "# Save pairs encoded to JSON file\n",
    "import json\n",
    "with open(\"pairs_encoded.json\", \"w\") as w:\n",
    "  json.dump(pairs_encoded, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEGWfgrymnrR"
   },
   "source": [
    "### PyTorch Data Pipeline for Dialogue Pairs\n",
    "This code creates a custom PyTorch Dataset and DataLoader to efficiently handle batches of encoded question-answer pairs for model training.\n",
    "\n",
    "#### Key Components:\n",
    "\n",
    "1. **Custom Dataset Class**:\n",
    "   - Inherits from `torch.utils.data.Dataset`\n",
    "   - **`__init__`**:\n",
    "     - Loads pre-encoded pairs from JSON file (`pairs_encoded.json`)\n",
    "     - Stores dataset size\n",
    "   - **`__getitem__`**:\n",
    "     - Converts encoded sequences to `LongTensor`\n",
    "     - Returns (question, reply) tuple for a given index\n",
    "   - **`__len__`**:\n",
    "     - Returns total number of pairs\n",
    "\n",
    "2. **DataLoader Setup**:\n",
    "   - Creates `train_loader` with:\n",
    "     - Batch size of 100 samples\n",
    "     - Shuffling enabled (`shuffle=True`)\n",
    "     - Pinned memory for faster GPU transfer (`pin_memory=True`)\n",
    "\n",
    "3. **Output Shapes**:\n",
    "   - **Questions**: `[100, 25]` (batch_size × max_question_length)\n",
    "   - **Replies**: `[100, 27]` (batch_size × max_reply_length + 2 for <start>/<end> tokens)\n",
    "\n",
    "#### Why This Matters:\n",
    "- **Efficient Training**:\n",
    "  - Batched processing speeds up training\n",
    "  - Automatic shuffling improves model generalization\n",
    "- **GPU Optimization**:\n",
    "  - `pin_memory=True` enables faster CPU-to-GPU transfers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6TzIVntBVL55"
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Custom Dataset class\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        # Load encoded pairs from JSON file\n",
    "        self.pairs = json.load(open(path))\n",
    "        # Store dataset size\n",
    "        self.dataset_size = len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Convert question and reply to LongTensors\n",
    "        question = torch.LongTensor(self.pairs[index][0])\n",
    "        reply = torch.LongTensor(self.pairs[index][1])\n",
    "        return question, reply\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return total number of pairs\n",
    "        return self.dataset_size\n",
    "\n",
    "# Create dataset instance\n",
    "dataset = Dataset(path=\"pairs_encoded.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LzGzcItXrtx",
    "outputId": "c4270f4d-6c33-40d2-f413-4d5bf9f614aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 25]), torch.Size([100, 27]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DataLoader from PyTorch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_loader = DataLoader(dataset, batch_size=100, shuffle=True, pin_memory=True)\n",
    "\n",
    "# Get a batch of data and check shapes\n",
    "question, reply = next(iter(train_loader))\n",
    "question.shape, reply.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_NXsl0tSYKob",
    "outputId": "40f33d6e-ef9d-4188-c831-e732bf678a6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18241,    87,  1063,    20,   267, 18242,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LGKGK6S9fmwa",
    "outputId": "36b538e8-9b01-4df6-9b9d-d29ba4e7bd51"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kB6u3K3Onmu7"
   },
   "source": [
    "## **Create Transformer Masks**  \n",
    "Generates attention masks for the transformer:  \n",
    "1. **`src_key_padding_mask`**: Mask for encoder input padding (`True` at pad positions).  \n",
    "2. **`tgt_key_padding_mask`**: Mask for decoder input padding.  \n",
    "3. **`tgt_mask`**: Causal mask for decoder self-attention (upper-triangular `-inf`).  \n",
    "\n",
    "**Args**:  \n",
    "- `src`: Encoder input tensor `[batch_size, src_len]`.  \n",
    "- `tgt_input`: Decoder input tensor `[batch_size, tgt_len]`.  \n",
    "- `pad_token`: Padding token ID (default: `0`).  \n",
    "\n",
    "**Returns**:  \n",
    "Tuple of masks for encoder/decoder attention.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wiV274g6btSq"
   },
   "outputs": [],
   "source": [
    "def create_transformer_masks(src, tgt_input, pad_token=0):\n",
    "    # Create source key padding mask:\n",
    "    # Marks positions where `src` tokens are padding (True for padding, False otherwise)\n",
    "    # Shape: [batch_size, src_len]\n",
    "    src_key_padding_mask = (src == pad_token)  # bool, True at PAD positions\n",
    "\n",
    "    # Create target key padding mask:\n",
    "    # Marks positions where `tgt_input` tokens are padding (True for padding, False otherwise)\n",
    "    # Shape: [batch_size, tgt_len]\n",
    "    tgt_key_padding_mask = (tgt_input == pad_token)  # bool, True at PAD positions\n",
    "\n",
    "    # Create target causal mask (prevents decoder from attending to future tokens):\n",
    "    # Upper triangular matrix with -inf (for masked positions) and 0 (for allowed positions)\n",
    "    # Shape: [tgt_len, tgt_len]\n",
    "    tgt_len = tgt_input.size(1)  # Get target sequence length\n",
    "    tgt_mask = torch.triu(torch.ones((tgt_len, tgt_len), device=src.device), diagonal=1) == 1  # Upper triangle (diagonal=1 excludes main diagonal)\n",
    "    tgt_mask = tgt_mask.float().masked_fill(tgt_mask == 1, float('-inf')).masked_fill(tgt_mask == 0, float(0.0))  # Replace 1s with -inf, 0s remain 0\n",
    "\n",
    "    return src_key_padding_mask, tgt_key_padding_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erIvUPJGrNYU"
   },
   "source": [
    "### **Embeddings Layer**  \n",
    "Combines token embeddings with positional encodings for transformer inputs.  \n",
    "\n",
    "#### **Key Components**:  \n",
    "1. **Token Embeddings**: `nn.Embedding` layer to map vocabulary indices to `d_model`-dimensional vectors.  \n",
    "2. **Positional Encodings**: Sinusoidal patterns to inject positional information (Vaswani et al., 2017).  \n",
    "3. **Dropout**: Regularization via `nn.Dropout`.  \n",
    "\n",
    "#### **Methods**:  \n",
    "- **`create_positional_encoding(max_len, d_model)`**:  \n",
    "  Generates sinusoidal positional encodings of shape `[max_len, d_model]` using geometric progression of wavelengths.  \n",
    "- **`forward(encoded_words)`**:  \n",
    "  Scales token embeddings by `√d_model`, adds positional encodings, and applies dropout.  \n",
    "\n",
    "#### **Args**:  \n",
    "- `vocab_size`: Size of the vocabulary.  \n",
    "- `d_model`: Embedding dimension.  \n",
    "- `dropout`: Dropout probability.  \n",
    "- `max_len`: Maximum sequence length for positional encodings (default: `50`).  \n",
    "\n",
    "#### **Input**:  \n",
    "- `encoded_words`: Token indices tensor `[batch_size, seq_len]`.  \n",
    "\n",
    "#### **Output**:  \n",
    "- Embeddings tensor `[batch_size, seq_len, d_model]`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9-8q954tfcQx"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, dropout, max_len=50):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model  # Dimension of the embedding vectors\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout layer for regularization\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)  # Token embedding layer\n",
    "        self.pe = self.create_positional_encoding(max_len, d_model)  # Pre-computed positional encoding\n",
    "\n",
    "    def create_positional_encoding(self, max_len, d_model):\n",
    "        # Initialize a matrix to hold positional encodings (max_len x d_model)\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "\n",
    "        # Generate positional encodings using sine and cosine functions\n",
    "        for pos in range(max_len):  # For each position in the sequence\n",
    "            for i in range(0, d_model, 2):  # For each even/odd pair in the embedding dimension\n",
    "                # Sine for even indices, cosine for odd indices\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1)) / d_model)))\n",
    "\n",
    "        # Add batch dimension: [1, max_len, d_model] for broadcasting\n",
    "        pe = pe.unsqueeze(0)\n",
    "        return pe\n",
    "\n",
    "    def forward(self, encoded_words):\n",
    "        # Convert token indices to embeddings and scale by sqrt(d_model)\n",
    "        embeddings = self.embed(encoded_words) * math.sqrt(self.d_model)\n",
    "\n",
    "        # Add positional encodings (truncate to match input sequence length)\n",
    "        embeddings += self.pe[:, :embeddings.size(1)]\n",
    "\n",
    "        # Apply dropout for regularization\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsQgndG8tEVr"
   },
   "source": [
    "### **Transformer Model**  \n",
    "End-to-end transformer architecture for sequence-to-sequence tasks (e.g., translation, text generation).  \n",
    "\n",
    "#### **Components**:  \n",
    "1. **Embedding Layer**:  \n",
    "   - Converts token indices to embeddings with positional encodings (`Embeddings` class).  \n",
    "2. **Transformer Layers**:  \n",
    "   - Stacked encoder/decoder layers with multi-head attention (PyTorch `nn.Transformer`).  \n",
    "   - Supports masking for padding (`key_padding_mask`) and causal attention (`tgt_mask`).  \n",
    "3. **Output Projection**:  \n",
    "   - Linear layer + log-softmax to predict token probabilities.  \n",
    "\n",
    "#### **Key Args (__init__)**:  \n",
    "- `vocab_size`: Size of vocabulary.  \n",
    "- `d_model`: Embedding dimension (default: `512`).  \n",
    "- `nhead`: Number of attention heads (default: `8`).  \n",
    "- `num_layers`: Encoder/decoder layers (default: `3`).  \n",
    "- `dim_feedforward`: FFN hidden dimension (default: `2048`).  \n",
    "- `dropout`: Dropout probability (default: `0.1`).  \n",
    "\n",
    "#### **Forward Pass**:  \n",
    "- **Inputs**:  \n",
    "  - `src`: Encoder input tokens `[batch_size, src_len]`.  \n",
    "  - `tgt`: Decoder input tokens `[batch_size, tgt_len]`.  \n",
    "  - `src_key_padding_mask`: Mask for encoder padding `[batch_size, src_len]`.  \n",
    "  - `tgt_key_padding_mask`: Mask for decoder padding `[batch_size, tgt_len]`.  \n",
    "  - `tgt_mask`: Causal mask for decoder `[tgt_len, tgt_len]`.  \n",
    "- **Output**:  \n",
    "  - Log probabilities over vocabulary `[batch_size, tgt_len, vocab_size]`.  \n",
    "\n",
    "#### **Note**:  \n",
    "- Uses `batch_first=True` for consistent tensor shapes with embeddings.  \n",
    "- Log-softmax stabilizes training vs. raw logits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "OlVVtjMGeFdF"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, nhead=8, num_layers=3, dim_feedforward=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # Embedding layer: converts token indices to embeddings + positional encoding\n",
    "        self.embedding = Embeddings(vocab_size, d_model, dropout)\n",
    "\n",
    "        # Core Transformer module (encoder + decoder)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,            # Embedding dimension\n",
    "            nhead=nhead,               # Number of attention heads\n",
    "            num_encoder_layers=num_layers,  # Number of encoder layers\n",
    "            num_decoder_layers=num_layers,  # Number of decoder layers\n",
    "            dim_feedforward=dim_feedforward,  # Hidden layer size in feedforward networks\n",
    "            dropout=dropout,           # Dropout probability\n",
    "            batch_first=True           # Input shape: (batch, seq_len, d_model)\n",
    "        )\n",
    "\n",
    "        # Final linear layer: projects transformer output back to vocabulary space\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask, tgt_key_padding_mask, tgt_mask):\n",
    "        # Convert input tokens to embeddings (add positional encoding)\n",
    "        src_emb = self.embedding(src)  # Shape: [batch_size, src_len, d_model]\n",
    "        tgt_emb = self.embedding(tgt)  # Shape: [batch_size, tgt_len, d_model]\n",
    "\n",
    "        # Pass through Transformer (encoder-decoder architecture)\n",
    "        output = self.transformer(\n",
    "            src_emb,  # Encoder input (source sequence embeddings)\n",
    "            tgt_emb,  # Decoder input (target sequence embeddings)\n",
    "            src_key_padding_mask=src_key_padding_mask,  # Mask for encoder padding tokens\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask,  # Mask for decoder padding tokens\n",
    "            memory_key_padding_mask=src_key_padding_mask,  # Mask for encoder output (memory) padding\n",
    "            tgt_mask=tgt_mask  # Causal mask for autoregressive decoding\n",
    "        )  # Output shape: [batch_size, tgt_len, d_model]\n",
    "\n",
    "        # Project to vocabulary space and apply log-softmax (for NLLLoss)\n",
    "        return torch.log_softmax(self.fc_out(output), dim=-1)  # Shape: [batch_size, tgt_len, vocab_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgaMY1p0tZoz"
   },
   "source": [
    "**Purpose**: Implements warmup learning rate schedule for Transformer training\n",
    "\n",
    "**Key Features**:\n",
    "- Linear warmup followed by inverse square root decay\n",
    "- Learning rate formula:\n",
    "  `lr = d_model^(-0.5) * min(step^(-0.5), step*warmup^(-1.5))`\n",
    "- Automatically updates optimizer's LR each step\n",
    "\n",
    "**Usage**:\n",
    "1. Wraps any PyTorch optimizer\n",
    "2. Call `step()` instead of optimizer.step()\n",
    "3. Warmup typically ~4000-8000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "f1sBpWcCgWNF"
   },
   "outputs": [],
   "source": [
    "class AdamWarmUp:\n",
    "  def __init__(self, model_size, warmup_size, optimizer):\n",
    "    # Initialize learning rate scheduler parameters\n",
    "    self.model_size   = model_size\n",
    "    self.warmup_size  = warmup_size\n",
    "    self.optimizer    = optimizer\n",
    "    self.current_step = 0\n",
    "    self.lr          = 0\n",
    "\n",
    "  def get_lr(self):\n",
    "    # Calculate learning rate with warmup\n",
    "    return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_size ** (-1.5))\n",
    "\n",
    "  def step(self):\n",
    "    # Update learning rate and optimizer step\n",
    "    self.current_step += 1\n",
    "    lr = self.get_lr()\n",
    "    for param_group in self.optimizer.param_groups:\n",
    "      param_group['lr'] = lr\n",
    "    self.lr = lr\n",
    "    self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fb0sxxDtXBq"
   },
   "source": [
    "**Purpose**: KLDivLoss with label smoothing regularization\n",
    "\n",
    "**Key Features**:\n",
    "- Distributes `smooth` probability mass over all classes\n",
    "- Keeps `confidence` (1-smooth) for true class\n",
    "- Masks padding positions (zero loss)\n",
    "- Helps prevent overconfidence in predictions\n",
    "\n",
    "**Parameters**:\n",
    "- `size`: Vocabulary size\n",
    "- `smooth`: Smoothing factor (e.g., 0.1)\n",
    "- Processes batches of shape `(seq_len, vocab_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "oiFpmgGmvKoo"
   },
   "outputs": [],
   "source": [
    "class LossWithLS(nn.Module):\n",
    "  def __init__(self, size, smooth):\n",
    "    super().__init__()\n",
    "\n",
    "    # Initialize loss components and smoothing parameters\n",
    "    self.criterion  = nn.KLDivLoss(size_average=False, reduce=False)\n",
    "    self.smooth     = smooth\n",
    "    self.confidence = 1 - self.smooth\n",
    "    self.size       = size\n",
    "\n",
    "  def forward(self, prediction, target, mask):\n",
    "    # Reshape tensors for loss calculation\n",
    "    prediction = prediction.view(-1, prediction.size(-1))  # Flatten predictions\n",
    "    target = target.contiguous().view(-1)  # Flatten targets\n",
    "    mask = mask.float()  # Convert mask to float\n",
    "    mask = mask.view(-1)  # Flatten mask\n",
    "\n",
    "    # Apply label smoothing\n",
    "    labels = prediction.data.clone()\n",
    "    labels.fill_(self.smooth / (self.size - 1))  # Uniform distribution\n",
    "    target = target.data.unsqueeze(1)\n",
    "    labels.scatter_(1, target, self.confidence)  # Add confidence to true class\n",
    "\n",
    "    # Calculate and mask the loss\n",
    "    loss = self.criterion(prediction, labels)  # Compute KL divergence\n",
    "    loss = (loss.sum(1) * mask).sum() / mask.sum()  # Apply mask and normalize\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "omNsG8xPxuVe"
   },
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "nhead = 8\n",
    "num_layers = 3\n",
    "dropout = 0.1\n",
    "\n",
    "with open(\"WORDMAP_corpus.json\", \"r\") as f:\n",
    "    word_map = json.load(f)\n",
    "\n",
    "model = TransformerModel(\n",
    "    vocab_size=len(word_map),\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SKdRzi1tpCi"
   },
   "source": [
    "### **Training Loop**  \n",
    "Implements the end-to-end training process for the transformer model with masked loss calculation.\n",
    "\n",
    "#### **Key Features**:\n",
    "1. **Teacher Forcing**: Uses decoder input (`reply_input`) shifted right by 1 token.\n",
    "2. **Masked Loss**: Computes loss only on non-padding tokens (ignores padding with `mask`).\n",
    "3. **Batch Processing**: Tracks and reports loss every 500 batches and per epoch.\n",
    "4. **Model Checkpoints**: Saves model weights after each epoch.\n",
    "\n",
    "#### **Parameters**:\n",
    "- `train_loader`: DataLoader providing (question, reply) batches.\n",
    "- `model`: Initialized transformer model.\n",
    "- `optimizer`: Optimizer (e.g., Adam) with learning rate scheduling.\n",
    "- `criterion`: Loss function (should handle masking).\n",
    "- `epochs`: Number of training epochs.\n",
    "- `device`: Target device (e.g., 'cuda').\n",
    "\n",
    "#### **Training Steps**:\n",
    "1. **Input Preparation**:\n",
    "   - Shifts target sequence (`reply_input = reply[:, :-1]`).\n",
    "   - Generates masks via `create_transformer_masks()`.\n",
    "2. **Forward Pass**:\n",
    "   - Computes log probabilities for next-token prediction.\n",
    "3. **Loss Calculation**:\n",
    "   - Flattens outputs/targets for batch processing.\n",
    "   - Applies mask to ignore padding tokens (0) in loss.\n",
    "4. **Optimization**:\n",
    "   - Standard backpropagation with gradient clipping (if needed).\n",
    "5. **Logging**:\n",
    "   - Prints batch/epoch progress.\n",
    "   - Saves model checkpoints (`transformer_{epoch}.pth`).\n",
    "\n",
    "#### **Output**:\n",
    "- `total_losses`: List of average losses per epoch for analysis.\n",
    "\n",
    "#### **Example Usage**:\n",
    "\n",
    "\n",
    "losses = train(train_loader, model, optimizer, criterion, epochs=10,\n",
    "device='cuda')\n",
    "\n",
    "plt.plot(losses)  # Visualize training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "NfC20akv3yP0"
   },
   "outputs": [],
   "source": [
    "criterion = LossWithLS(size=len(word_map), smooth=0.1).to(device)\n",
    "base_optimizer = torch.optim.Adam(model.parameters(), lr=0)\n",
    "optimizer = AdamWarmUp(model_size=d_model, warmup_size=4000, optimizer=base_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "GkiOmn8K2z9a"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, criterion, epochs, device):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_losses = []  # Store average loss per epoch\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []  # Store loss per batch in current epoch\n",
    "\n",
    "        for batch_number, (question, reply) in enumerate(train_loader, start=1):\n",
    "            # Move data to GPU/CPU\n",
    "            question, reply = question.to(device), reply.to(device)\n",
    "\n",
    "            # Prepare decoder input (shifted right) and target (shifted left)\n",
    "            reply_input = reply[:, :-1]  # Exclude last token (used as decoder input) [batch_size, tgt_len-1]\n",
    "            reply_target = reply[:, 1:]  # Exclude first token (used as target) [batch_size, tgt_len-1]\n",
    "\n",
    "            # Create masks for transformer (padding + causal masking)\n",
    "            src_key_padding_mask, tgt_key_padding_mask, tgt_mask = create_transformer_masks(question, reply_input)\n",
    "\n",
    "            # Forward pass: model computes log probabilities for next-token prediction\n",
    "            outputs = model(\n",
    "                question,  # Encoder input (source sequence)\n",
    "                reply_input,  # Decoder input (target sequence shifted right)\n",
    "                src_key_padding_mask=src_key_padding_mask,  # Mask for encoder padding\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,  # Mask for decoder padding\n",
    "                tgt_mask=tgt_mask  # Causal mask for autoregressive decoding\n",
    "            )\n",
    "\n",
    "            # Reshape outputs and targets for loss calculation\n",
    "            outputs = outputs.view(-1, outputs.shape[-1])  # Flatten to [batch_size * (tgt_len-1), vocab_size]\n",
    "            reply_target = reply_target.reshape(-1)  # Flatten to [batch_size * (tgt_len-1)]\n",
    "\n",
    "            # Create loss mask (ignore padding tokens, i.e., where target == 0)\n",
    "            mask = (reply_target != 0).float()  # 1 for non-padding, 0 for padding\n",
    "            loss = criterion(outputs, reply_target, mask)  # Compute masked loss\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.optimizer.zero_grad()  # Reset gradients\n",
    "            loss.backward()  # Compute gradients\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            batch_losses.append(loss.item())  # Track batch loss\n",
    "\n",
    "            # Log progress every 500 batches\n",
    "            if batch_number % 500 == 0:\n",
    "                avg_loss = sum(batch_losses[-500:]) / len(batch_losses[-500:])\n",
    "                print(f\"[Batch/Epoch] [{batch_number}/{epoch+1}] | Avg Loss (last 500): {avg_loss:.4f}\")\n",
    "\n",
    "        # Save model checkpoint after each epoch\n",
    "        torch.save(model.state_dict(), f\"transformer_{epoch+1}.pth\")\n",
    "\n",
    "        # Compute epoch average loss\n",
    "        epoch_avg = sum(batch_losses) / len(batch_losses)\n",
    "        total_losses.append(epoch_avg)\n",
    "        print(f\"Epoch {epoch+1} finished | Avg Loss: {epoch_avg:.4f}\")\n",
    "\n",
    "    return total_losses  # Return list of average losses per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-z2iex1wOK6",
    "outputId": "3e1a0e80-0b7b-4d6f-9ac2-65a83867ff5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch/Epoch] [500/1] | Avg Loss (last 500): 6.4089\n",
      "[Batch/Epoch] [1000/1] | Avg Loss (last 500): 4.9818\n",
      "[Batch/Epoch] [1500/1] | Avg Loss (last 500): 4.6920\n",
      "[Batch/Epoch] [2000/1] | Avg Loss (last 500): 4.5899\n",
      "Epoch 1 finished | Avg Loss: 5.1058\n",
      "[Batch/Epoch] [500/2] | Avg Loss (last 500): 4.4712\n",
      "[Batch/Epoch] [1000/2] | Avg Loss (last 500): 4.4392\n",
      "[Batch/Epoch] [1500/2] | Avg Loss (last 500): 4.4155\n",
      "[Batch/Epoch] [2000/2] | Avg Loss (last 500): 4.3867\n",
      "Epoch 2 finished | Avg Loss: 4.4221\n",
      "[Batch/Epoch] [500/3] | Avg Loss (last 500): 4.2893\n",
      "[Batch/Epoch] [1000/3] | Avg Loss (last 500): 4.2797\n",
      "[Batch/Epoch] [1500/3] | Avg Loss (last 500): 4.2598\n",
      "[Batch/Epoch] [2000/3] | Avg Loss (last 500): 4.2501\n",
      "Epoch 3 finished | Avg Loss: 4.2668\n"
     ]
    }
   ],
   "source": [
    "total_losses = train(train_loader, model, optimizer, criterion, 3, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "vAvkqS6EzVKT",
    "outputId": "935eeddf-35e4-4bda-ecd0-92060a0dc71f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7b2ad3f84790>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # Import the matplotlib plotting library\n",
    "\n",
    "plt.figure(figsize=(15, 7))       # Create a new figure with size 15x7 inches\n",
    "\n",
    "plt.plot(range(len(total_losses)), total_losses, 'r--' ,label=\"Train Loss\")\n",
    "# Plot training losses with red dashed line and label\n",
    "plt.legend()\n",
    "# Display the legend to identify plotted lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EB3kxZ4KqiFS",
    "outputId": "07e23138-c6ff-4f6d-a4de-1c1c66511d44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"transformer_2.pth\"  # Replace with your saved file\n",
    "state_dict = torch.load(checkpoint_path, map_location=device)  # Load to CPU/GPU\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Isf8AhXRt3G6"
   },
   "source": [
    "### **Model Evaluation and Interactive Inference**\n",
    "\n",
    "#### **Evaluation Function (`evaluate`)**\n",
    "Generates responses using either greedy decoding (deterministic) or top-k sampling (stochastic).\n",
    "\n",
    "**Parameters:**\n",
    "- `model`: Trained transformer model\n",
    "- `question`: Input sequence tensor `[1, src_len]`\n",
    "- `word_map`: Vocabulary mapping (word → index)\n",
    "- `max_len`: Maximum output length (default: 30)\n",
    "- `top_k`: Controls decoding strategy:\n",
    "  - `1`: Greedy decoding (always picks highest probability token)\n",
    "  - `>1`: Top-k sampling (randomly samples from top-k tokens)\n",
    "  - `None`: Full vocabulary sampling\n",
    "\n",
    "**Process:**\n",
    "1. Initializes generation with `<start>` token\n",
    "2. Iteratively predicts next token:\n",
    "   - Applies transformer masks for proper attention\n",
    "   - Selects token based on `top_k` parameter\n",
    "   - Stops when `<end>` token is generated or `max_len` reached\n",
    "3. Converts token indices back to words\n",
    "\n",
    "**Returns:**\n",
    "- Generated response string\n",
    "\n",
    "---\n",
    "\n",
    "#### **Interactive Loop**\n",
    "Provides a chat interface for real-time model interaction:\n",
    "\n",
    "**Features:**\n",
    "- Handles OOV words with `<unk>` tokens\n",
    "- Dynamic input length handling\n",
    "- Exit with \"quit\" command\n",
    "\n",
    "**Usage Example:**\n",
    "\n",
    "Question: What is AI?\n",
    "\n",
    "Bot: AI is the simulation of human intelligence processes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "OWSOlVNFptTZ"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, question, word_map, max_len=30, top_k=1):\n",
    "    \"\"\"\n",
    "    Performs decoding using either Greedy (top_k=1) or Top-k sampling (top_k > 1 or None).\n",
    "    Args:\n",
    "        model: Trained Transformer model.\n",
    "        question: Input sequence tensor of shape [1, src_len].\n",
    "        word_map: Dictionary mapping words to indices.\n",
    "        max_len: Maximum length of generated sequence.\n",
    "        top_k: If 1, uses greedy decoding. If >1 or None, uses Top-k sampling.\n",
    "    Returns:\n",
    "        sentence: Generated output sequence as a string.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Get special tokens\n",
    "    start_token = word_map['<start>']\n",
    "    end_token = word_map['<end>']\n",
    "\n",
    "    question = question.to(device)  # Move input to device (shape: [1, src_len])\n",
    "    generated = torch.LongTensor([[start_token]]).to(device)  # Initialize with <start> token (shape: [1, 1])\n",
    "\n",
    "    # Autoregressive decoding loop\n",
    "    for _ in range(max_len - 1):\n",
    "        # Create masks for current generated sequence\n",
    "        src_key_padding_mask, tgt_key_padding_mask, tgt_mask = create_transformer_masks(question, generated)\n",
    "\n",
    "        # Forward pass (no teacher forcing)\n",
    "        output = model(\n",
    "            question,\n",
    "            generated,\n",
    "            src_key_padding_mask=src_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "            tgt_mask=tgt_mask\n",
    "        )\n",
    "        predictions = output[:, -1, :]  # Get last predicted token (shape: [1, vocab_size])\n",
    "        probs = torch.softmax(predictions, dim=-1).squeeze(0)  # Convert to probabilities (shape: [vocab_size])\n",
    "\n",
    "        # Select next token (greedy or sampling)\n",
    "        if top_k != 1:\n",
    "            if top_k is None:  # Sample from full vocabulary\n",
    "                top_ch = np.arange(len(word_map))\n",
    "                p = probs.detach().cpu().numpy()\n",
    "            else:  # Top-k sampling\n",
    "                p, top_ch = torch.topk(probs, k=top_k)\n",
    "                p = p.detach().cpu().numpy()\n",
    "                top_ch = top_ch.detach().cpu().numpy()\n",
    "            next_word = np.random.choice(top_ch, p=p/p.sum())  # Sample from Top-k\n",
    "        else:  # Greedy decoding\n",
    "            next_word = torch.argmax(probs).item()\n",
    "\n",
    "        # Stop if <end> token is generated\n",
    "        if next_word == end_token:\n",
    "            break\n",
    "\n",
    "        # Append new token to generated sequence\n",
    "        next_word_tensor = torch.LongTensor([[next_word]]).to(device)\n",
    "        generated = torch.cat([generated, next_word_tensor], dim=1)  # shape: [1, current_len + 1]\n",
    "\n",
    "    # Convert token indices to words\n",
    "    rev_word_map = {v: k for k, v in word_map.items()}  # Inverse word map\n",
    "    generated = generated.squeeze(0).tolist()  # Remove batch dim and convert to list\n",
    "    sen_idx = [idx for idx in generated if idx != start_token]  # Remove <start> token\n",
    "    sentence = \" \".join([rev_word_map[idx] for idx in sen_idx])  # Join tokens into string\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rm2QnWg6puaq",
    "outputId": "b26479aa-49e6-465a-8a7d-29c9e50aa87b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: hello\n",
      "Bot: i was a very good one\n",
      "Question: how are you doing\n",
      "Bot: i dont want to know what i mean\n",
      "Question: what is your name\n",
      "Bot: what are you going to have\n",
      "Question: quit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Interactive loop\n",
    "while True:\n",
    "    question = input(\"Question: \")\n",
    "    if question.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    max_len = 20\n",
    "\n",
    "    enc_qus = [word_map.get(word, word_map[\"<unk>\"]) for word in question.strip().split()]\n",
    "    if not enc_qus:\n",
    "        print(\"Empty input.\")\n",
    "        continue\n",
    "\n",
    "    question_tensor = torch.LongTensor(enc_qus).unsqueeze(0).to(device)  # [1, src_len]\n",
    "\n",
    "    sentence = evaluate(model, question_tensor, word_map, max_len=max_len, top_k=3)\n",
    "    print(\"Bot:\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ici1PrTZBP1P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
